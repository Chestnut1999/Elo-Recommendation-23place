{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 17:42:49,229 utils 400 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import glob\n",
    "sys.path.append('../py/')\n",
    "from s027_kfold_ods import ods_kfold\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "sys.path.append(f'{HOME}/kaggle/data_analysis/library')\n",
    "import utils\n",
    "from utils import logger_func, get_categorical_features, get_numeric_features, reduce_mem_usage, elo_save_feature, impute_feature\n",
    "try:\n",
    "    if not logger:\n",
    "        logger=logger_func()\n",
    "except NameError:\n",
    "    logger=logger_func()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#========================================================================\n",
    "# Keras \n",
    "# Corporación Favorita Grocery Sales Forecasting\n",
    "from sklearn.linear_model import Ridge\n",
    "#========================================================================\n",
    "\n",
    "\n",
    "#========================================================================\n",
    "# Args\n",
    "out_part = ['', 'part', 'all'][0]\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_active_month', 'index', 'personal_term', 'no_out_flg', 'clf_pred']\n",
    "stack_name='ridge'\n",
    "submit = pd.read_csv('../input/sample_submission.csv')\n",
    "model_type='ridge'\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
    "seed = 328\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Path List \n",
    "def get_dataset(base, model_no):\n",
    "    win_path = f'../features/4_winner/*.gz'\n",
    "    #  win_path = f'../features/1_first_valid/*.gz'\n",
    "    model_path_list = [f'../model/LB3670_70leaves_colsam0322/*.gz', '../model/E2_lift_set/*.gz', '../model/E3_PCA_set/*.gz', '../model/E4_mix_set/*.gz', '../model/LB3669LB_70leaves/*.gz'][0]\n",
    "    model_path = model_path_list[model_no]\n",
    "    tmp_path_list = glob.glob(f'../features/5_tmp/*.gz') + glob.glob(f'../features/0_exp/*.gz')\n",
    "    #  tmp_path_list = glob.glob(f'../features/5_tmp/*.gz')\n",
    "    win_path_list = glob.glob(model_path) + glob.glob(win_path) + tmp_path_list\n",
    "    #  win_path_list = glob.glob(model_path) + tmp_path_list\n",
    "    #  win_path_list = glob.glob(model_path) + glob.glob(win_path)\n",
    "    win_path_list = glob.glob(win_path) + tmp_path_list\n",
    "    #  win_path_list = glob.glob(model_path) + glob.glob(win_path) + tmp_path_list\n",
    "    #========================================================================\n",
    "    \n",
    "    feature_list = utils.parallel_load_data(path_list=win_path_list)\n",
    "    df_feat = pd.concat(feature_list, axis=1)\n",
    "    base = pd.concat([base, df_feat], axis=1)\n",
    "    \n",
    "    for col in base.columns:\n",
    "        if col in ignore_list:\n",
    "            continue\n",
    "        base[col] = utils.impute_feature(df=base, col=col)\n",
    "    \n",
    "    train = base[~base[target].isnull()]\n",
    "    test = base[base[target].isnull()]\n",
    "    \n",
    "    return train, test\n",
    "model_no = 0\n",
    "base = utils.read_pkl_gzip('../input/base_type_group.gz')[[key, target]]\n",
    "base_train, base_test = get_dataset(base, model_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Make Dataset \n",
    "pred_col = 'prediction'\n",
    "valid_type = 'ods'\n",
    "set_type = 'all'\n",
    "#========================================================================\n",
    "    \n",
    "#========================================================================\n",
    "# CVの準備\n",
    "fold_seed = 328\n",
    "fold = 6\n",
    "\n",
    "#========================================================================\n",
    "# Dataset\n",
    "submit = pd.read_csv('../input/sample_submission.csv').set_index(key)\n",
    "result_list = []\n",
    "score_list = []\n",
    "feat_list = [col for col in base_train.columns if col not in ignore_list]\n",
    "use_cols = []\n",
    "feim = pd.read_csv('../valid/0224_215_valid_lgb_lr0.01_272feats_10seed_70leaves_iter1161_OUT0_CV3.6176129805843_LB.csv')\n",
    "top100 = feim['feature'].values[:100]\n",
    "for col in top100:\n",
    "    for feat in feat_list:\n",
    "        if feat.count\n",
    "#========================================================================\n",
    "\n",
    "if debug:\n",
    "    use_cols = use_cols[:10]\n",
    "    train = base_train.head(10000)\n",
    "    test = base_test.head(1000)\n",
    "    Y = train[target]\n",
    "else:\n",
    "    train = base_train.copy()\n",
    "    test = base_test.copy()\n",
    "    Y = train[target]\n",
    "    \n",
    "#========================================================================\n",
    "# NN Model Setting \n",
    "params = {}\n",
    "params['n_jobs']=-1\n",
    "params['n_neighbors']=350\n",
    "# params['metric']='rmse'\n",
    "model = KNeighborsRegressor(**params)\n",
    "\n",
    "kfold = utils.read_pkl_gzip(f'../input/kfold_ods_equal_seed328.gz')\n",
    "\n",
    "#========================================================================\n",
    "# Preset\n",
    "test_pred = np.zeros(len(test))\n",
    "result_list = []\n",
    "score_list = []\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# Train & Prediction Start\n",
    "for fold_no, (trn_idx, val_idx) in enumerate(zip(*kfold)):\n",
    "        \n",
    "    if key not in train.columns:\n",
    "        train = train.reset_index()\n",
    "        test = test.reset_index() \n",
    "         \n",
    "    #========================================================================\n",
    "    # Make Dataset\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(pd.concat([train[use_cols], test[use_cols]]))\n",
    "    x_test = scaler.transform(test[use_cols])\n",
    "\n",
    "    X_train, y_train = train.loc[train[key].isin(trn_idx), :][use_cols], Y.loc[train[key].isin(trn_idx)]\n",
    "    X_val, y_val = train.loc[train[key].isin(val_idx), :][use_cols], Y.loc[train[key].isin(val_idx)]\n",
    "    \n",
    "    X_train[:] = scaler.transform(X_train)\n",
    "    X_val[:] = scaler.transform(X_val)\n",
    "    X_train = X_train.as_matrix()\n",
    "    X_val = X_val.as_matrix()\n",
    "\n",
    "    print(f\"Train: {X_train.shape} | Valid: {X_val.shape} | Test: {x_test.shape}\")\n",
    "    #========================================================================\n",
    "    \n",
    "    # Fitting\n",
    "      print(X_train[:5])\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction\n",
    "    y_pred = model.predict(X_val)\n",
    "    test_pred += model.predict(x_test)\n",
    "    \n",
    "    df_pred = train.loc[train[key].isin(val_idx), :][[key, target]].copy()\n",
    "    df_pred['prediction'] = y_pred\n",
    "    result_list.append(df_pred)\n",
    "    \n",
    "    # Scoring\n",
    "    score = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    print(f'RMSE: {score}')\n",
    "    score_list.append(score)\n",
    "    #========================================================================\n",
    "\n",
    "cv_score = np.mean(score_list)\n",
    "\n",
    "#========================================================================\n",
    "# Stacking\n",
    "test_pred /= fold_no+1\n",
    "test['prediction'] = test_pred\n",
    "stack_test = test[[key, 'prediction']]\n",
    "\n",
    "result_list.append(stack_test)\n",
    "df_pred = pd.concat(result_list, axis=0, ignore_index=True).drop(target, axis=1)\n",
    "if key not in base:\n",
    "    base.reset_index(inplace=True)\n",
    "df_pred = base[[key, target]].merge(df_pred, how='inner', on=key)\n",
    "\n",
    "print(f'''\n",
    "# =====================================================================\n",
    "#  SCORE AVG: {cv_score}\n",
    "# =====================================================================''')\n",
    "\n",
    "best_score = 100\n",
    "\n",
    "best_score = cv_score\n",
    "best_score_list = use_cols\n",
    "\n",
    "#========================================================================\n",
    "# Save Stack\n",
    "utils.to_pkl_gzip(path=f\"../stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8304, 10) | Valid: (1696, 10) | Test: (1000, 10)\n",
      "RMSE: 3.9980054757912042\n",
      "Train: (8267, 10) | Valid: (1733, 10) | Test: (1000, 10)\n",
      "RMSE: 3.9309646274222403\n",
      "Train: (8397, 10) | Valid: (1603, 10) | Test: (1000, 10)\n",
      "RMSE: 3.450177230263311\n",
      "Train: (8305, 10) | Valid: (1695, 10) | Test: (1000, 10)\n",
      "RMSE: 3.6238768113209625\n",
      "Train: (8344, 10) | Valid: (1656, 10) | Test: (1000, 10)\n",
      "RMSE: 3.5971899498366158\n",
      "Train: (8383, 10) | Valid: (1617, 10) | Test: (1000, 10)\n",
      "RMSE: 3.628385773804166\n",
      "\n",
      "#========================================================================\n",
      "# CV SCORE AVG: 3.7047666447397494\n",
      "#========================================================================\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "k/{start_time[4:12]}_stack_{model_type}_set-{set_type}_valid-{valid_type}-seed{fold_seed}_lgb{len(lgb_list)}_NN{is_nn}_ridge{is_rid}_ext{is_ext}_rmf{is_rmf}_OUT{str(out_score)[:7]}_CV{cv_score}_LB\" , obj=df_pred[[key, 'prediction']])\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 30,  60,  90, 120, 150, 180, 210])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(30, 211, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
