{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import datetime, itertools, zipfile, os, time, psutil, gc\n",
    "from datetime import date, timedelta\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys\n",
    "sys.path.append('../input/my-temp-files/')\n",
    "import alml\n",
    "\n",
    "RS = alml.rs(0)\n",
    "\n",
    "SUBMIT = False\n",
    "SUBMIT = True\n",
    "\n",
    "ROUNDS = 1000\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "\tscore = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\treturn score\n",
    "\n",
    "NROWS = None\n",
    "NROWS_VAL = None\n",
    "if not SUBMIT:\n",
    "\tNROWS = 30000 #None \n",
    "\tNROWS_VAL = 20000\n",
    "\n",
    "MODELS = ['lgb']\n",
    "#MODELS = ['lgb','rfr','lnr','lasso','ridge','abr','etr','gbr']\n",
    "\n",
    "MODELS2 = ['lgb']\n",
    "LEVEL = 1 \n",
    "\n",
    "BAGS = 0 if SUBMIT else 0\n",
    "FOLDS = 5 if SUBMIT else 5\n",
    "EARLY_STOPPING = 100 #100\n",
    "\n",
    "if LEVEL == 2:\n",
    "\tFOLDS = 0\n",
    "\tMODELS = MODELS2\n",
    "\n",
    "# XGB\n",
    "params1 = {}\n",
    "params1['objective'] = 'binary:logistic'\t\t#'binary:logistic'\n",
    "params1['eval_metric'] = 'auc'\t\t\t#'logloss'\n",
    "params1['eta'] = 0.04\n",
    "params1['max_depth'] = 7\n",
    "params1['silent'] = 1\n",
    "params1['subsample'] = 0.8\n",
    "params1['subsample_bytree'] = 0.7\n",
    "#params1['subsample_bylevel'] = 0.7\n",
    "params1['num_rounds'] = 30 #100\n",
    "\n",
    "#LightGBM\n",
    "params2 = {}\n",
    "params2['objective'] = 'regression' #'regression'\n",
    "params2['metric'] = 'rmse'\t\t#'multi_logloss', 'binary_logloss'\n",
    "params2['boosting'] = 'gbdt' #'gbdt'\n",
    "params2['learning_rate'] = 0.05 #0.2\n",
    "params2['verbose'] = -1\n",
    "#params2['num_class'] = 6\n",
    "params2['num_leaves'] = 15 # 1:2 2:4 3:8 4:16 5:32 6:64 7:128 8:256\n",
    "params2['bagging_fraction'] = 0.8\n",
    "params2['bagging_freq'] = 1\n",
    "params2['bagging_seed'] = RS\n",
    "params2['feature_fraction'] = 0.7\n",
    "#params2['colsample_bytree'] = 0.05\n",
    "params2['feature_fraction_seed'] = RS\n",
    "#params2['scale_pos_weight'] = 10\n",
    "#params2['max_bin'] = 300\n",
    "params2['max_depth'] = 5 #6 #s-1\n",
    "params2['min_child_samples'] = 90\n",
    "#params2['min_gain_to_split'] = 0.5\n",
    "params2['reg_lambda'] = 2\n",
    "params2['reg_alpha'] = 0.4\n",
    "params2['num_rounds'] = ROUNDS\n",
    "#params2['tree_learner'] = 'voting'\n",
    "params2['feature_name'] = 'auto'\n",
    "#params2['categorical_feature'] = [\"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\", \"param_1\", \"param_2\", \"param_3\"]\n",
    "#params2['histogram_pool_size'] = 8000\n",
    "\n",
    "params3 = {}\n",
    "params3['n_jobs'] = 2\n",
    "params3['n_estimators'] = 100\n",
    "params3['max_depth'] = 5\n",
    "params3['verbose'] = 0\n",
    "params3['learning_rate'] = 0.1\n",
    "\n",
    "if LEVEL == 2:\n",
    "\t#XGB\n",
    "\tROUNDS = 980\n",
    "\n",
    "CONFIG = []\n",
    "if 'lgb' in MODELS:\n",
    "\tCONFIG.append({'model': 'lgb','params': params2,})\n",
    "if 'etr' in MODELS:\n",
    "\tCONFIG.append({'model': 'etr','params': params3,})\n",
    "if 'abr' in MODELS:\n",
    "\tCONFIG.append({'model': 'abr','params': params3,})\n",
    "if 'gbr' in MODELS:\n",
    "\tCONFIG.append({'model': 'gbr','params': params3,})\n",
    "if 'xgb' in MODELS:\n",
    "\tCONFIG.append({'model': 'xgb','params': params1,})\n",
    "if 'rfr' in MODELS:\n",
    "\tCONFIG.append({'model': 'rfr','params': params3,})\n",
    "if 'lasso' in MODELS:\n",
    "\tCONFIG.append({'model': 'lasso','params': params3,})\n",
    "if 'ridge' in MODELS:\n",
    "\tCONFIG.append({'model': 'ridge','params': params3,})\n",
    "if 'lnr' in MODELS:\n",
    "\tCONFIG.append({'model': 'lnr','params': params3,})\n",
    "\n",
    "print(\"Started {}\".format(\"SUBMIT\" if SUBMIT else \"TEST\"))\n",
    "print(psutil.virtual_memory())\n",
    "target = 'target'\n",
    "scorefn = rmse\n",
    "feats_not_to_use = ['card_id', target, 'first_active_month', 'fold_id','merchant_id']\n",
    "cat_vars = [] \n",
    "\n",
    "tr = pd.read_csv('../input/elo-merchant-category-recommendation/train.csv') [['card_id','target']]\n",
    "print('Train  : shape=',tr.shape)\n",
    "\n",
    "trm = tr['target'].mean()\n",
    "trtmp = tr[['target']].copy()\n",
    "trtmp['preds'] = trm\n",
    "scoremean = scorefn(trtmp['target'], trtmp['preds'])\n",
    "print('Score mean:',scoremean)\n",
    "del trtmp, trm\n",
    "\n",
    "#, usecols=['card_id','merchant_id','purchase_date','purchase_amount','installments','month_lag']\n",
    "df = pd.read_csv('../input/elo-merchant-category-recommendation/historical_transactions.csv', nrows=NROWS, parse_dates=['purchase_date']).sample(frac=0.8)\n",
    "print('History: shape=',df.shape)\n",
    "print(df.dtypes)\n",
    "\n",
    "df = df.sort_values(['card_id','purchase_date'])\n",
    "\n",
    "df['next_card_id'] = df['card_id'].shift(-1)\n",
    "df['prev_card_id'] = df['card_id'].shift(1)\n",
    "df['next_date'] = df['purchase_date'].shift(-1)\n",
    "df['prev_date'] = df['purchase_date'].shift(1)\n",
    "df['next_amount'] = df['purchase_amount'].shift(-1)\n",
    "df['prev_amount'] = df['purchase_amount'].shift(1)\n",
    "print('a')\n",
    "df['next_merchant_id'] = df['merchant_id'].shift(-1)\n",
    "df['prev_merchant_id'] = df['merchant_id'].shift(1)\n",
    "df['next_installments'] = df['installments'].shift(-1)\n",
    "df['prev_installments'] = df['installments'].shift(1)\n",
    "df['next_category_2'] = df['category_2'].shift(-1)\n",
    "df['prev_category_2'] = df['category_2'].shift(1)\n",
    "print('b')\n",
    "df['next_category_3'] = df['category_3'].shift(-1)\n",
    "df['prev_category_3'] = df['category_3'].shift(1)\n",
    "df.loc[df['next_card_id'] != df['card_id'], 'next_date'] = np.nan\n",
    "df.loc[df['card_id'] != df['prev_card_id'], 'prev_date'] = np.nan\n",
    "df.loc[df['next_card_id'] != df['card_id'], 'next_amount'] = np.nan\n",
    "df.loc[df['card_id'] != df['prev_card_id'], 'prev_amount'] = np.nan\n",
    "df.loc[df['next_card_id'] != df['card_id'], 'next_merchant_id'] = np.nan\n",
    "df.loc[df['card_id'] != df['prev_card_id'], 'prev_merchant_id'] = np.nan\n",
    "df.loc[df['next_card_id'] != df['card_id'], 'next_installments'] = np.nan\n",
    "df.loc[df['card_id'] != df['prev_card_id'], 'prev_installments'] = np.nan\n",
    "df.loc[df['next_card_id'] != df['card_id'], 'next_category_2'] = np.nan\n",
    "df.loc[df['card_id'] != df['prev_card_id'], 'prev_category_2'] = np.nan\n",
    "df.loc[df['next_card_id'] != df['card_id'], 'next_category_3'] = np.nan\n",
    "df.loc[df['card_id'] != df['prev_card_id'], 'prev_category_3'] = np.nan\n",
    "\n",
    "df['next_merchant_same'] = (df['next_merchant_id'] == df['merchant_id']).astype(int)\n",
    "#df['prev_merchant_same'] = (df['prev_merchant_id'] == df['merchant_id']).astype(int)\n",
    "df.drop(['next_merchant_id','prev_merchant_id','city_id','merchant_category_id','state_id','subsector_id'], axis=1, inplace=True)\n",
    "print('c')\n",
    "\n",
    "df['days_to_next'] = (df['next_date'] - df['purchase_date']).dt.days\n",
    "df['days_from_prev'] = (df['purchase_date'] - df['prev_date']).dt.days\n",
    "df['hours_to_next'] = np.round((df['next_date'] - df['purchase_date']).dt.seconds * 60 * 60)\n",
    "df['hours_from_prev'] = np.round((df['purchase_date'] - df['prev_date']).dt.seconds * 60 * 60)\n",
    "print('d')\n",
    "\n",
    "df['amount_vs_next'] = df['purchase_amount'] / df['next_amount']\n",
    "#df['amount_vs_prev'] = df['purchase_amount'] / df['prev_amount']\n",
    "df['installments_vs_next'] = df['installments'] / (df['next_installments'] + 0.001)\n",
    "df['installments_vs_prev'] = df['installments'] / (df['prev_installments'] + 0.001)\n",
    "print('e')\n",
    "\n",
    "df = df[['card_id','merchant_id','purchase_date','purchase_amount','installments','month_lag','days_to_next','days_from_prev','hours_to_next'\\\n",
    "\t\t,'hours_from_prev','next_merchant_same','authorized_flag','category_1','category_2','category_3'\\\n",
    "\t\t,'next_installments','prev_installments','next_category_2','prev_category_2','next_category_3','prev_category_3'\\\n",
    "\t\t,'amount_vs_next','installments_vs_next','installments_vs_prev']]\n",
    "#,'amount_vs_prev','prev_merchant_same'\n",
    "print(df.head(100).tail(50))\n",
    "\n",
    "df = alml.proc_reduce_mem(df)\n",
    "\n",
    "#df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\n",
    "df['category_2'] = df['category_2'].astype(str)\n",
    "\n",
    "df['date_uptonow'] = (pd.Timestamp('2018-12-06') - df['purchase_date']).dt.days\n",
    "df['month_uptonow'] = ((pd.Timestamp('2018-12-06') - df['purchase_date']).dt.days)//30\n",
    "df['date_diff'] = df['date_uptonow'] + df['month_lag']*30\t\n",
    "#df['month_diff'] = df['month_uptonow'] + df['month_lag']\t\n",
    "\n",
    "\n",
    "df['year'] = df['purchase_date'].dt.year\n",
    "df['weekofyear'] = df['purchase_date'].dt.weekofyear\n",
    "df['month'] = df['purchase_date'].dt.month\n",
    "#df['dayofweek'] = df['purchase_date'].dt.dayofweek\n",
    "#df['weekend'] = (df.purchase_date.dt.weekday >=5).astype(int)\n",
    "#df['hour'] = df['purchase_date'].dt.hour\n",
    "df['purchase_date'] = df['purchase_date'].astype(np.int64) * 1e-9\n",
    "\n",
    "df = alml.proc_reduce_mem(df)\n",
    "\n",
    "df = df.merge(tr, how='left', on='card_id')\n",
    "print('Merged : shape=',df.shape)\n",
    "\n",
    "def procfeats(df):\n",
    "\n",
    "\tdf['installments_vs_month_lag'] = df['installments'] / (df['month_lag'] + 0.001)\n",
    "\treturn df\n",
    "\t\n",
    "df = procfeats(df)\n",
    "\n",
    "print(df.dtypes)\n",
    "cat_vars = [f for f in df.columns if df[f].dtype == 'object' and f not in feats_not_to_use]\n",
    "print('Categorical:',cat_vars)\n",
    "\n",
    "for col in cat_vars:\n",
    "\tlbl = LabelEncoder()\n",
    "\tdf[col] = lbl.fit_transform(df[col].values.astype('str'))\n",
    "\n",
    "print(df.head())\n",
    "\t\n",
    "x_train = df[~df['target'].isnull()].reset_index(drop=True)\n",
    "x_test = df[df['target'].isnull()].reset_index(drop=True)\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "use = [x for x in x_train.columns.values if x not in feats_not_to_use]\n",
    "cid = x_train['card_id'].values\n",
    "train_y = x_train[target].values\n",
    "#x_train = x_train[use]\n",
    "cid_test = x_test['card_id'].values\n",
    "x_test = x_test[use]\n",
    "\n",
    "print('Training on',x_train.shape, train_y.shape ,'testing on',x_test.shape)\t\n",
    "params2['categorical_feature'] = [x for x in cat_vars if x in use]\n",
    "print('Categorical:',params2['categorical_feature'])\t\n",
    "\n",
    "gc.collect()\n",
    "print(psutil.virtual_memory())\n",
    "if 0:\n",
    "\talml.features_eliminator(x_train, train_y, CONFIG[0]['params'], seed=RS, bags=2, score_fn=scorefn, logname='features_eliminator.txt')\n",
    "\tprint('elimination done')\n",
    "\texit()\n",
    "\t\n",
    "if 1:\t\n",
    "\tfoldsdf = pd.read_csv('../input/my-temp-files/train_folds_1.csv')\n",
    "\tprint(foldsdf.head())\n",
    "\tprint(foldsdf.shape)\n",
    "\tprint(x_train.shape)\n",
    "\tx_train = x_train.merge(foldsdf, how='left', on='card_id')\n",
    "\tprint(x_train.shape)\n",
    "\tpreds_test = None\n",
    "\tpreds_train = None\n",
    "\tfor ff in range(FOLDS):\n",
    "\t\tparams2['num_rounds'] = ROUNDS\n",
    "\n",
    "\t\tprint('FOLD:', ff)\n",
    "\t\tfold_train = x_train[x_train['fold_id'] != ff].copy()\n",
    "\t\tfold_cv = x_train[x_train['fold_id'] == ff].copy()\n",
    "\t\tfold_train_y = fold_train[target].values\n",
    "\t\tfold_cv_y = fold_cv[target].values\n",
    "\t\tfold_cv_ids = fold_cv['card_id'].values\n",
    "\t\t\n",
    "\t\tfold_train = fold_train[use]\n",
    "\t\tfold_cv = fold_cv[use]\n",
    "\t\t\n",
    "\t\tpreds, preds_cv, models, preds_cv_cols = alml.ml(fold_train, fold_train_y, x_test, CONFIG, None, True, BAGS, 0, score_fn=scorefn, stratify=True, early_stopping=EARLY_STOPPING, Xval=fold_cv, yval=fold_cv_y)\n",
    "\t\tpreds_test = preds if preds_test is None else preds_test + preds\n",
    "\t\t\n",
    "\t\tcvd = pd.DataFrame({'card_id':fold_cv_ids, 'preds':preds_cv, 'target':fold_cv_y})\n",
    "\t\tprint(cvd.head())\n",
    "\t\tprint(cvd.shape)\n",
    "\t\tprint('Score:',scorefn(cvd['target'], cvd['preds']))\n",
    "\t\tpreds_train = cvd if preds_train is None else pd.concat([preds_train, cvd])\n",
    "\tpreds = preds_test / FOLDS\n",
    "else:\n",
    "\tpreds, preds_cv, models, preds_cv_cols = alml.ml(x_train, train_y, x_test, CONFIG, None, True, BAGS, FOLDS, score_fn=scorefn, stratify=False, early_stopping=EARLY_STOPPING)\n",
    "\t\n",
    "del x_train\n",
    "gc.collect()\n",
    "\t\n",
    "df_train = preds_train\n",
    "print('Score full on',df_train.shape[0],'entries',rmse(df_train[target],df_train['preds']))\n",
    "dfg = df_train.groupby('card_id').mean().reset_index()\n",
    "print('Score grouped mean on',dfg.shape[0],'entries',rmse(dfg[target],dfg['preds']))\n",
    "dfg = df_train.groupby('card_id').min().reset_index()\n",
    "print('Score grouped min on',dfg.shape[0],'entries',rmse(dfg[target],dfg['preds']))\n",
    "dfg = df_train.groupby('card_id').max().reset_index()\n",
    "print('Score grouped max on',dfg.shape[0],'entries',rmse(dfg[target],dfg['preds']))\n",
    "print('Score mean baseline:',scoremean)\n",
    "\n",
    "print(df_train.describe())\n",
    "\n",
    "print('\\n----- biggest errors')\n",
    "df_train['error'] = (df_train['preds'] - df_train[target]) ** 2\n",
    "print(df_train.sort_values('error', ascending=False).head(30))\n",
    "\n",
    "print('\\n----- lowest preds')\n",
    "print(df_train.sort_values('preds', ascending=True).head(30))\n",
    "\n",
    "now = str(datetime.datetime.now().strftime(\"%m%d%H%M\"))\n",
    "tf = 's1_preds_%s.' % now\n",
    "\t\n",
    "if not SUBMIT:\n",
    "\tsavename = 'cv_sub_last.csv'\n",
    "\tprint('\\nPreparing to save CV',df_train.shape)\n",
    "\tprint(df_train.head())\n",
    "\tdf_train.to_csv(savename, index=False)\n",
    "\tprint('CV saved to',savename)\n",
    "\n",
    "if SUBMIT:\n",
    "\tsavename = 'cv_' + tf + 'csv'\n",
    "\tprint('\\nPreparing to save CV',df_train.shape)\n",
    "\tprint(df_train.head())\n",
    "\tdf_train.to_csv(savename, index=False)\n",
    "\tprint('CV saved to',savename)\n",
    "\n",
    "\tprint('\\nTest predictions preparing...')\n",
    "\tsavename = 'test_' + tf + 'csv'\n",
    "\tcvd = pd.DataFrame({'card_id':cid_test, 'preds':preds})\n",
    "\tprint(cvd.head())\n",
    "\tprint(cvd.shape)\n",
    "\tprint(cvd.describe())\n",
    "\tcvd.to_csv(savename, index=False)\n",
    "\tprint('Test saved to',savename)\n",
    "\t\n",
    "print(\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
