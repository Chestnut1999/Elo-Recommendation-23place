{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# hyper parameters\n",
    "num_epochs = 5000\n",
    "learning_rate = 1e-2\n",
    "early_stopping_rounds = 5\n",
    "\n",
    "# linear regression model\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        y_train = np.expand_dims(y_train, axis=1)\n",
    "        inputs = torch.from_numpy(X_train).float()\n",
    "        targets = torch.from_numpy(y_train).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = torch.sqrt(criterion(outputs, targets))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def valid(self, X_val, y_val):\n",
    "        y_val = np.expand_dims(y_val, axis=1)\n",
    "        inputs = torch.from_numpy(X_val).float()\n",
    "        targets = torch.from_numpy(y_val).float()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        val_loss = criterion(outputs, targets)\n",
    "\n",
    "        return val_loss.item()\n",
    "\n",
    "model = LinearRegression(input_size=len(use_cols), output_size=1)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#========================================================================\n",
    "# Result Box\n",
    "model_list = []\n",
    "result_list = []\n",
    "score_list = []\n",
    "val_pred_list = []\n",
    "test_pred = np.zeros(len(test))\n",
    "x_test = x_test.astype(np.float32)\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# Train & Prediction Start\n",
    "\n",
    "for fold_no, (trn_idx, val_idx) in enumerate(zip(*kfold)):\n",
    "\n",
    "    #========================================================================\n",
    "    # Make Dataset\n",
    "    \n",
    "    X_train, y_train = train.loc[train[key].isin(trn_idx), :][use_cols], Y.loc[train[key].isin(trn_idx)].values\n",
    "    X_val, y_val = train.loc[train[key].isin(val_idx), :][use_cols], Y.loc[train[key].isin(val_idx)].values\n",
    "    \n",
    "    X_train[:] = scaler.transform(X_train)\n",
    "    X_val[:] = scaler.transform(X_val)\n",
    "    X_train = X_train.as_matrix().astype(np.float32)\n",
    "    X_val = X_val.as_matrix().astype(np.float32)\n",
    "    \n",
    "    #========================================================================\n",
    "    # Fitting\n",
    "    loss_list = []\n",
    "    val_loss_list = []\n",
    "    best_loss = 10**10\n",
    "    early_stop_cnt = 0\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        loss = model.train(X_train, y_train)\n",
    "        val_loss = model.valid(X_val, y_val)\n",
    "        if best_loss>val_loss:\n",
    "            best_loss = val_loss\n",
    "        else:\n",
    "            early_stop_cnt+=1\n",
    "\n",
    "        if epoch % 200 == 0:\n",
    "            print('epoch %d, loss: %.4f val_loss: %.4f' % (epoch, loss, val_loss))\n",
    "\n",
    "        loss_list.append(loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "        if early_stop_cnt>early_stopping_rounds:\n",
    "            break\n",
    "    #========================================================================\n",
    "    \n",
    "    # Prediction\n",
    "    if is_oof:\n",
    "        val_id_list = list(set(train_ids) - set(trn_idx))\n",
    "        X_val = train.loc[train[key].isin(val_id_list), :][use_cols]\n",
    "        y_val = Y.loc[train[key].isin(val_id_list)]\n",
    "        y_pred = model(torch.from_numpy(X_val)).detach().numpy()\n",
    "        tmp_val = train.loc[train[key].isin(val_id_list), :][[key, target]].set_index(key)\n",
    "        tmp_val['prediction'] = y_pred\n",
    "        df_stack['pred_{fold_no}'] = tmp_val['prediction']\n",
    "        del tmp_val\n",
    "        gc.collect()\n",
    "    else:\n",
    "        y_pred = model(torch.from_numpy(X_val)).detach().numpy()\n",
    "    out_cnt = (y_pred==np.inf).sum()+(y_pred==-np.inf).sum()+(y_pred!=y_pred).sum()\n",
    "\n",
    "    if out_cnt>0:\n",
    "        print(\"Exist Inf or NaN\")\n",
    "        sys.exit()\n",
    "    \n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], )\n",
    "    tmp_pred = model(torch.from_numpy(x_test)).detach().numpy()\n",
    "    test_pred += tmp_pred.reshape(tmp_pred.shape[0], )\n",
    "    test['prediction'] = test_pred\n",
    "    test = test[[key, 'prediction']]\n",
    "    \n",
    "    if is_plus:\n",
    "        y_val += (y_min-1)\n",
    "        y_pred += (y_min-1)\n",
    "        test_pred += (y_min-1)\n",
    "#     model_list.append(model)\n",
    "    \n",
    "    # Stack Prediction\n",
    "    df_pred = train.loc[train[key].isin(val_idx), :][[key, target]].copy()\n",
    "    df_pred['prediction'] = y_pred\n",
    "    result_list.append(df_pred)\n",
    "    \n",
    "    # Scoring\n",
    "    if out_part=='clf':\n",
    "        score = roc_auc_score(y_val, y_pred)\n",
    "        print(f'RMSE: {score} | SUM ERROR: {err.sum()}')\n",
    "    else:\n",
    "        err = (y_val - y_pred)\n",
    "        score = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        print(f'RMSE: {score} | SUM ERROR: {err.sum()}')\n",
    "    score_list.append(score)\n",
    "    #========================================================================\n",
    "\n",
    "cv_score = np.mean(score_list)\n",
    "logger.info(f'''\n",
    "#========================================================================\n",
    "# CV SCORE AVG: {cv_score}\n",
    "#========================================================================''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 1e-2\n",
    "epochs = 200\n",
    "early_stopping_rounds = 50\n",
    "best_loss = 10**10\n",
    "early_stop_cnt = 0\n",
    "\n",
    "# Building model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_cols, hidden, output):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = nn.Linear(input_cols, 192)\n",
    "        self.l2 = nn.Linear(192 , 128)\n",
    "        self.l3 = nn.Linear(128 , 64)\n",
    "        self.l4 = nn.Linear(64 , 32)\n",
    "        self.l5 = nn.Linear(32 , 16)\n",
    "        self.l6 = nn.Linear(16, output)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.l1(x))\n",
    "        out = F.relu(self.l2(out))\n",
    "        out = F.relu(self.l3(out))\n",
    "        out = F.relu(self.l4(out))\n",
    "        out = F.relu(self.l5(out))\n",
    "        out = self.l6(out)\n",
    "        return out        \n",
    "    \n",
    "    \n",
    "# Trainig\n",
    "model = Model(input_cols=len(use_cols), hidden=64, output=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def print_(loss):\n",
    "    print (\"The loss calculated: \", loss)\n",
    "    \n",
    "    # Make Dataset\n",
    "X_train, y_train = train.loc[train[key].isin(trn_idx), :][use_cols], Y.loc[train[key].isin(trn_idx)].values\n",
    "X_val, y_val = train.loc[train[key].isin(val_idx), :][use_cols], Y.loc[train[key].isin(val_idx)].values\n",
    "\n",
    "X_train[:] = scaler.transform(X_train)\n",
    "X_val[:] = scaler.transform(X_val)\n",
    "X_train = X_train.as_matrix()\n",
    "X_val = X_val.as_matrix()\n",
    "    \n",
    "# Not using dataloader\n",
    "X_train = Variable(torch.from_numpy(X_train)).float()\n",
    "y_train = Variable(torch.from_numpy(y_train)).long()\n",
    "for epoch in range(1, epochs+1):\n",
    "    if epoch%10==0:\n",
    "        print (\"Epoch #\",epoch)\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    if best_loss>loss.item():\n",
    "        best_loss = loss\n",
    "    else:\n",
    "        early_stop_cnt+=1\n",
    "        \n",
    "    print_(loss.item())\n",
    "    if early_stop_cnt>early_stopping_rounds:\n",
    "        break\n",
    "    \n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward() # Gradients\n",
    "    optimizer.step() # Update\n",
    "    \n",
    "# Prediction\n",
    "X_val = Variable(torch.from_numpy(X_val)).float()\n",
    "y_pred = model(X_val)\n",
    "y_pred = torch.max(y_pred,1)[1]\n",
    "# y_pred = y_pred.detach().numpy()\n",
    "score = roc_auc_score(y_val, y_pred)\n",
    "print(f'AUC: {score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
