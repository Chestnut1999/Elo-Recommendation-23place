{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFM\n",
    "FFM用のDatasetを作成し、kerasで実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-12 17:19:56,465 utils 366 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import gc\n",
    "import os\n",
    "\n",
    "#========================================================================\n",
    "# Args\n",
    "#========================================================================\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_active_month']\n",
    "\n",
    "HOME = os.path.expanduser('~')\n",
    "\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "import utils\n",
    "from preprocessing import get_ordinal_mapping, get_dummies\n",
    "from utils import logger_func\n",
    "try:\n",
    "    if not logger:\n",
    "        logger=logger_func()\n",
    "except NameError:\n",
    "    logger=logger_func()\n",
    "\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 40.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "      <th>110_ker_auth_category_2_4_0_mean</th>\n",
       "      <th>123_mai_diff_hist_new_main_city_ratio@</th>\n",
       "      <th>110_ker_auth_category_3_B_mean</th>\n",
       "      <th>111_ker_hist_month_lag_max@</th>\n",
       "      <th>111_ker_feature_1@</th>\n",
       "      <th>114_mer_merchant_id_M_ID_ef87dd1879@</th>\n",
       "      <th>114_mer_merchant_id_M_ID_8fadd601d2@</th>\n",
       "      <th>153_nlc_auth1_category_3_null_cnt@</th>\n",
       "      <th>115_out_state_id_24@</th>\n",
       "      <th>111_ker_new_hist_month_nunique@</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.174286</td>\n",
       "      <td>0.802360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.093023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.168546</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target  110_ker_auth_category_2_4_0_mean  \\\n",
       "0  C_ID_92a2005557 -0.820283                          0.000000   \n",
       "1  C_ID_3d0044924f  0.392913                          0.000000   \n",
       "2  C_ID_d639edf6cd  0.688056                          0.000000   \n",
       "3  C_ID_186d6a6901  0.142495                          0.688312   \n",
       "4  C_ID_cdbd2c0db2 -0.159749                          0.820312   \n",
       "\n",
       "   123_mai_diff_hist_new_main_city_ratio@  110_ker_auth_category_3_B_mean  \\\n",
       "0                                0.127759                        0.000000   \n",
       "1                               -0.174286                        0.802360   \n",
       "2                               -0.093023                        0.000000   \n",
       "3                               -0.181818                        0.883117   \n",
       "4                                0.168546                        0.968750   \n",
       "\n",
       "   111_ker_hist_month_lag_max@  111_ker_feature_1@  \\\n",
       "0                            0            0.013145   \n",
       "1                            0            0.010712   \n",
       "2                            0            0.010610   \n",
       "3                            0            0.010712   \n",
       "4                            0            0.008058   \n",
       "\n",
       "   114_mer_merchant_id_M_ID_ef87dd1879@  114_mer_merchant_id_M_ID_8fadd601d2@  \\\n",
       "0                                   0.0                                   0.0   \n",
       "1                                   0.0                                   0.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                                   0.0                                   0.0   \n",
       "4                                   0.0                                   0.0   \n",
       "\n",
       "   153_nlc_auth1_category_3_null_cnt@  115_out_state_id_24@  \\\n",
       "0                                 0.0                   0.0   \n",
       "1                                 2.0                   0.0   \n",
       "2                                 0.0                   0.0   \n",
       "3                                 2.0                   0.0   \n",
       "4                                 0.0                   0.0   \n",
       "\n",
       "   111_ker_new_hist_month_nunique@  \n",
       "0                              2.0  \n",
       "1                              2.0  \n",
       "2                              1.0  \n",
       "3                              2.0  \n",
       "4                              2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Data Load\n",
    "base = utils.read_df_pkl('../input/base*')\n",
    "win_path = f'../features/4_winner/*.gz'\n",
    "win_path_list = glob.glob(win_path)\n",
    "train_path_list = []\n",
    "test_path_list = []\n",
    "for path in win_path_list[:20]:\n",
    "    if path.count('train'):\n",
    "        train_path_list.append(path)\n",
    "    elif path.count('test'):\n",
    "        test_path_list.append(path)\n",
    "\n",
    "base_train = base[~base[target].isnull()].reset_index(drop=True)\n",
    "base_test = base[base[target].isnull()].reset_index(drop=True)\n",
    "train_feature_list = utils.parallel_load_data(path_list=train_path_list)\n",
    "test_feature_list = utils.parallel_load_data(path_list=test_path_list)\n",
    "train = pd.concat(train_feature_list, axis=1)\n",
    "train = pd.concat([base_train, train], axis=1)\n",
    "test = pd.concat(test_feature_list, axis=1)\n",
    "test = pd.concat([base_test, test], axis=1)\n",
    "\n",
    "train.fillna(train.median(), inplace=True)\n",
    "test.fillna(test.median(), inplace=True)\n",
    "\n",
    "train.head()\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from keras.layers import Input, Embedding, Dense,Flatten, Activation, dot, add\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2 as l2_reg\n",
    "from keras import initializers\n",
    "import itertools\n",
    "\n",
    "\n",
    "def make_batches(size, batch_size):\n",
    "    nb_batch = int(np.ceil(size/float(batch_size)))\n",
    "    return [(i*batch_size, min(size, (i+1)*batch_size)) for i in range(0, nb_batch)]\n",
    "\n",
    "\n",
    "def batch_generator(X,y,batch_size=128,shuffle=True):\n",
    "    sample_size = X[0].shape[0]\n",
    "    index_array = np.arange(sample_size)\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(index_array)\n",
    "        batches = make_batches(sample_size, batch_size)\n",
    "        for batch_index, (batch_start, batch_end) in enumerate(batches):\n",
    "            batch_ids = index_array[batch_start:batch_end]\n",
    "            X_batch = [X[i][batch_ids] for i in range(len(X))]\n",
    "            y_batch = y[batch_ids]\n",
    "            yield X_batch,y_batch\n",
    "\n",
    "\n",
    "def test_batch_generator(X,y,batch_size=128):\n",
    "    sample_size = X[0].shape[0]\n",
    "    index_array = np.arange(sample_size)\n",
    "    batches = make_batches(sample_size, batch_size)\n",
    "    for batch_index, (batch_start, batch_end) in enumerate(batches):\n",
    "        batch_ids = index_array[batch_start:batch_end]\n",
    "        X_batch = [X[i][batch_ids] for i in range(len(X))]\n",
    "        y_batch = y[batch_ids]\n",
    "        yield X_batch,y_batch\n",
    "\n",
    "\n",
    "def predict_batch(model,X_t,batch_size=128):\n",
    "    outcome = []\n",
    "    for X_batch,y_batch in test_batch_generator(X_t,np.zeros(X_t[0].shape[0]),batch_size=batch_size):\n",
    "        outcome.append(model.predict(X_batch,batch_size=batch_size))\n",
    "    outcome = np.concatenate(outcome).ravel()\n",
    "    return outcome\n",
    "\n",
    "\n",
    "\n",
    "def build_model(input_len, max_features,K=8,solver='adam',l2=0.0,l2_fm = 0.0):\n",
    "\n",
    "    inputs = []\n",
    "    flatten_layers=[]\n",
    "    columns = range(len(max_features))\n",
    "    for c in columns:\n",
    "        inputs_c = Input(shape=(1,), dtype='int32',name = 'input_%s'%c)\n",
    "        num_c = max_features[c]\n",
    "\n",
    "        embed_c = Embedding(\n",
    "                        input_dim=num_c, # 埋め込む特徴の次元\n",
    "                        output_dim=K, # 何次元に埋め込むか\n",
    "                        input_length=1,\n",
    "#                         input_length=1,\n",
    "                        name = 'embed_%s'%c,\n",
    "                        W_regularizer=l2_reg(l2_fm)\n",
    "                        )(inputs_c)\n",
    "\n",
    "              \n",
    "        flatten_c = Flatten()(embed_c)\n",
    "\n",
    "        inputs.append(inputs_c)\n",
    "        flatten_layers.append(flatten_c)\n",
    "\n",
    "    fm_layers = []\n",
    "\n",
    "    for emb1,emb2 in itertools.combinations(flatten_layers, 2):\n",
    "        \n",
    "#         dot_layer = merge([emb1,emb2], mode='dot', dot_axes=1)\n",
    "        dot_layer = dot(inputs=[emb1, emb2], axes=1)\n",
    "        \n",
    "        fm_layers.append(dot_layer)\n",
    "\n",
    "        \n",
    "    for c in columns:\n",
    "        num_c = max_features[c]\n",
    "        \n",
    "        embed_c = Embedding(\n",
    "                        num_c,\n",
    "                        1,\n",
    "                        input_length=1,\n",
    "#                         input_length=input_len,\n",
    "                        name = 'linear_%s'%c,\n",
    "                        W_regularizer=l2_reg(l2)\n",
    "                        )(inputs[c])\n",
    "\n",
    "        flatten_c = Flatten()(embed_c)\n",
    "\n",
    "        fm_layers.append(flatten_c)\n",
    "        \n",
    "#     flatten = merge(fm_layers, mode='sum')\n",
    "    flatten = add(fm_layers) \n",
    "    outputs = Activation('sigmoid',name='outputs')(flatten)\n",
    "    \n",
    "    model = Model(input=inputs, output=outputs)\n",
    "\n",
    "    model.compile(\n",
    "                optimizer=solver,\n",
    "                loss= 'binary_crossentropy'\n",
    "              )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class KerasFM(BaseEstimator):\n",
    "    def __init__(self, input_len, max_features=[], K=8, solver='adam', l2=0.0, l2_fm=0.0):\n",
    "        self.model = build_model(input_len, max_features,K,solver,l2=l2,l2_fm = l2_fm)\n",
    "\n",
    "    def fit(self, X, y, batch_size=128, nb_epoch=10, shuffle=True, verbose=1, validation_data=None):\n",
    "        self.model.fit(X,y,batch_size=batch_size,nb_epoch=nb_epoch,shuffle=shuffle,verbose=verbose,validation_data=None)\n",
    "\n",
    "    def fit_generator(self,X,y,batch_size=128,nb_epoch=10,shuffle=True,verbose=1,validation_data=None,callbacks=None):\n",
    "        tr_gen = batch_generator(X,y,batch_size=batch_size,shuffle=shuffle)\n",
    "        if validation_data:\n",
    "            X_test,y_test = validation_data\n",
    "            te_gen = batch_generator(X_test,y_test,batch_size=batch_size,shuffle=False)\n",
    "            nb_val_samples = X_test[-1].shape[0]\n",
    "        else:\n",
    "            te_gen = None\n",
    "            nb_val_samples = None\n",
    "\n",
    "        self.model.fit_generator(\n",
    "                tr_gen, \n",
    "                samples_per_epoch=X[-1].shape[0], \n",
    "                nb_epoch=nb_epoch, \n",
    "                verbose=verbose, \n",
    "                callbacks=callbacks, \n",
    "                validation_data=te_gen, \n",
    "                nb_val_samples=nb_val_samples, \n",
    "                max_q_size=10\n",
    "                )\n",
    "\n",
    "    def predict(self,X,batch_size=128):\n",
    "        y_preds = predict_batch(self.model,X,batch_size=batch_size)\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load & FFM Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 36)\n",
      "(292, 36)\n",
      "(1459, 36)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train = pd.read_csv('../../house_prise/input/train.csv')\n",
    "test = pd.read_csv('../../house_prise/input/test.csv')\n",
    "\n",
    "num_list = [col for col in train.columns if str(train[col].dtype).count('int') or str(train[col].dtype).count('float') ]\n",
    "\n",
    "train = train[num_list]\n",
    "num_list.remove('SalePrice')\n",
    "test = test[num_list]\n",
    "train.drop('Id', axis=1, inplace=True)\n",
    "test.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "train, valid = train_test_split(train, test_size=0.2)\n",
    "tmp_y_train = train['SalePrice'].map(lambda x: 1 if x<120000 else 0)\n",
    "tmp_y_valid = valid['SalePrice'].map(lambda x: 1 if x<120000 else 0)\n",
    "train.drop('SalePrice', axis=1, inplace=True)\n",
    "valid.drop('SalePrice', axis=1, inplace=True)\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "print(test.shape)\n",
    "# sys.exit()\n",
    "\n",
    "# max_features = [len(train[col]) for col in train.columns]\n",
    "# model = KerasFM(input_len=len(train), max_features=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = len(train)\n",
    "len_valid = len(valid)\n",
    "len_test = len(test)\n",
    "\n",
    "train_val = train.values\n",
    "y_train_val = tmp_y_train.values\n",
    "valid_val = valid.values\n",
    "y_valid_val = tmp_y_valid.values\n",
    "test_val = test.values\n",
    "\n",
    "x_train = train_val.reshape(len_train, 36)\n",
    "y_train = y_train_val.reshape(len_train, 1)\n",
    "x_valid = valid_val.reshape(len_valid, 36)\n",
    "y_valid = y_valid_val.reshape(len_valid, 1)\n",
    "x_test = test_val.reshape(len_test, 36)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "# (1168, 36)\n",
    "# (1168, 1)\n",
    "# (292, 36)\n",
    "# (292, 1)\n",
    "\n",
    "x_train = [i for i in x_train.T]\n",
    "x_valid = [i for i in x_valid.T]\n",
    "x_test = [i for i in x_test.T]\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_valid))\n",
    "print(len(x_test))\n",
    "# 36\n",
    "# 36\n",
    "# 36\n",
    "\n",
    "model.fit(X=x_train, y=y_train, validation_data=(x_valid, y_valid))\n",
    "pred = model.predict(X=x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
