{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:40:08.183701Z",
     "start_time": "2018-10-28T07:40:07.309627Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "import os\n",
    "import sys\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "sys.path.append(f'{HOME}/kaggle/data_analysis/library')\n",
    "import utils\n",
    "from utils import get_categorical_features, get_numeric_features\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "os.listdir('../input/')\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_avtive_month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 84.81it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 180.62it/s]\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.95s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  4.04 Mb (56.2% reduction)\n",
      "Mem. usage decreased to  2.24 Mb (52.5% reduction)\n",
      "Mem. usage decreased to 2554.26 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 183.47 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train = utils.read_df_pkl('../input/train0*')\n",
    "df_test = utils.read_df_pkl('../input/test0*')\n",
    "df_train.set_index(key, inplace=True)\n",
    "df_test.set_index(key, inplace=True)\n",
    "train_test = pd.concat([df_train, df_test], axis=0)\n",
    "df_hist = utils.read_df_pkl('../input/hist_clean*')\n",
    "df_new = utils.read_df_pkl('../input/new_clean*')\n",
    "\n",
    "df_train = utils.reduce_mem_usage(df_train)\n",
    "df_test  = utils.reduce_mem_usage(df_test )\n",
    "df_hist  = utils.reduce_mem_usage(df_hist )\n",
    "df_new   = utils.reduce_mem_usage(df_new  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>all_term</th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>yyyy_week</th>\n",
       "      <th>purchase_amount_over</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>2017-06-25 15:33:07</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.043579</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>699</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>2017-06-25</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>2017-07-15 12:10:45</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-7</td>\n",
       "      <td>0.013786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>699</td>\n",
       "      <td>2017-07</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>28</td>\n",
       "      <td>2017-28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>2017-08-09 22:04:29</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-6</td>\n",
       "      <td>0.026535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>699</td>\n",
       "      <td>2017-08</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>32</td>\n",
       "      <td>2017-32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>2017-09-02 10:06:26</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>560</td>\n",
       "      <td>M_ID_e6d5ae8ea6</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>699</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>35</td>\n",
       "      <td>2017-35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>2017-03-10 01:14:19</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>699</td>\n",
       "      <td>2017-03</td>\n",
       "      <td>2017-03-10</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id       purchase_date  authorized_flag  city_id  category_1  \\\n",
       "0  C_ID_4e6213e9bc 2017-06-25 15:33:07                1       88           0   \n",
       "1  C_ID_4e6213e9bc 2017-07-15 12:10:45                1       88           0   \n",
       "2  C_ID_4e6213e9bc 2017-08-09 22:04:29                1       88           0   \n",
       "3  C_ID_4e6213e9bc 2017-09-02 10:06:26                1       88           0   \n",
       "4  C_ID_4e6213e9bc 2017-03-10 01:14:19                1       88           0   \n",
       "\n",
       "   installments category_3  merchant_category_id      merchant_id  month_lag  \\\n",
       "0           0.0          A                    80  M_ID_e020e9b302         -8   \n",
       "1           0.0          A                   367  M_ID_86ec983688         -7   \n",
       "2           0.0          A                    80  M_ID_979ed661fc         -6   \n",
       "3           0.0          A                   560  M_ID_e6d5ae8ea6         -5   \n",
       "4           0.0          A                    80  M_ID_e020e9b302        -11   \n",
       "\n",
       "   purchase_amount  category_2  state_id  subsector_id first_active_month  \\\n",
       "0         0.043579         1.0        16            37         2016-06-01   \n",
       "1         0.013786         1.0        16            16         2016-06-01   \n",
       "2         0.026535         1.0        16            37         2016-06-01   \n",
       "3         0.011566         1.0        16            34         2016-06-01   \n",
       "4         0.024048         1.0        16            37         2016-06-01   \n",
       "\n",
       "   all_term   yyyymm     yyyymmdd  weekofyear yyyy_week  purchase_amount_over  \n",
       "0       699  2017-06  2017-06-25           25   2017-25                   0.0  \n",
       "1       699  2017-07  2017-07-15           28   2017-28                   0.0  \n",
       "2       699  2017-08  2017-08-09           32   2017-32                   0.0  \n",
       "3       699  2017-09  2017-09-02           35   2017-35                   0.0  \n",
       "4       699  2017-03  2017-03-10           10   2017-10                   0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_columns(name,aggs):\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "# for df in [df_hist]:\n",
    "#     df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "#     df['weekofyear'] = df['purchase_date'].dt.weekofyear\n",
    "#     df['month'] = df['purchase_date'].dt.month\n",
    "#     df['hour'] = df['purchase_date'].dt.hour\n",
    "#     df['month_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)//30\n",
    "#     df['date_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hist.drop(['city_id', 'category_1', 'installments', 'category_2', 'category_3', 'merchant_category_id', 'merchant_id', 'purchase_amount'], axis=1, inplace=True)\n",
    "auth1 = df_hist[df_hist['authorized_flag']==1]\n",
    "auth0 = df_hist[df_hist['authorized_flag']==0]\n",
    "\n",
    "# df_hist['yyyymm'] =  df_hist['purchase_date'].map(lambda x: str(x)[:7] + '-01')\n",
    "# df_hist['yyyy_week'] = df_hist['yyyymm'].map(lambda x: str(x)[:4]) + df_hist['weekofyear'].map(lambda x: '-0' + str(x) if len(str(x))==1 else '-' + str(x) )\n",
    "# df_hist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 連続week, month利用回数、期間内week, monthカバー率を特徴にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 106.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 167.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970897\n",
      "970897\n"
     ]
    }
   ],
   "source": [
    "df = auth0\n",
    "df_train = utils.read_df_pkl('../input/train0*')\n",
    "df_test = utils.read_df_pkl('../input/test0*')\n",
    "train_test = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "for df, fname in zip([auth1, auth0], ['auth1', 'auth0']):\n",
    "\n",
    "#     if fname.count('auth1'):\n",
    "        \n",
    "    df.sort_values(by=[key, 'purchase_date'], inplace=True)\n",
    "    \n",
    "    df_month = df[[key, 'yyyymm']].drop_duplicates()\n",
    "    df_month['yyyymm_shift1'] = df_month.groupby(key)['yyyymm'].shift(1)\n",
    "    df_month['diff_month'] = ((pd.to_datetime(df_month['yyyymm']) - pd.to_datetime(df_month['yyyymm_shift1'])).dt.days)//28\n",
    "    # 連続してる時はフラグ1がたち、それ以外は0\n",
    "    df_month['continuours_flg'] = df_month['diff_month'].where(df_month['diff_month']==1, 0)\n",
    "    \n",
    "    # 0になったらしきり直しなので1, 1が続く限り+1していけば、idなど関係なく、1が続いた数をカウントできる。（天才的）\n",
    "    cont_list = df_month['continuours_flg'].values\n",
    "    continuous_list = []\n",
    "    for i in cont_list:\n",
    "        if i==0:\n",
    "            cnt=1\n",
    "        else:\n",
    "            cnt+=1\n",
    "        continuous_list.append(cnt)\n",
    "    print(len(cont_list))\n",
    "    print(len(continuous_list))\n",
    "    \n",
    "    df_month['continuous'] = continuous_list\n",
    "    df_month['continuous_shift1'] = df_month['continuous'].shift(1)\n",
    "    df_month['diff_cont'] = df_month['continuous'] - df_month['continuous_shift1']\n",
    "    # 最大連続回数を取り出す時はこれが必要\n",
    "    df_month['diff_cont_shift-1'] = df_month['diff_cont'].shift(-1)\n",
    "    \n",
    "    # 1月以外の連続した回数を残す\n",
    "    df_month.fillna(1.0, inplace=True)\n",
    "    df_month_cont = df_month[df_month['diff_cont_shift-1']<0][[key, 'yyyymm', 'continuous']]\n",
    "    df_month_cont.rename(columns={'continuous':'continuous_month'}, inplace=True)\n",
    "    df_month_cont.head()\n",
    "    \n",
    "    \n",
    "    cont_max = df_month_cont.groupby(key)['continuous_month'].max().reset_index()\n",
    "    cont_min = df_month_cont.groupby(key)['continuous_month'].min().reset_index().rename(columns={'continuous_month':'continuous_month_min'})\n",
    "    cont_mean = df_month_cont.groupby(key)['continuous_month'].mean().reset_index().rename(columns={'continuous_month':'continuous_month_mean'})\n",
    "    cont_std = df_month_cont.groupby(key)['continuous_month'].std().reset_index().rename(columns={'continuous_month':'continuous_month_std'})\n",
    "    \n",
    "    tmp_max = df_month_cont.merge(cont_max, how='inner', on=[key, 'continuous_month'])\n",
    "    cont_max_month = tmp_max.groupby(key)['yyyymm'].max()\n",
    "    \n",
    "    cont_max.rename(columns={'continuous_month':'continuous_month_max'}, inplace=True)\n",
    "    \n",
    "    cont_max_month = cont_max_month.to_frame().reset_index().rename(columns={'index':key})\n",
    "    \n",
    "    cont_max_month = cont_max_month.merge(train_test[[key, 'first_active_month']], how='left', on=key)\n",
    "    cont_max_month = cont_max_month.merge(cont_max, how='left', on=key)\n",
    "    \n",
    "    cont_max_month['diff_cont_max_month_from_today'] = ((datetime.datetime.today() - pd.to_datetime(cont_max_month['yyyymm'])).dt.days)//27\n",
    "    cont_max_month['diff_cont_max_last_month_from_first'] = ((pd.to_datetime(cont_max_month['yyyymm']) - pd.to_datetime(cont_max_month['first_active_month']) ).dt.days)//30\n",
    "    cont_max_month['diff_cont_max_from_first'] = cont_max_month['diff_cont_max_last_month_from_first'] - cont_max_month['continuous_month_max']\n",
    "    cont_max_month['diff_cont_max_from_first'] += 1\n",
    "    \n",
    "    cont_cnt = df_month_cont.groupby(key).size()\n",
    "    cont_cnt.name = 'cont_month_cut_cnt'\n",
    "    cont_cnt = cont_cnt.to_frame().reset_index().rename(columns={'index':key})\n",
    "    \n",
    "    \n",
    "    # contがついてるfeatureのみ保存すればOK\n",
    "    for feat in [cont_min, cont_mean, cont_std, cont_max_month, cont_cnt]:\n",
    "        feat.columns = [col if col==key else f\"{fname}_{col}\" for col in feat.columns]\n",
    "        df_train = df_train.merge(feat, how='left', on=key)\n",
    "        df_test = df_test.merge(feat, how='left', on=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 連続月達成時期を1月ごとに横持ちする（01）で\n",
    "2ヵ月連続を達成したのは何か月前か？という形で  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_list = []\n",
    "# for i in range(2, 25, 1):\n",
    "#     tmp = df_cont[df_cont['continuous_month']>=i].groupby(key)['yyyymm'].max().reset_index()\n",
    "#     tmp[f'diff_month_cont_month'] = (datetime.datetime.today() - pd.to_datetime(tmp['yyyymm'])).dt.days//30\n",
    "#     tmp[f'cont_month_timing_from_today'] = f'cont_{i}month_timing_from_today'\n",
    "#     tmp_list.append(tmp[[key, f'cont_month_timing_from_today', f'diff_month_cont_month']].copy())\n",
    "# cont_from = pd.concat(tmp_list, axis=0)\n",
    "# display(cont_from.head(10))\n",
    "# display(cont_from.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cont_from_table = cont_from.pivot_table(index=key, columns='cont_month_timing_from_today', values='diff_month_cont_month')\n",
    "# cont_from_table.head()\n",
    "# df_train = df_train.merge(cont_from_table, how='left', on=key)\n",
    "# df_test = df_test.merge(cont_from_table, how='left', on=key)\n",
    "# print(df_train.shape)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>auth1_continuous_month_min</th>\n",
       "      <th>auth1_continuous_month_mean</th>\n",
       "      <th>auth1_continuous_month_std</th>\n",
       "      <th>auth1_yyyymm</th>\n",
       "      <th>auth1_first_active_month</th>\n",
       "      <th>auth1_continuous_month_max</th>\n",
       "      <th>auth1_diff_cont_max_month_from_today</th>\n",
       "      <th>auth1_diff_cont_max_last_month_from_first</th>\n",
       "      <th>auth1_diff_cont_max_from_first</th>\n",
       "      <th>auth1_cont_month_cut_cnt</th>\n",
       "      <th>auth0_continuous_month_min</th>\n",
       "      <th>auth0_continuous_month_mean</th>\n",
       "      <th>auth0_continuous_month_std</th>\n",
       "      <th>auth0_yyyymm</th>\n",
       "      <th>auth0_first_active_month</th>\n",
       "      <th>auth0_continuous_month_max</th>\n",
       "      <th>auth0_diff_cont_max_month_from_today</th>\n",
       "      <th>auth0_diff_cont_max_last_month_from_first</th>\n",
       "      <th>auth0_diff_cont_max_from_first</th>\n",
       "      <th>auth0_cont_month_cut_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-10</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>2016-08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0            2017-06  C_ID_92a2005557          5          2          1   \n",
       "1            2017-01  C_ID_3d0044924f          4          1          0   \n",
       "2            2016-08  C_ID_d639edf6cd          2          2          0   \n",
       "3            2017-09  C_ID_186d6a6901          4          3          0   \n",
       "4            2017-11  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  auth1_continuous_month_min  auth1_continuous_month_mean  \\\n",
       "0 -0.820283                         9.0                          9.0   \n",
       "1  0.392913                        13.0                         13.0   \n",
       "2  0.688056                         3.0                          4.0   \n",
       "3  0.142495                         6.0                          6.0   \n",
       "4 -0.159749                         4.0                          4.0   \n",
       "\n",
       "   auth1_continuous_month_std auth1_yyyymm auth1_first_active_month  \\\n",
       "0                         NaN      2018-02                  2017-06   \n",
       "1                         NaN      2018-01                  2017-01   \n",
       "2                         1.0      2017-05                  2016-08   \n",
       "3                         NaN      2018-02                  2017-09   \n",
       "4                         NaN      2018-02                  2017-11   \n",
       "\n",
       "   auth1_continuous_month_max  auth1_diff_cont_max_month_from_today  \\\n",
       "0                         9.0                                  13.0   \n",
       "1                        13.0                                  14.0   \n",
       "2                         5.0                                  23.0   \n",
       "3                         6.0                                  13.0   \n",
       "4                         4.0                                  13.0   \n",
       "\n",
       "   auth1_diff_cont_max_last_month_from_first  auth1_diff_cont_max_from_first  \\\n",
       "0                                        8.0                             0.0   \n",
       "1                                       12.0                             0.0   \n",
       "2                                        9.0                             5.0   \n",
       "3                                        5.0                             0.0   \n",
       "4                                        3.0                             0.0   \n",
       "\n",
       "   auth1_cont_month_cut_cnt  auth0_continuous_month_min  \\\n",
       "0                       1.0                         6.0   \n",
       "1                       1.0                         2.0   \n",
       "2                       3.0                         NaN   \n",
       "3                       1.0                         NaN   \n",
       "4                       1.0                         2.0   \n",
       "\n",
       "   auth0_continuous_month_mean  auth0_continuous_month_std auth0_yyyymm  \\\n",
       "0                          6.0                         NaN      2017-12   \n",
       "1                          2.0                         NaN      2017-10   \n",
       "2                          NaN                         NaN          NaN   \n",
       "3                          NaN                         NaN          NaN   \n",
       "4                          2.0                         NaN      2018-02   \n",
       "\n",
       "  auth0_first_active_month  auth0_continuous_month_max  \\\n",
       "0                  2017-06                         6.0   \n",
       "1                  2017-01                         2.0   \n",
       "2                      NaN                         NaN   \n",
       "3                      NaN                         NaN   \n",
       "4                  2017-11                         2.0   \n",
       "\n",
       "   auth0_diff_cont_max_month_from_today  \\\n",
       "0                                  15.0   \n",
       "1                                  17.0   \n",
       "2                                   NaN   \n",
       "3                                   NaN   \n",
       "4                                  13.0   \n",
       "\n",
       "   auth0_diff_cont_max_last_month_from_first  auth0_diff_cont_max_from_first  \\\n",
       "0                                        6.0                             1.0   \n",
       "1                                        9.0                             8.0   \n",
       "2                                        NaN                             NaN   \n",
       "3                                        NaN                             NaN   \n",
       "4                                        3.0                             2.0   \n",
       "\n",
       "   auth0_cont_month_cut_cnt  \n",
       "0                       1.0  \n",
       "1                       1.0  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n",
      "(325540,)\n"
     ]
    }
   ],
   "source": [
    "fname = '134_com'\n",
    "ignore_features = ['first_active_month', 'card_id']\n",
    "\n",
    "df_feat = pd.concat([df_train, df_test], axis=0)\n",
    "df_feat.fillna(-1, inplace=True)\n",
    "\n",
    "for col in df_feat.columns:\n",
    "#     if col in ignore_features:\n",
    "#         continue\n",
    "#     if not(col.count('feature_')):continue\n",
    "    if not(col.count('cont')):continue\n",
    "\n",
    "    feature = df_feat[col].values.astype('float32')\n",
    "    if feature.shape[0]!=325540:\n",
    "        print(feature.shape)\n",
    "    utils.to_pkl_gzip(path = f'../features/1_first_valid/{fname}_all_{col}@', obj=feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 135 week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 101.22it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 164.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6712457\n",
      "6712457\n",
      "1343579\n",
      "1343579\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>auth1_continuous_week_max</th>\n",
       "      <th>auth1_continuous_week_min</th>\n",
       "      <th>auth1_continuous_week_mean</th>\n",
       "      <th>auth1_continuous_week_std</th>\n",
       "      <th>auth1_cont_week_cut_cnt</th>\n",
       "      <th>auth0_continuous_week_max</th>\n",
       "      <th>auth0_continuous_week_min</th>\n",
       "      <th>auth0_continuous_week_mean</th>\n",
       "      <th>auth0_continuous_week_std</th>\n",
       "      <th>auth0_cont_week_cut_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>7.325754</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>2.362908</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>4.163332</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0            2017-06  C_ID_92a2005557          5          2          1   \n",
       "1            2017-01  C_ID_3d0044924f          4          1          0   \n",
       "2            2016-08  C_ID_d639edf6cd          2          2          0   \n",
       "3            2017-09  C_ID_186d6a6901          4          3          0   \n",
       "4            2017-11  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  auth1_continuous_week_max  auth1_continuous_week_min  \\\n",
       "0 -0.820283                       35.0                       35.0   \n",
       "1  0.392913                       24.0                        8.0   \n",
       "2  0.688056                        7.0                        2.0   \n",
       "3  0.142495                       11.0                        3.0   \n",
       "4 -0.159749                       17.0                       17.0   \n",
       "\n",
       "   auth1_continuous_week_mean  auth1_continuous_week_std  \\\n",
       "0                   35.000000                        NaN   \n",
       "1                   13.500000                   7.325754   \n",
       "2                    3.750000                   2.362908   \n",
       "3                    6.333333                   4.163332   \n",
       "4                   17.000000                        NaN   \n",
       "\n",
       "   auth1_cont_week_cut_cnt  auth0_continuous_week_max  \\\n",
       "0                      1.0                        3.0   \n",
       "1                      4.0                        4.0   \n",
       "2                      4.0                        NaN   \n",
       "3                      3.0                        NaN   \n",
       "4                      1.0                        NaN   \n",
       "\n",
       "   auth0_continuous_week_min  auth0_continuous_week_mean  \\\n",
       "0                        2.0                    2.333333   \n",
       "1                        4.0                    4.000000   \n",
       "2                        NaN                         NaN   \n",
       "3                        NaN                         NaN   \n",
       "4                        NaN                         NaN   \n",
       "\n",
       "   auth0_continuous_week_std  auth0_cont_week_cut_cnt  \n",
       "0                    0.57735                      3.0  \n",
       "1                        NaN                      1.0  \n",
       "2                        NaN                      NaN  \n",
       "3                        NaN                      NaN  \n",
       "4                        NaN                      NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = utils.read_df_pkl('../input/train0*')\n",
    "df_test = utils.read_df_pkl('../input/test0*')\n",
    "train_test = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "for df, fname in zip([auth1, auth0], ['auth1', 'auth0']):\n",
    "\n",
    "    df.sort_values(by=[key, 'purchase_date'], inplace=True)\n",
    "    df_week = df[[key, 'yyyy_week']].drop_duplicates()\n",
    "    \n",
    "    week_val = df_week['yyyy_week'].drop_duplicates().sort_values().to_frame()\n",
    "    week_val['index'] = np.arange(len(week_val)) + 1\n",
    "    df_week = df_week.merge(week_val, how='inner', on='yyyy_week')\n",
    "    \n",
    "    df_week.sort_values(by=[key, 'yyyy_week'], inplace=True)\n",
    "    df_week['index_shift1'] = df_week.groupby(key)['index'].shift(1)\n",
    "    df_week['diff_week'] = df_week['index'] - df_week['index_shift1']\n",
    "    # 連続してる時はフラグ1がたち、それ以外は0\n",
    "    df_week['continuours_flg'] = df_week['diff_week'].where(df_week['diff_week']==1, 0)\n",
    "    \n",
    "    # 0になったらしきり直しなので1, 1が続く限り+1していけば、idなど関係なく、1が続いた数をカウントできる。（天才的）\n",
    "    cont_list = df_week['continuours_flg'].values\n",
    "    continuous_list = []\n",
    "    for i in cont_list:\n",
    "        if i==0:\n",
    "            cnt=1\n",
    "        else:\n",
    "            cnt+=1\n",
    "        continuous_list.append(cnt)\n",
    "    print(len(cont_list))\n",
    "    print(len(continuous_list))\n",
    "    \n",
    "    df_week['continuous'] = continuous_list\n",
    "    df_week['continuous_shift1'] = df_week['continuous'].shift(1)\n",
    "    df_week['diff_cont'] = df_week['continuous'] - df_week['continuous_shift1']\n",
    "    # 最大連続回数を取り出す時はこれが必要\n",
    "    df_week['diff_cont_shift-1'] = df_week['diff_cont'].shift(-1)\n",
    "    \n",
    "    # 1月以外の連続した回数を残す\n",
    "    df_week.fillna(1.0, inplace=True)\n",
    "    df_cont = df_week[df_week['diff_cont_shift-1']<0][[key, 'yyyy_week', 'continuous']]\n",
    "    df_cont.rename(columns={'continuous':'continuous_week'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    cont_max = df_cont.groupby(key)['continuous_week'].max().reset_index().rename(columns={'continuous_week':'continuous_week_max'})\n",
    "    cont_min = df_cont.groupby(key)['continuous_week'].min().reset_index().rename(columns={'continuous_week':'continuous_week_min'})\n",
    "    cont_mean = df_cont.groupby(key)['continuous_week'].mean().reset_index().rename(columns={'continuous_week':'continuous_week_mean'})\n",
    "    cont_std = df_cont.groupby(key)['continuous_week'].std().reset_index().rename(columns={'continuous_week':'continuous_week_std'})\n",
    "    \n",
    "    cont_cnt = df_cont.groupby(key).size()\n",
    "    cont_cnt.name = 'cont_week_cut_cnt'\n",
    "    cont_cnt = cont_cnt.to_frame().reset_index().rename(columns={'index':key})\n",
    "    \n",
    "    # contがついてるfeatureのみ保存すればOK\n",
    "    for feat in [cont_max, cont_min, cont_mean, cont_std, cont_cnt]:\n",
    "        feat.columns = [col if col==key else f\"{fname}_{col}\" for col in feat.columns]\n",
    "        df_train = df_train.merge(feat, how='left', on=key)\n",
    "        df_test = df_test.merge(feat, how='left', on=key)\n",
    "        \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '135_cow'\n",
    "ignore_features = ['first_active_month', 'card_id']\n",
    "\n",
    "df_feat = pd.concat([df_train, df_test], axis=0)\n",
    "df_feat.fillna(-1, inplace=True)\n",
    "\n",
    "for col in df_feat.columns:\n",
    "#     if col in ignore_features:\n",
    "#         continue\n",
    "#     if not(col.count('feature_')):continue\n",
    "    if not(col.count('cont')):continue\n",
    "\n",
    "    feature = df_feat[col].values.astype('float32')\n",
    "    if feature.shape[0]!=325540:\n",
    "        print(feature.shape)\n",
    "    utils.to_pkl_gzip(path = f'../features/1_first_valid/{fname}_all_{col}@', obj=feature)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
