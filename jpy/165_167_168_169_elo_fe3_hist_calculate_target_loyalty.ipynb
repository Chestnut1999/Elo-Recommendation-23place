{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 165 calculation target loyalty feature\n",
    "targetとなっているloyaltyを計算している期間に絞ったfeatureを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:40:08.183701Z",
     "start_time": "2018-10-28T07:40:07.309627Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "import os\n",
    "import sys\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "sys.path.append(f'{HOME}/kaggle/data_analysis/library')\n",
    "import utils\n",
    "from utils import get_categorical_features, get_numeric_features, reduce_mem_usage\n",
    "from preprocessing import get_dummies\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import sys\n",
    "\n",
    "os.listdir('../input/')\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_avtive_month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 87.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 183.07it/s]\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2554.26 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train = utils.read_df_pkl('../input/train0*')\n",
    "df_test = utils.read_df_pkl('../input/test0*')\n",
    "df_train.set_index(key, inplace=True)\n",
    "df_test.set_index(key, inplace=True)\n",
    "df_hist = utils.read_df_pkl('../input/hist_clean_rdm0*')\n",
    "df_hist = reduce_mem_usage(df_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term\n",
    "col_month = 'month_lag'\n",
    "df = df_hist[df_hist[col_month]>=-3]\n",
    "# df = df_hist[df_hist[col_month]<-2]\n",
    "# df = df_new\n",
    "\n",
    "auth1 = df[df.authorized_flag==1]\n",
    "auth0 = df[df.authorized_flag==0]\n",
    "\n",
    "# auth1_cat1 = auth1[auth1.category_1==1]\n",
    "# auth1_cat0 = auth1[auth1.category_1==0]\n",
    "# auth0_cat1 = auth0[auth0.category_1==1]\n",
    "# auth0_cat0 = auth0[auth0.category_1==0]\n",
    "# del auth1, auth0\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_type = 'lag0_-2'\n",
    "last_type = 'lag0_-3'\n",
    "last_type = 'lag0_-4'\n",
    "# last_type = 'lag-3_-13'\n",
    "null_cols = ['category_2', 'installments', 'merchant_id']\n",
    "\n",
    "# df_list = [auth1_cat1, auth1_cat0, auth0_cat1, auth0_cat0]\n",
    "df_list = [auth1, auth0]\n",
    "\n",
    "cat1_0 = False\n",
    "\n",
    "# category_2\n",
    "col = 'category_2'\n",
    "for df in df_list:\n",
    "    df[col].fillna('NA', inplace=True)\n",
    "\n",
    "if cat1_0:\n",
    "        \n",
    "    fname = 'auth1_cat0'\n",
    "    auth1_cat0[f'{col}_null_cnt'] = (auth1_cat0[col]=='NA')\n",
    "    fname = 'auth0_cat0'\n",
    "    auth0_cat0[f'{col}_null_cnt'] = (auth0_cat0[col]=='NA')\n",
    "    \n",
    "    # installments\n",
    "    col = 'installments'\n",
    "    fname = 'auth1_cat0'\n",
    "    auth1_cat0[f'{col}_isnull'] = (auth1_cat0[col].isnull())\n",
    "    fname = 'auth1_cat1'\n",
    "    auth1_cat1[f'{col}_isnull'] = (auth1_cat1[col].isnull())\n",
    "    fname = 'auth0_cat0'\n",
    "    auth0_cat0[f'{col}_isnull'] = (auth0_cat0[col].isnull())\n",
    "    fname = 'auth0_cat1'\n",
    "    auth0_cat1[f'{col}_isnull'] = (auth0_cat1[col].isnull())\n",
    "    \n",
    "    # merchant_id\n",
    "    col = 'merchant_id'\n",
    "    fname = 'auth1_cat0'\n",
    "    auth1_cat0[f'{col}_isnull'] = (auth1_cat0[col].isnull())\n",
    "    fname = 'auth1_cat1'\n",
    "    auth1_cat1[f'{col}_isnull'] = (auth1_cat1[col].isnull())\n",
    "    fname = 'auth0_cat0'\n",
    "    auth0_cat0[f'{col}_isnull'] = (auth0_cat0[col].isnull())\n",
    "    fname = 'auth0_cat1'\n",
    "    auth0_cat1[f'{col}_isnull'] = (auth0_cat1[col].isnull())\n",
    "\n",
    "else:\n",
    "    # auth1, auth0\n",
    "    fname = 'auth1'\n",
    "    auth1[f'{col}_null_cnt'] = (auth1[col]=='NA')\n",
    "    \n",
    "    # installments\n",
    "    col = 'installments'\n",
    "    fname = 'auth1'\n",
    "    auth1[f'{col}_isnull'] = (auth1[col].isnull())\n",
    "    fname = 'auth0'\n",
    "    auth0[f'{col}_isnull'] = (auth0[col].isnull())\n",
    "    \n",
    "    # merchant_id\n",
    "    col = 'merchant_id'\n",
    "    fname = 'auth1'\n",
    "    auth1[f'{col}_isnull'] = (auth1[col].isnull())\n",
    "    fname = 'auth0'\n",
    "    auth0[f'{col}_isnull'] = (auth0[col].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_type = 'lag0_-2'\n",
    "last_type = 'lag-3_-13'\n",
    "last_type = 'lag0_-3'\n",
    "last_type = 'lag0_-4'\n",
    "# df_list = [auth1_cat1, auth1_cat0, auth0_cat1, auth0_cat0]\n",
    "# fname_list = [f'{last_type}_auth1_cat1', f'{last_type}_auth1_cat0', f'{last_type}_auth0_cat1', f'{last_type}_auth0_cat0']\n",
    "\n",
    "df_list = [auth1, auth0]\n",
    "fname_list = [f'{last_type}_auth1', f'{last_type}_auth0']\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "def get_new_columns(name,aggs):\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "\n",
    "\n",
    "def feat_agg(df, fname):\n",
    "\n",
    "    null_cols = [col for col in df.columns if col.count('isnull')]\n",
    "    \n",
    "    aggs = {}\n",
    "    \n",
    "    # category_1==1のときcategory_2 = Null\n",
    "    if not(fname.count('cat1')):\n",
    "        cat_list = ['category_2']\n",
    "        df = get_dummies(df=df, cat_list=cat_list)\n",
    "        category_2_list = [col for col in df.columns if col.count('category_2')]\n",
    "        for cat in category_2_list:\n",
    "            aggs[cat] = ['mean', 'sum']\n",
    "            \n",
    "    # isnull feature\n",
    "    for col in null_cols:\n",
    "        aggs[col] = ['mean', 'sum']\n",
    "    \n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['first_active_month'] =  pd.to_datetime(df['first_active_month'])\n",
    "    df['month_diff'] = (pd.to_datetime('2018-05-01') - df['purchase_date']).dt.days\n",
    "    df['unix_date'] =  df['purchase_date'].map(lambda x: int(x.timestamp()) )\n",
    "    \n",
    "    aggs['month_lag'] = ['mean', 'std']\n",
    "    aggs['yyyy_week'] = ['nunique']\n",
    "    aggs['unix_date'] = ['max','min']\n",
    "    aggs['purchase_date'] = ['max','min']\n",
    "    aggs['month_diff'] = ['mean', 'std']\n",
    "    \n",
    "    aggs['purchase_amount'] = ['sum','max', 'min','mean']\n",
    "    aggs['purchase_amount_over'] = ['sum','max', 'min','mean']\n",
    "    \n",
    "    aggs['merchant_id'] = ['nunique']\n",
    "    aggs['merchant_category_id'] = ['nunique']\n",
    "    aggs['card_id'] = ['size']\n",
    "    aggs['installments'] = ['sum','max', 'min','mean', 'std']\n",
    "    \n",
    "    new_columns = get_new_columns(fname, aggs)\n",
    "    df_agg = df.groupby(key).agg(aggs)\n",
    "    df_agg.columns = new_columns\n",
    "    df_agg.reset_index(drop=False,inplace=True)\n",
    "     \n",
    "    df_agg[f'{fname}_term'] = (df_agg[f'{fname}_unix_date_max'] - df_agg[f'{fname}_unix_date_min']).astype('int64')\n",
    "    df_agg[f'{fname}_freq_per_90days'] = df_agg[f'{fname}_card_id_size'] / 90\n",
    "    df_agg[f'{fname}_amount_per_90days'] = df_agg[f'{fname}_purchase_amount_sum'] / 90\n",
    "    df_agg[f'{fname}_installments_per_90days'] = df_agg[f'{fname}_installments_sum'] / 90\n",
    "    df_agg[f'{fname}_amount_per_installments_sum'] = df_agg[f'{fname}_purchase_amount_sum'] / df_agg[f'{fname}_installments_sum']\n",
    "    df_agg[f'{fname}_amount_per_installments_mean'] = df_agg[f'{fname}_purchase_amount_mean'] / df_agg[f'{fname}_installments_mean']\n",
    "    \n",
    "    feat_train = df_train.merge(df_agg, on=key, how='left')\n",
    "    feat_test = df_test.merge(df_agg, on=key, how='left')\n",
    "    del df_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    print(fname)\n",
    "    display(feat_train.head())\n",
    "    \n",
    "    train_list.append(feat_train)\n",
    "    test_list.append(feat_test)\n",
    "    \n",
    "for df, fname in zip(df_list, fname_list):\n",
    "    feat_agg(df, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute\n",
    "\n",
    "def impute_agg(df):\n",
    "    for col in df.columns:\n",
    "        if col.count('isnull'):\n",
    "            df[col].fillna(-1, inplace=True)\n",
    "        if col.count('null_cnt'):\n",
    "            df[col].fillna(-1, inplace=True)\n",
    "        if col.count('month_lag'):\n",
    "            df[col].fillna(df[col].min()-15, inplace=True)\n",
    "        if col.count('month_diff'):\n",
    "            df[col].fillna(df[col].max()+100, inplace=True)\n",
    "        if col.count('nunique'):\n",
    "            df[col].fillna(-1, inplace=True)\n",
    "        if col.count('amount'):\n",
    "            df[col].fillna(-1, inplace=True)\n",
    "        if col.count('installments'):\n",
    "            df[col].fillna(-2, inplace=True)\n",
    "        if col.count('unix_date'):\n",
    "            df[col].fillna(df[col].min()-100000, inplace=True)\n",
    "        if col.count('size'):\n",
    "            df[col].fillna(-1, inplace=True)\n",
    "        if col.count('term'):\n",
    "            df[col].fillna(-1, inplace=True)\n",
    "        if col.count('per'):\n",
    "            df[col].fillna(-1, inplace=True)\n",
    "        if col.count('dummie'):\n",
    "            df[col].fillna(-1, inplace=True)\n",
    "            \n",
    "    return df\n",
    "        \n",
    "for train, test in zip(train_list, test_list):\n",
    "    try:\n",
    "        train.drop(['feature_1', 'feature_2', 'feature_3', 'first_active_month', 'target'], axis=1, inplace=True)\n",
    "        test.drop(['feature_1', 'feature_2', 'feature_3', 'first_active_month'], axis=1, inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        train.set_index(key, inplace=True)\n",
    "        test.set_index(key, inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    df_train = df_train.join(train)\n",
    "    df_test = df_test.join(test)\n",
    "\n",
    "df_train = impute_agg(df_train)\n",
    "df_test = impute_agg(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_type = 'lag0_-2'\n",
    "last_type = 'lag-3_-13'\n",
    "last_type = 'lag0_-3'\n",
    "last_type = 'lag0_-4'\n",
    "\n",
    "cat1_0 = False\n",
    "\n",
    "if cat1_0:\n",
    "\n",
    "    df_train['first_active_month'] =  pd.to_datetime(df_train['first_active_month'])\n",
    "    df_test['first_active_month'] =  pd.to_datetime(df_test['first_active_month'])\n",
    "    \n",
    "    # 最終のcat0, auth1までの期間\n",
    "    df_train[f'{last_type}_auth1_cat0_elapsed_time_from_first'] = (df_train[f'{last_type}_auth1_cat0_purchase_date_max'] - df_train[f'first_active_month']).dt.days\n",
    "    df_test[f'{last_type}_auth1_cat0_elapsed_time_from_first']  = (df_test[f'{last_type}_auth1_cat0_purchase_date_max'] - df_test[f'first_active_month']).dt.days\n",
    "    \n",
    "    # 最終のcat1, auth1までの期間\n",
    "    df_train[f'{last_type}_cat0_elapsed_time_from_first'] = (df_train[f'{last_type}_auth1_cat0_purchase_date_max'] - df_train[f'first_active_month']).dt.days\n",
    "    df_test[f'{last_type}_cat0_elapsed_time_from_first']  = (df_test[f'{last_type}_auth1_cat0_purchase_date_max'] - df_test[f'first_active_month']).dt.days\n",
    "    df_train[f'{last_type}_cat1_elapsed_time_from_first'] = (df_train[f'{last_type}_auth1_cat1_purchase_date_max'] - df_train[f'first_active_month']).dt.days\n",
    "    df_test[f'{last_type}_cat1_elapsed_time_from_first']  = (df_test[f'{last_type}_auth1_cat1_purchase_date_max'] - df_test[f'first_active_month']).dt.days\n",
    "    \n",
    "    # {last_type}の初回購買までの期間\n",
    "    df_train[f'{last_type}_cat0_first_buy'] = (df_train[f'{last_type}_auth1_cat0_purchase_date_min'] - df_train[f'first_active_month']).dt.days\n",
    "    df_test[f'{last_type}_cat0_first_buy']  = (df_test[f'{last_type}_auth1_cat0_purchase_date_min'] - df_test[f'first_active_month']).dt.days\n",
    "    df_train[f'{last_type}_cat1_first_buy'] = (df_train[f'{last_type}_auth1_cat1_purchase_date_min'] - df_train[f'first_active_month']).dt.days\n",
    "    df_test[f'{last_type}_cat1_first_buy']  = (df_test[f'{last_type}_auth1_cat1_purchase_date_min'] - df_test[f'first_active_month']).dt.days\n",
    "    \n",
    "    # 20180501までの期間を各データセットパターンで\n",
    "    df_train[f'{last_type}_auth1_cat0_term_from_now'] = (pd.to_datetime('2018-05-01') - df_train[f'{last_type}_auth1_cat0_purchase_date_max']).dt.days\n",
    "    df_train[f'{last_type}_auth1_cat1_term_from_now'] = (pd.to_datetime('2018-05-01') - df_train[f'{last_type}_auth1_cat1_purchase_date_max']).dt.days\n",
    "    df_train[f'{last_type}_auth0_cat0_term_from_now'] = (pd.to_datetime('2018-05-01') - df_train[f'{last_type}_auth0_cat0_purchase_date_max']).dt.days\n",
    "    df_train[f'{last_type}_auth0_cat1_term_from_now'] = (pd.to_datetime('2018-05-01') - df_train[f'{last_type}_auth0_cat1_purchase_date_max']).dt.days\n",
    "    df_test[f'{last_type}_auth1_cat0_term_from_now'] = (pd.to_datetime('2018-05-01') - df_test[f'{last_type}_auth1_cat0_purchase_date_max']).dt.days\n",
    "    df_test[f'{last_type}_auth1_cat1_term_from_now'] = (pd.to_datetime('2018-05-01') - df_test[f'{last_type}_auth1_cat1_purchase_date_max']).dt.days\n",
    "    df_test[f'{last_type}_auth0_cat0_term_from_now'] = (pd.to_datetime('2018-05-01') - df_test[f'{last_type}_auth0_cat0_purchase_date_max']).dt.days\n",
    "    df_test[f'{last_type}_auth0_cat1_term_from_now'] = (pd.to_datetime('2018-05-01') - df_test[f'{last_type}_auth0_cat1_purchase_date_max']).dt.days\n",
    "    \n",
    "    # cat0, auth1, auth0の間の期間\n",
    "    df_train[f'{last_type}_auth1_0_term'] = df_train[f'{last_type}_auth1_cat0_term_from_now'] - df_train[f'{last_type}_auth0_cat0_term_from_now']\n",
    "    df_test[f'{last_type}_auth1_0_term']  = df_test[f'{last_type}_auth1_cat0_term_from_now'] - df_test[f'{last_type}_auth0_cat0_term_from_now']\n",
    "    \n",
    "else:\n",
    "\n",
    "    df_train['first_active_month'] =  pd.to_datetime(df_train['first_active_month'])\n",
    "    df_test['first_active_month'] =  pd.to_datetime(df_test['first_active_month'])\n",
    "    \n",
    "    # 最終のcat0, auth1までの期間\n",
    "    df_train[f'{last_type}_auth1_elapsed_time_from_first'] = (df_train[f'{last_type}_auth1_purchase_date_max'] - df_train[f'first_active_month']).dt.days\n",
    "    df_test[f'{last_type}_auth1_elapsed_time_from_first']  = (df_test[f'{last_type}_auth1_purchase_date_max'] - df_test[f'first_active_month']).dt.days\n",
    "    \n",
    "    # 最終のcat1, auth1までの期間\n",
    "    df_train[f'{last_type}_elapsed_time_from_first'] = (df_train[f'{last_type}_auth1_purchase_date_max'] - df_train[f'first_active_month']).dt.days\n",
    "    df_test[f'{last_type}_elapsed_time_from_first']  = (df_test[f'{last_type}_auth1_purchase_date_max'] - df_test[f'first_active_month']).dt.days\n",
    "    \n",
    "    # {last_type}の初回購買までの期間\n",
    "    df_train[f'{last_type}_first_buy'] = (df_train[f'{last_type}_auth1_purchase_date_min'] - df_train[f'first_active_month']).dt.days\n",
    "    df_test[f'{last_type}_first_buy']  = (df_test[f'{last_type}_auth1_purchase_date_min'] - df_test[f'first_active_month']).dt.days\n",
    "    \n",
    "    # 20180501までの期間を各データセットパターンで\n",
    "    df_train[f'{last_type}_auth1_term_from_now'] = (pd.to_datetime('2018-05-01') - df_train[f'{last_type}_auth1_purchase_date_max']).dt.days\n",
    "    df_train[f'{last_type}_auth0_term_from_now'] = (pd.to_datetime('2018-05-01') - df_train[f'{last_type}_auth0_purchase_date_max']).dt.days\n",
    "    df_test[f'{last_type}_auth1_term_from_now'] = (pd.to_datetime('2018-05-01') - df_test[f'{last_type}_auth1_purchase_date_max']).dt.days\n",
    "    df_test[f'{last_type}_auth0_term_from_now'] = (pd.to_datetime('2018-05-01') - df_test[f'{last_type}_auth0_purchase_date_max']).dt.days\n",
    "    \n",
    "    # cat0, auth1, auth0の間の期間\n",
    "    df_train[f'{last_type}_auth1_0_term'] = df_train[f'{last_type}_auth1_term_from_now'] - df_train[f'{last_type}_auth0_term_from_now']\n",
    "    df_test[f'{last_type}_auth1_0_term']  = df_test[f'{last_type}_auth1_term_from_now'] - df_test[f'{last_type}_auth0_term_from_now']\n",
    "    \n",
    "    \n",
    "# if last_type=='lag0_-2':\n",
    "if False\n",
    "    df_train[f'first_active_month'].fillna('2017-10', inplace=True)\n",
    "    df_train[f'first_active_month'] =  pd.to_datetime(df_train['first_active_month'])\n",
    "    df_train[f'{last_type}_unix_first_active_month'] =  df_train['first_active_month'].map(lambda x: x.timestamp())\n",
    "    \n",
    "    df_test[f'first_active_month'].fillna('2017-10', inplace=True)\n",
    "    df_test[f'first_active_month'] =  pd.to_datetime(df_test['first_active_month'])\n",
    "    df_test[f'{last_type}_unix_first_active_month'] =  df_test['first_active_month'].map(lambda x: x.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Impute\n",
    "for col in df_train.columns:\n",
    "    if col in ignore_list:continue\n",
    "    if str(type(df_test[col].dtypes)).count('time'):\n",
    "        df_train[col].fillna(df_train[col].min(), inplace=True)\n",
    "        df_test[col].fillna(df_train[col].min(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '165_fe3'\n",
    "fname = '167_fe3'\n",
    "fname = '168_fe3'\n",
    "fname = '169_fe3'\n",
    "fname = '172_fe4'\n",
    "fname = '173_fe4'\n",
    "ignore_features = ['unix_first_active_month', 'first_active_month', 'card_id', target]\n",
    "ignore_features = ['first_active_month', 'card_id', target]\n",
    "\n",
    "for col in df_train.columns:\n",
    "    if col in ignore_features: continue\n",
    "    if (col.count('feature_')):continue\n",
    "    if (col.count('purchase_date')):continue\n",
    "    feat_train = df_train[col].astype('float32').values\n",
    "    try:\n",
    "        feat_test = df_test[col].astype('float32').values\n",
    "    except TypeError:\n",
    "        print(col)\n",
    "        sys.exit()\n",
    "    utils.to_pkl_gzip(path = f'../features/1_first_valid/{fname}_train_{col}@', obj=feat_train)\n",
    "    utils.to_pkl_gzip(path = f'../features/1_first_valid/{fname}_test_{col}@', obj=feat_test)\n",
    "#     utils.to_pkl_gzip(path = f'../season1_features/1_first_valid/{fname}_train_{col}@', obj=feat_train)\n",
    "#     utils.to_pkl_gzip(path = f'../season1_features/1_first_valid/{fname}_test_{col}@', obj=feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# path_list = glob.glob('../features/1_first_valid/*.gz')\n",
    "# for path in path_list:\n",
    "#     length = utils.read_pkl_gzip(path).shape[0]\n",
    "#     if path.count('test'):\n",
    "#         print(length)\n",
    "#         if length>220000:\n",
    "#             print(path)\n",
    "#     if path.count('test'):\n",
    "#         if length>140000:\n",
    "#             print(path)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
