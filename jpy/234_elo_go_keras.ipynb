{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Preparing dataset...\n",
      "Train: (201917, 239) | Test: (123623, 239)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "is_LSTM = False\n",
    "is_remain = [True, False][1]\n",
    "is_plus = [True, False][1]\n",
    "out_part = ['all', 'clf_out', 'no_out_flg', 'no_out', 'clf'][0]\n",
    "set_no = [0,1,2,3][0]\n",
    "const_cnt = 1\n",
    "is_oof = [True, False][1]\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import glob\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "sys.path.append(f'{HOME}/kaggle/data_analysis/library')\n",
    "import utils\n",
    "from utils import logger_func, get_categorical_features, get_numeric_features, reduce_mem_usage, elo_save_feature, impute_feature\n",
    "try:\n",
    "    if not logger:\n",
    "        logger=logger_func()\n",
    "except NameError:\n",
    "    logger=logger_func()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
    "\n",
    "#========================================================================\n",
    "# Keras \n",
    "# Corporación Favorita Grocery Sales Forecasting\n",
    "sys.path.append(f'{HOME}/kaggle/data_analysis/model')\n",
    "from nn_keras import mercari_1st_NN, corp_1st_LSTM, RMSE\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# Args\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_active_month', 'index', 'personal_term', 'no_out_flg', 'clf_pred']\n",
    "stack_name='keras'\n",
    "model_type='keras'\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
    "seed = 328\n",
    "#========================================================================\n",
    "\n",
    "\n",
    "#========================================================================\n",
    "# Data Load \n",
    "print(\"Preparing dataset...\")\n",
    "# win_path = f'../features/4_winner/*.gz'\n",
    "# Ensemble 1\n",
    "set1 = f'../model/E1_set/*.gz'\n",
    "# Ensemble 2\n",
    "set2 = f'../model/E2_set/*.gz'\n",
    "# Ensemble 3\n",
    "set3 = f'../model/E3_set/*.gz'\n",
    "# Ensemble 4\n",
    "set4 = f'../model/E4_set/*.gz'\n",
    "\n",
    "set_list = [set1, set2, set3, set4]\n",
    "win_path = set_list[set_no]\n",
    "\n",
    "win_path_list = glob.glob(win_path)\n",
    "\n",
    "base = utils.read_pkl_gzip('../input/base_no_out_clf.gz')[[key, target, 'first_active_month', 'no_out_flg']]\n",
    "base_train = base[~base[target].isnull()].reset_index(drop=True)\n",
    "base_test = base[base[target].isnull()].reset_index(drop=True)\n",
    "feature_list = utils.parallel_load_data(path_list=win_path_list)\n",
    "df = pd.concat(feature_list, axis=1)\n",
    "train = pd.concat([base_train, df.iloc[:len(base_train), :]], axis=1)\n",
    "test = pd.concat([base_test, df.iloc[len(base_train):, :].reset_index(drop=True)], axis=1)\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "test.reset_index(inplace=True , drop=True)\n",
    "use_cols = [col for col in train.columns if col not in ignore_list]\n",
    "train_ids = train[key].values\n",
    "df_stack = train[[key, target]].copy().set_index(key)\n",
    "\n",
    "if out_part=='clf_out':\n",
    "#     train = train[train[target]>-30]\n",
    "    base_clf = utils.read_pkl_gzip('../input/base_clf.gz')[[key, 'clf_pred']]\n",
    "    train = train.merge(base_clf, on=key, how='inner')\n",
    "    train = train[train['clf_pred']<0.01]\n",
    "    test = test.merge(base_clf, on=key, how='inner')\n",
    "    test = test[test['clf_pred']<0.01]\n",
    "    \n",
    "    train.drop('clf_pred', axis=1, inplace=True)\n",
    "    test.drop('clf_pred', axis=1, inplace=True)\n",
    "elif out_part=='no_out_flg':\n",
    "    train = train[train['no_out_flg']==1]\n",
    "    test = test[test['no_out_flg']==1]\n",
    "    train.drop('no_out_flg', axis=1, inplace=True)\n",
    "    test.drop('no_out_flg', axis=1, inplace=True)\n",
    "elif out_part=='no_out':\n",
    "    train = train[train[target]>-30]\n",
    "elif out_part=='clf':\n",
    "    train[target] = train[target].map(lambda x: 1 if x<-30 else 0)\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# 正規化の前処理(Null埋め, inf, -infの処理) \n",
    "for col in train.columns:\n",
    "    if col in ignore_list: continue\n",
    "        \n",
    "    train[col] = impute_feature(train, col)\n",
    "    test[col] = impute_feature(test, col)\n",
    "#========================================================================\n",
    "\n",
    "\n",
    "#========================================================================\n",
    "# Construction Value Range Preprocessing\n",
    "def constraction(feature, is_viz=False, out_range=1.64):\n",
    "    if is_viz:\n",
    "        print('before:', feature.max(), feature.min())\n",
    "    std = feature.std()\n",
    "    avg = feature.mean()\n",
    "    z_val = (feature - avg)/std\n",
    "    \n",
    "    # Pass the Case No Outlier\n",
    "    try:\n",
    "        p_min = feature[feature>=out_range].min()\n",
    "        feature = np.where(z_val>=out_range, p_min, feature)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        m_max = feature[feature<=-1*out_range].max()\n",
    "        feature = np.where(z_val<=-1*out_range, m_max, feature)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    if is_viz:\n",
    "        print('after:', feature.max(), feature.min())   \n",
    "    return feature\n",
    "\n",
    "train_test = pd.concat([train, test], axis=0)\n",
    "for col in use_cols:\n",
    "    feature = train_test[col].values\n",
    "    \n",
    "    for i in range(const_cnt):\n",
    "        feature = constraction(feature)\n",
    "    \n",
    "    feature = feature.astype('float32')\n",
    "    train_test[col] = feature\n",
    "    \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_test[use_cols])\n",
    "    \n",
    "train = train_test[~train_test[target].isnull()]\n",
    "test = train_test[train_test[target].isnull()]\n",
    "\n",
    "if is_remain:\n",
    "    rem_train = train[train[target]>0].reset_index(drop=True)\n",
    "    train = train[train[target]<=0].reset_index(drop=True)\n",
    "    test = pd.concat([rem_train, test])\n",
    "    x_test = scaler.transform(test[use_cols])\n",
    "else:\n",
    "    x_test = scaler.transform(test[use_cols])\n",
    "         \n",
    "train[target] = 2**train[target]\n",
    "Y = train[target]\n",
    "\n",
    "# ========================================================================\n",
    "\n",
    "\n",
    "#========================================================================\n",
    "# CVの準備\n",
    "fold = 6\n",
    "if out_part == 'all' or out_part=='clf':\n",
    "#     kfold = utils.read_pkl_gzip('../input/kfold_ods_all_fold6_seed328.gz')\n",
    "    kfold = utils.read_pkl_gzip('../input/kfold_ods_equal_seed328.gz')\n",
    "# elif out_part=='clf_out':\n",
    "#     kfold = utils.read_pkl_gzip('../input/ods_clf001_thres_kfold.gz')\n",
    "# elif out_part=='no_out_flg':\n",
    "#     kfold = utils.read_pkl_gzip('../input/ods_no_out_flg_kfold.gz')\n",
    "elif out_part=='no_out':\n",
    "    kfold = utils.read_pkl_gzip('../input/kfold_ods_no_out_fold6_seed328.gz')\n",
    "# elif out_part=='clf':\n",
    "\n",
    "    \n",
    "if is_plus:\n",
    "    y_min = Y.min()\n",
    "    Y = Y - (y_min-1)\n",
    "\n",
    "# x_test = x_test.as_matrix()\n",
    "# For LSTM\n",
    "if is_LSTM:\n",
    "    x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "    \n",
    "    \n",
    "is_kfold = [True, False][1]\n",
    "if is_kfold:\n",
    "    fold_seed = 328\n",
    "    train['rounded_target'] = train['target'].round(0)\n",
    "    train = train.sort_values('rounded_target').reset_index(drop=True)\n",
    "    vc = train['rounded_target'].value_counts()\n",
    "    vc = dict(sorted(vc.items()))\n",
    "    df = pd.DataFrame()\n",
    "    train['indexcol'],i = 0,1\n",
    "    for k,v in vc.items():\n",
    "        step = train.shape[0]/v\n",
    "        indent = train.shape[0]/(v+1)\n",
    "        df2 = train[train['rounded_target'] == k].sample(v, random_state=120).reset_index(drop=True)\n",
    "        for j in range(0, v):\n",
    "            df2.at[j, 'indexcol'] = indent + j*step + 0.000001*i\n",
    "        df = pd.concat([df2,df])\n",
    "        i+=1\n",
    "    train = df.sort_values('indexcol', ascending=True).reset_index(drop=True)\n",
    "    del train['indexcol'], train['rounded_target']\n",
    "\n",
    "    folds = KFold(n_splits=6, shuffle=False, random_state=fold_seed)\n",
    "    kfold = list(folds.split(train, train[target].values))\n",
    "\n",
    "    # card_id listにする\n",
    "    trn_list = []\n",
    "    val_list = []\n",
    "    for trn, val in kfold:\n",
    "        trn_ids = train.iloc[trn][key].values\n",
    "        val_ids = train.iloc[val][key].values\n",
    "        trn_list.append(trn_ids)\n",
    "        val_list.append(val_ids)\n",
    "    kfold = [trn_list, val_list]\n",
    "\n",
    "print(f\"Train: {train.shape} | Test: {test.shape}\") \n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Target Min --- Train: 9.999999992192566e-11 Valid: 9.999999992192566e-11\n",
      "Target Min Count --- Train: 1839 Valid: 368\n",
      "Train on 168264 samples, validate on 33653 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 7.0959 - RMSE: 7.0959 - val_loss: 2.1425 - val_RMSE: 2.1425\n",
      "Epoch 2/30\n",
      " - 5s - loss: 7.0587 - RMSE: 7.0587 - val_loss: 2.1350 - val_RMSE: 2.1350\n",
      "Epoch 3/30\n",
      " - 5s - loss: 7.0535 - RMSE: 7.0535 - val_loss: 2.1336 - val_RMSE: 2.1336\n",
      "Epoch 4/30\n",
      " - 5s - loss: 7.0504 - RMSE: 7.0504 - val_loss: 2.1329 - val_RMSE: 2.1329\n",
      "Epoch 5/30\n",
      " - 5s - loss: 7.0483 - RMSE: 7.0483 - val_loss: 2.1334 - val_RMSE: 2.1334\n",
      "Epoch 6/30\n",
      " - 5s - loss: 7.0459 - RMSE: 7.0459 - val_loss: 2.1308 - val_RMSE: 2.1308\n",
      "Epoch 7/30\n",
      " - 5s - loss: 7.0435 - RMSE: 7.0435 - val_loss: 2.1318 - val_RMSE: 2.1318\n",
      "Epoch 8/30\n",
      " - 5s - loss: 7.0415 - RMSE: 7.0415 - val_loss: 2.1306 - val_RMSE: 2.1306\n",
      "Epoch 9/30\n",
      " - 5s - loss: 7.0394 - RMSE: 7.0394 - val_loss: 2.1309 - val_RMSE: 2.1309\n",
      "Epoch 10/30\n",
      " - 5s - loss: 7.0371 - RMSE: 7.0371 - val_loss: 2.1315 - val_RMSE: 2.1315\n",
      "RMSE: 27.24368217850991 | SUM ERROR: 53025.86679884061\n",
      "Target Min --- Train: 9.999999992192566e-11 Valid: 9.999999992192566e-11\n",
      "Target Min Count --- Train: 1840 Valid: 367\n",
      "Train on 168264 samples, validate on 33653 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 5.0073 - RMSE: 5.0073 - val_loss: 12.2747 - val_RMSE: 12.2747\n",
      "Epoch 2/30\n",
      " - 5s - loss: 5.0049 - RMSE: 5.0049 - val_loss: 12.2759 - val_RMSE: 12.2759\n",
      "Epoch 3/30\n",
      " - 5s - loss: 5.0027 - RMSE: 5.0027 - val_loss: 12.2779 - val_RMSE: 12.2779\n",
      "RMSE: 1210.9907017073588 | SUM ERROR: 395211.36235705664\n",
      "Target Min --- Train: 9.999999992192566e-11 Valid: 9.999999992192566e-11\n",
      "Target Min Count --- Train: 1838 Valid: 369\n",
      "Train on 168264 samples, validate on 33653 samples\n",
      "Epoch 1/30\n",
      " - 5s - loss: 6.7560 - RMSE: 6.7560 - val_loss: 3.5059 - val_RMSE: 3.5059\n",
      "Epoch 2/30\n",
      " - 5s - loss: 6.7530 - RMSE: 6.7530 - val_loss: 3.5072 - val_RMSE: 3.5072\n",
      "Epoch 3/30\n",
      " - 6s - loss: 6.7510 - RMSE: 6.7510 - val_loss: 3.5205 - val_RMSE: 3.5205\n",
      "RMSE: 222.8317500679371 | SUM ERROR: 97410.88542379651\n",
      "Target Min --- Train: 9.999999992192566e-11 Valid: 9.999999992192566e-11\n",
      "Target Min Count --- Train: 1840 Valid: 367\n",
      "Train on 168264 samples, validate on 33653 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 6.7061 - RMSE: 6.7061 - val_loss: 3.7251 - val_RMSE: 3.7251\n",
      "Epoch 2/30\n",
      " - 6s - loss: 6.7024 - RMSE: 6.7024 - val_loss: 3.7291 - val_RMSE: 3.7291\n",
      "Epoch 3/30\n",
      " - 6s - loss: 6.7008 - RMSE: 6.7008 - val_loss: 3.7308 - val_RMSE: 3.7308\n",
      "RMSE: 215.42999415669382 | SUM ERROR: 107749.79196193696\n",
      "Target Min --- Train: 9.999999992192566e-11 Valid: 9.999999992192566e-11\n",
      "Target Min Count --- Train: 1839 Valid: 368\n",
      "Train on 168264 samples, validate on 33653 samples\n",
      "Epoch 1/30\n",
      " - 6s - loss: 5.0678 - RMSE: 5.0678 - val_loss: 11.8887 - val_RMSE: 11.8887\n",
      "Epoch 2/30\n",
      " - 6s - loss: 5.0657 - RMSE: 5.0657 - val_loss: 11.8924 - val_RMSE: 11.8924\n",
      "Epoch 3/30\n",
      " - 6s - loss: 5.0626 - RMSE: 5.0626 - val_loss: 11.8958 - val_RMSE: 11.8958\n",
      "RMSE: 1423.1497068747256 | SUM ERROR: 383746.547295145\n",
      "Target Min --- Train: 9.999999992192566e-11 Valid: 9.999999992192566e-11\n",
      "Target Min Count --- Train: 1839 Valid: 368\n",
      "Train on 168265 samples, validate on 33652 samples\n",
      "Epoch 1/30\n",
      " - 7s - loss: 6.6928 - RMSE: 6.6928 - val_loss: 3.7408 - val_RMSE: 3.7408\n",
      "Epoch 2/30\n",
      " - 8s - loss: 6.6897 - RMSE: 6.6897 - val_loss: 3.7397 - val_RMSE: 3.7397\n",
      "Epoch 3/30\n",
      " - 8s - loss: 6.6865 - RMSE: 6.6865 - val_loss: 3.7448 - val_RMSE: 3.7448\n",
      "Epoch 4/30\n",
      " - 8s - loss: 6.6846 - RMSE: 6.6846 - val_loss: 3.7473 - val_RMSE: 3.7473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-23 02:06:11,218 utils 137 [INFO]    [<module>] \n",
      "#========================================================================\n",
      "# CV SCORE AVG: 549.4685156601846\n",
      "#======================================================================== \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 197.16525897588238 | SUM ERROR: 109643.95098735385\n",
      "Stacking Shape: (325540, 5)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nn_keras import mercari_1st_NN, corp_1st_LSTM, clf_NN\n",
    "#========================================================================\n",
    "# NN Model Setting \n",
    "N_EPOCHS = 15\n",
    "N_EPOCHS = 30\n",
    "# N_EPOCHS = 10\n",
    "# learning_rate = 1e-5\n",
    "# learning_rate = 1e-4\n",
    "learning_rate = 1e-3\n",
    "# lerning_rate = 3e-3\n",
    "\n",
    "is_LSTM = False\n",
    "break_cnt=0\n",
    "first_batch=6 # 7: 128\n",
    "first_batch=7 # 7: 128\n",
    "\n",
    "if is_LSTM:\n",
    "    model = corp_1st_LSTM(input_rows=1, input_cols=len(use_cols))\n",
    "    metric = RMSE\n",
    "elif out_part=='clf':\n",
    "    model = clf_NN(input_cols=len(use_cols))\n",
    "    metric = 'binary_crossentropy'\n",
    "else:\n",
    "    model = mercari_1st_NN(input_cols=len(use_cols))\n",
    "    metric = RMSE\n",
    "\n",
    "opt = optimizers.Adam(lr=learning_rate)\n",
    "model.compile(loss=metric, optimizer=opt, metrics=[metric])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "]\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# Result Box\n",
    "model_list = []\n",
    "result_list = []\n",
    "score_list = []\n",
    "val_pred_list = []\n",
    "test_pred = np.zeros(len(test))\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# Train & Prediction Start\n",
    "\n",
    "for fold_no, (trn_idx, val_idx) in enumerate(zip(*kfold)):\n",
    "\n",
    "    #========================================================================\n",
    "    # Make Dataset\n",
    "    X_train, y_train = train.loc[train[key].isin(trn_idx), :][use_cols], Y.loc[train[key].isin(trn_idx)]\n",
    "    X_val, y_val = train.loc[train[key].isin(val_idx), :][use_cols], Y.loc[train[key].isin(val_idx)]\n",
    "    print(f\"Target Min --- Train: {y_train.min()} Valid: {y_val.min()}\")\n",
    "    print(f\"Target Min Count --- Train: {np.sum(y_train==y_train.min())} Valid: {np.sum(y_val==y_val.min())}\")\n",
    "    \n",
    "    X_train[:] = scaler.transform(X_train)\n",
    "    X_val[:] = scaler.transform(X_val)\n",
    "    X_train = X_train.as_matrix()\n",
    "    X_val = X_val.as_matrix()\n",
    "    \n",
    "    if is_LSTM:\n",
    "        X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "    #========================================================================\n",
    "    \n",
    "    cnt = -1\n",
    "    while True:\n",
    "        cnt+=1\n",
    "        # Fitting\n",
    "        # なぜか平均を引いてる？そのほうがfitするの？\n",
    "        # model.fit(X_train, y- y_mean, batch_size = batch_size, epochs = N_EPOCHS, verbose=2,\n",
    "        #            validation_data=(X_val, y_val - y_mean), callbacks=callbacks )\n",
    "    #     model.fit(X_train, y_train, batch_size = batch_size, epochs = N_EPOCHS, verbose=2,\n",
    "    #                validation_data=(X_val, y_val), callbacks=callbacks )\n",
    "        \n",
    "        batch_size = 2**(first_batch + cnt)\n",
    "        model.fit(x=X_train, y=y_train, validation_data=(X_val, y_val)\n",
    "                  , batch_size=2**(first_batch + cnt), epochs=N_EPOCHS\n",
    "                  , verbose=2, callbacks=callbacks)\n",
    "\n",
    "        # Prediction\n",
    "        if is_oof:\n",
    "            val_id_list = list(set(train_ids) - set(trn_idx))\n",
    "            X_val = train.loc[train[key].isin(val_id_list), :][use_cols]\n",
    "            y_val = Y.loc[train[key].isin(val_id_list)]\n",
    "            y_pred = model.predict(X_val)\n",
    "            tmp_val = train.loc[train[key].isin(val_id_list), :][[key, target]].set_index(key)\n",
    "            tmp_val['prediction'] = y_pred\n",
    "            df_stack['pred_{fold_no}'] = tmp_val['prediction']\n",
    "            del tmp_val\n",
    "            gc.collect()\n",
    "        else:\n",
    "            y_pred = model.predict(X_val)\n",
    "        out_cnt = (y_pred==np.inf).sum()+(y_pred==-np.inf).sum()+(y_pred!=y_pred).sum()\n",
    "        \n",
    "        if out_cnt>0:\n",
    "            print(\"Exist Inf or NaN\")\n",
    "            sys.exit()\n",
    "            \n",
    "        break\n",
    "    \n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], )\n",
    "    tmp_pred = model.predict(x_test)\n",
    "    test_pred += tmp_pred.reshape(tmp_pred.shape[0], )\n",
    "    test['prediction'] = test_pred\n",
    "    test = test[[key, 'prediction']]\n",
    "    \n",
    "    if is_plus:\n",
    "        y_val += (y_min-1)\n",
    "        y_pred += (y_min-1)\n",
    "        test_pred += (y_min-1)\n",
    "#     model_list.append(model)\n",
    "    \n",
    "    # Stack Prediction\n",
    "    df_pred = train.loc[train[key].isin(val_idx), :][[key, target]].copy()\n",
    "    df_pred['prediction'] = y_pred\n",
    "    result_list.append(df_pred)\n",
    "    \n",
    "    # Scoring\n",
    "    if out_part=='clf':\n",
    "        score = roc_auc_score(y_val, y_pred)\n",
    "        print(f'AUC: {score}')\n",
    "    else:\n",
    "        err = (y_val - y_pred)\n",
    "        score = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        print(f'RMSE: {score} | SUM ERROR: {err.sum()}')\n",
    "    score_list.append(score)\n",
    "    #========================================================================\n",
    "\n",
    "cv_score = np.mean(score_list)\n",
    "logger.info(f'''\n",
    "#========================================================================\n",
    "# CV SCORE AVG: {cv_score}\n",
    "#========================================================================''')\n",
    "\n",
    "#========================================================================\n",
    "# Stacking\n",
    "if is_oof:\n",
    "    pred_cols = [col for col in df_stack.columns if col.count('pred_')]\n",
    "    df_stack['prediction'] = df_stack[pred_cols].mean(axis=1)\n",
    "    df_stack.drop(pred_cols, axis=1, inplace=True)\n",
    "    df_stack.reset_index(inplace=True)\n",
    "    df_stack = pd.concat([df_stack, test], axis=0, ignore_index=True)\n",
    "    print(f\"DF Stack Shape: {df_stack.shape}\")    \n",
    "else:\n",
    "    test_pred /= fold\n",
    "    test['prediction'] = test_pred\n",
    "    stack_test = test[[key, 'prediction']]\n",
    "    result_list.append(stack_test)\n",
    "    df_pred = pd.concat(result_list, axis=0, ignore_index=True).drop(target, axis=1)\n",
    "    df_stack = base.merge(df_pred, how='inner', on=key)\n",
    "    print(f\"Stacking Shape: {df_stack.shape}\")\n",
    "    del df_pred\n",
    "    gc.collect()\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.to_pkl_gzip(obj=df_stack[[key, target, 'prediction']], path=f'../stack/{start_time[4:12]}_elo_NN_stack_E{set_no+1}_row{len(train)}_outpart-{out_part}_{len(use_cols)}feat_const{const_cnt}_lr{learning_rate}_batch{batch_size}_epoch{N_EPOCHS}_CV{cv_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stack['new_prediction'] = df_stack['prediction'].map(lambda x: np.log2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>new_target</th>\n",
       "      <th>new_prediction</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101046</th>\n",
       "      <td>4.638363</td>\n",
       "      <td>2.490499e+01</td>\n",
       "      <td>4.208998</td>\n",
       "      <td>18.494162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152693</th>\n",
       "      <td>6.175019</td>\n",
       "      <td>7.225469e+01</td>\n",
       "      <td>4.062174</td>\n",
       "      <td>16.704609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180489</th>\n",
       "      <td>5.134202</td>\n",
       "      <td>3.511955e+01</td>\n",
       "      <td>4.041325</td>\n",
       "      <td>16.464941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261648</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.976009</td>\n",
       "      <td>15.736128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128575</th>\n",
       "      <td>3.618411</td>\n",
       "      <td>1.228147e+01</td>\n",
       "      <td>3.931528</td>\n",
       "      <td>15.258364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140908</th>\n",
       "      <td>4.026417</td>\n",
       "      <td>1.629567e+01</td>\n",
       "      <td>3.915574</td>\n",
       "      <td>15.090552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150223</th>\n",
       "      <td>2.370789</td>\n",
       "      <td>5.172241e+00</td>\n",
       "      <td>3.877187</td>\n",
       "      <td>14.694324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233388</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.848916</td>\n",
       "      <td>14.409176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289923</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.834788</td>\n",
       "      <td>14.268755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48103</th>\n",
       "      <td>9.242588</td>\n",
       "      <td>6.057539e+02</td>\n",
       "      <td>3.801656</td>\n",
       "      <td>13.944806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275511</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.782906</td>\n",
       "      <td>13.764750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294951</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.775295</td>\n",
       "      <td>13.692320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296468</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.717510</td>\n",
       "      <td>13.154732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102708</th>\n",
       "      <td>7.333495</td>\n",
       "      <td>1.612880e+02</td>\n",
       "      <td>3.712612</td>\n",
       "      <td>13.110147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46345</th>\n",
       "      <td>5.188275</td>\n",
       "      <td>3.646082e+01</td>\n",
       "      <td>3.710229</td>\n",
       "      <td>13.088510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72257</th>\n",
       "      <td>6.314243</td>\n",
       "      <td>7.957500e+01</td>\n",
       "      <td>3.707822</td>\n",
       "      <td>13.066689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28515</th>\n",
       "      <td>6.053691</td>\n",
       "      <td>6.642667e+01</td>\n",
       "      <td>3.671946</td>\n",
       "      <td>12.745764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102598</th>\n",
       "      <td>3.686977</td>\n",
       "      <td>1.287926e+01</td>\n",
       "      <td>3.670070</td>\n",
       "      <td>12.729198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125896</th>\n",
       "      <td>-0.852648</td>\n",
       "      <td>5.537675e-01</td>\n",
       "      <td>3.668480</td>\n",
       "      <td>12.715178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184327</th>\n",
       "      <td>5.338200</td>\n",
       "      <td>4.045372e+01</td>\n",
       "      <td>3.663379</td>\n",
       "      <td>12.670306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257905</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.658301</td>\n",
       "      <td>12.625781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287342</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.656765</td>\n",
       "      <td>12.612351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322991</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.653697</td>\n",
       "      <td>12.585556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215156</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.645556</td>\n",
       "      <td>12.514737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75874</th>\n",
       "      <td>4.630476</td>\n",
       "      <td>2.476920e+01</td>\n",
       "      <td>3.641543</td>\n",
       "      <td>12.479975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229678</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.633739</td>\n",
       "      <td>12.412648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142559</th>\n",
       "      <td>4.694160</td>\n",
       "      <td>2.588707e+01</td>\n",
       "      <td>3.618414</td>\n",
       "      <td>12.281495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73982</th>\n",
       "      <td>3.709039</td>\n",
       "      <td>1.307772e+01</td>\n",
       "      <td>3.609525</td>\n",
       "      <td>12.206055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265042</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.609219</td>\n",
       "      <td>12.203463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274179</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.569892</td>\n",
       "      <td>11.875301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208959</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.216161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60447</th>\n",
       "      <td>-5.132533</td>\n",
       "      <td>2.850715e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.219981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109718</th>\n",
       "      <td>-0.888553</td>\n",
       "      <td>5.401555e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.221542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181706</th>\n",
       "      <td>-0.186989</td>\n",
       "      <td>8.784369e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.227886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247648</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.239223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35976</th>\n",
       "      <td>-1.822384</td>\n",
       "      <td>2.827533e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.251281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160638</th>\n",
       "      <td>-2.041457</td>\n",
       "      <td>2.429183e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.252553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201012</th>\n",
       "      <td>-33.219281</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.252559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143346</th>\n",
       "      <td>-33.219281</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.254165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157659</th>\n",
       "      <td>1.865713</td>\n",
       "      <td>3.644481e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.255844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108689</th>\n",
       "      <td>-3.815091</td>\n",
       "      <td>7.104660e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.258938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76806</th>\n",
       "      <td>-3.879679</td>\n",
       "      <td>6.793606e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.289116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136615</th>\n",
       "      <td>4.442723</td>\n",
       "      <td>2.174668e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.291462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145672</th>\n",
       "      <td>-1.499439</td>\n",
       "      <td>3.536908e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.320952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196945</th>\n",
       "      <td>-6.002743</td>\n",
       "      <td>1.559532e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.342229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662</th>\n",
       "      <td>-2.434347</td>\n",
       "      <td>1.850072e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.343954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249533</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.360340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113920</th>\n",
       "      <td>-2.494519</td>\n",
       "      <td>1.774496e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.384122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85329</th>\n",
       "      <td>-33.219281</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.390455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294599</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.402630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114490</th>\n",
       "      <td>-3.011268</td>\n",
       "      <td>1.240275e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.407162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156357</th>\n",
       "      <td>-2.242939</td>\n",
       "      <td>2.112555e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.428696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155438</th>\n",
       "      <td>-33.219281</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.441437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192008</th>\n",
       "      <td>-33.219281</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.478879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161535</th>\n",
       "      <td>-1.160465</td>\n",
       "      <td>4.473684e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.483884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178805</th>\n",
       "      <td>-33.219281</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.538705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186515</th>\n",
       "      <td>-1.502373</td>\n",
       "      <td>3.529724e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.550524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131095</th>\n",
       "      <td>1.978943</td>\n",
       "      <td>3.942042e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63685</th>\n",
       "      <td>-0.675270</td>\n",
       "      <td>6.262150e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.699393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119056</th>\n",
       "      <td>-33.219281</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.059758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325540 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           target    new_target  new_prediction  prediction\n",
       "101046   4.638363  2.490499e+01        4.208998   18.494162\n",
       "152693   6.175019  7.225469e+01        4.062174   16.704609\n",
       "180489   5.134202  3.511955e+01        4.041325   16.464941\n",
       "261648        NaN           NaN        3.976009   15.736128\n",
       "128575   3.618411  1.228147e+01        3.931528   15.258364\n",
       "140908   4.026417  1.629567e+01        3.915574   15.090552\n",
       "150223   2.370789  5.172241e+00        3.877187   14.694324\n",
       "233388        NaN           NaN        3.848916   14.409176\n",
       "289923        NaN           NaN        3.834788   14.268755\n",
       "48103    9.242588  6.057539e+02        3.801656   13.944806\n",
       "275511        NaN           NaN        3.782906   13.764750\n",
       "294951        NaN           NaN        3.775295   13.692320\n",
       "296468        NaN           NaN        3.717510   13.154732\n",
       "102708   7.333495  1.612880e+02        3.712612   13.110147\n",
       "46345    5.188275  3.646082e+01        3.710229   13.088510\n",
       "72257    6.314243  7.957500e+01        3.707822   13.066689\n",
       "28515    6.053691  6.642667e+01        3.671946   12.745764\n",
       "102598   3.686977  1.287926e+01        3.670070   12.729198\n",
       "125896  -0.852648  5.537675e-01        3.668480   12.715178\n",
       "184327   5.338200  4.045372e+01        3.663379   12.670306\n",
       "257905        NaN           NaN        3.658301   12.625781\n",
       "287342        NaN           NaN        3.656765   12.612351\n",
       "322991        NaN           NaN        3.653697   12.585556\n",
       "215156        NaN           NaN        3.645556   12.514737\n",
       "75874    4.630476  2.476920e+01        3.641543   12.479975\n",
       "229678        NaN           NaN        3.633739   12.412648\n",
       "142559   4.694160  2.588707e+01        3.618414   12.281495\n",
       "73982    3.709039  1.307772e+01        3.609525   12.206055\n",
       "265042        NaN           NaN        3.609219   12.203463\n",
       "274179        NaN           NaN        3.569892   11.875301\n",
       "...           ...           ...             ...         ...\n",
       "208959        NaN           NaN             NaN   -0.216161\n",
       "60447   -5.132533  2.850715e-02             NaN   -0.219981\n",
       "109718  -0.888553  5.401555e-01             NaN   -0.221542\n",
       "181706  -0.186989  8.784369e-01             NaN   -0.227886\n",
       "247648        NaN           NaN             NaN   -0.239223\n",
       "35976   -1.822384  2.827533e-01             NaN   -0.251281\n",
       "160638  -2.041457  2.429183e-01             NaN   -0.252553\n",
       "201012 -33.219281  1.000000e-10             NaN   -0.252559\n",
       "143346 -33.219281  1.000000e-10             NaN   -0.254165\n",
       "157659   1.865713  3.644481e+00             NaN   -0.255844\n",
       "108689  -3.815091  7.104660e-02             NaN   -0.258938\n",
       "76806   -3.879679  6.793606e-02             NaN   -0.289116\n",
       "136615   4.442723  2.174668e+01             NaN   -0.291462\n",
       "145672  -1.499439  3.536908e-01             NaN   -0.320952\n",
       "196945  -6.002743  1.559532e-02             NaN   -0.342229\n",
       "12662   -2.434347  1.850072e-01             NaN   -0.343954\n",
       "249533        NaN           NaN             NaN   -0.360340\n",
       "113920  -2.494519  1.774496e-01             NaN   -0.384122\n",
       "85329  -33.219281  1.000000e-10             NaN   -0.390455\n",
       "294599        NaN           NaN             NaN   -0.402630\n",
       "114490  -3.011268  1.240275e-01             NaN   -0.407162\n",
       "156357  -2.242939  2.112555e-01             NaN   -0.428696\n",
       "155438 -33.219281  1.000000e-10             NaN   -0.441437\n",
       "192008 -33.219281  1.000000e-10             NaN   -0.478879\n",
       "161535  -1.160465  4.473684e-01             NaN   -0.483884\n",
       "178805 -33.219281  1.000000e-10             NaN   -0.538705\n",
       "186515  -1.502373  3.529724e-01             NaN   -0.550524\n",
       "131095   1.978943  3.942042e+00             NaN   -0.671875\n",
       "63685   -0.675270  6.262150e-01             NaN   -0.699393\n",
       "119056 -33.219281  1.000000e-10             NaN   -1.059758\n",
       "\n",
       "[325540 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_stack['new_target'] = 2**df_stack[target]\n",
    "df_stack[[target, 'new_target', 'new_prediction', 'prediction']].sort_values(by='prediction', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_stack[~df_stack[target].isnull()]\n",
    "y_train = train[target].values\n",
    "y_pred = train['prediction'].values\n",
    "score = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print(f'RMSE: {score}')\n",
    "utils.to_pkl_gzip(obj=df_stack, path=f'../stack/{start_time[4:12]}_elo_NN_stack_E{set_no+1}_row{len(train)}_outpart-{out_part}_{len(use_cols)}feat_const{const_cnt}_lr{learning_rate}_batch{batch_size}_epoch{N_EPOCHS}_CV{cv_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
