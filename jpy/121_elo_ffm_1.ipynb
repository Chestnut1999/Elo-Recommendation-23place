{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-31 00:18:54,125 utils 366 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import gc\n",
    "import os\n",
    "\n",
    "#========================================================================\n",
    "# Args\n",
    "#========================================================================\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_active_month']\n",
    "\n",
    "win_path = f'../features/4_winner/*.gz'\n",
    "fname=''\n",
    "# submit = pd.read_csv('../input/sample_submission.csv')\n",
    "submit = []\n",
    "\n",
    "HOME = os.path.expanduser('~')\n",
    "\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "import utils\n",
    "from preprocessing import get_ordinal_mapping\n",
    "from utils import logger_func\n",
    "try:\n",
    "    if not logger:\n",
    "        logger=logger_func()\n",
    "except NameError:\n",
    "    logger=logger_func()\n",
    "\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# Data Load\n",
    "base = utils.read_df_pkl('../input/base*')\n",
    "win_path_list = glob.glob(win_path)\n",
    "train_path_list = []\n",
    "test_path_list = []\n",
    "for path in win_path_list:\n",
    "    if path.count('train'):\n",
    "        train_path_list.append(path)\n",
    "    elif path.count('test'):\n",
    "        test_path_list.append(path)\n",
    "\n",
    "base_train = base[~base[target].isnull()].reset_index(drop=True)\n",
    "base_test = base[base[target].isnull()].reset_index(drop=True)\n",
    "train_feature_list = utils.parallel_load_data(path_list=train_path_list)\n",
    "test_feature_list = utils.parallel_load_data(path_list=test_path_list)\n",
    "train = pd.concat(train_feature_list, axis=1)\n",
    "train = pd.concat([base_train, train], axis=1)\n",
    "test = pd.concat(test_feature_list, axis=1)\n",
    "test = pd.concat([base_test, test], axis=1)\n",
    "\n",
    "train_id = train[key].values\n",
    "test_id = test[key].values\n",
    "\n",
    "y = train[[key, target]]\n",
    "# y[target] = y[target].map(lambda x: 1 if x<-30 else 0)\n",
    "train.drop(target, axis=1, inplace=True)\n",
    "\n",
    "for col in train.columns:\n",
    "    if len(train[train[col].isnull()])==0 or len(test[test[col].isnull()])==0:\n",
    "        continue\n",
    "        \n",
    "    imp_train = train[col].median()\n",
    "    imp_test = test[col].median()\n",
    "    \n",
    "    train[col].fillna(imp_train, inplace=True)\n",
    "    test[col].fillna(imp_test, inplace=True)\n",
    "\n",
    "print(train.shape)\n",
    "# FFMは最後の列がラベルになる\n",
    "train.sort_index(axis=1, inplace=True)\n",
    "test.sort_index(axis=1, inplace=True)\n",
    "train = train.merge(y, how='inner', on=key)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed = 1208\n",
    "\n",
    "train['outliers'] = train[target].map(lambda x: 1 if x<-30 else 0)\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "outliers = train['outliers'].values\n",
    "train.drop('outliers', axis=1, inplace=True)\n",
    "kfold = folds.split(train, outliers)\n",
    "\n",
    "train[target] =  train[target].map(lambda x: 1 if x<-30 else 0)\n",
    "y = train[target]\n",
    "\n",
    "use_cols = [col for col in train.columns if col not in ignore_list]\n",
    "\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(kfold):\n",
    "    x_train, y_train = train[use_cols].iloc[trn_idx, :].values, y.iloc[trn_idx].values\n",
    "    x_val, y_val = train[use_cols].iloc[val_idx, :].values, y.iloc[val_idx].values\n",
    "    \n",
    "    y_train = y_train.astype('int8')\n",
    "    y_val = y_val.astype('int8')\n",
    "    \n",
    "    tmp = np.hstack((x_train, y_train.reshape(len(y_train), 1)))\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.to_csv(f'../input/ffm_train_{n_fold}.csv', index=False, header=False)\n",
    "    del tmp\n",
    "    gc.collect()\n",
    "    \n",
    "    tmp = np.hstack((x_val, y_val.reshape(len(y_val), 1)))\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.to_csv(f'../input/ffm_val_{n_fold}.csv', index=False, header=False)\n",
    "    del tmp\n",
    "    gc.collect()\n",
    "    sys.exit()\n",
    "    \n",
    "train.to_csv('../input/ffm_train.csv', index=False)\n",
    "test.to_csv('../input/ffm_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import xlearn as xl\n",
    "\n",
    "ffm_model = xl.FFMModel(task='binary', \n",
    "                        lr=0.2, \n",
    "                        epoch=10, \n",
    "                        reg_lambda=0.02,\n",
    "                        metric='rmse')\n",
    "# Start to train\n",
    "# Directly use string to specify data source\n",
    "ffm_model.fit('../input/ffm_train_0.csv', \n",
    "              eval_set='../input/ffm_val_0.csv'\n",
    "             )\n",
    "\n",
    "# print model weights\n",
    "print(ffm_model.weights)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = ffm_model.predict('../input/ffm_test.csv')\n",
    "sys.exit()\n",
    "\n",
    "\n",
    "# Training task\n",
    "ffm_model = xl.create_ffm()  # Use field-aware factorization machine\n",
    "ffm_model.setTrain(\"../input/ffm_train.csv\")   # Training data\n",
    "# ffm_model.setValidate(\"../input/titanic_test.txt\")  # Validation data\n",
    "\n",
    "# param:\n",
    "#  0. binary classification\n",
    "#  1. learning rate : 0.2\n",
    "#  2. regular lambda : 0.002\n",
    "param = {'task':'binary', 'lr':0.1, 'lambda':0.02, 'metric':'auc'}\n",
    "# param = {'task':'reg', 'lr':0.1, 'lambda':0.02}\n",
    "\n",
    "# Train model\n",
    "ffm_model.cv(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
