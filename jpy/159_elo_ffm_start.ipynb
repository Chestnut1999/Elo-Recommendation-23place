{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFM\n",
    "FFM用のDatasetを作成し、kerasで実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-12 17:25:36,940 utils 366 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import gc\n",
    "import os\n",
    "\n",
    "#========================================================================\n",
    "# Args\n",
    "#========================================================================\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_active_month']\n",
    "\n",
    "HOME = os.path.expanduser('~')\n",
    "\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "import utils\n",
    "from preprocessing import get_ordinal_mapping, get_dummies\n",
    "from utils import logger_func\n",
    "try:\n",
    "    if not logger:\n",
    "        logger=logger_func()\n",
    "except NameError:\n",
    "    logger=logger_func()\n",
    "\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 36.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "      <th>110_ker_auth_category_2_1_0_mean</th>\n",
       "      <th>110_ker_auth_category_2_2_0_mean</th>\n",
       "      <th>110_ker_auth_category_2_3_0_mean</th>\n",
       "      <th>110_ker_auth_category_2_4_0_mean</th>\n",
       "      <th>110_ker_auth_category_2_5_0_mean</th>\n",
       "      <th>110_ker_auth_category_3_A_mean</th>\n",
       "      <th>110_ker_auth_category_3_B_mean</th>\n",
       "      <th>110_ker_hist_category_2_1_0_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>110_ker_hist_category_2_4_0_mean</th>\n",
       "      <th>110_ker_hist_category_2_5_0_mean</th>\n",
       "      <th>110_ker_hist_category_3_A_mean</th>\n",
       "      <th>110_ker_hist_category_3_B_mean</th>\n",
       "      <th>110_ker_hist_category_3_C_mean</th>\n",
       "      <th>110_ker_new_category_2_1_0_mean</th>\n",
       "      <th>110_ker_new_category_2_2_0_mean</th>\n",
       "      <th>110_ker_new_category_2_3_0_mean</th>\n",
       "      <th>110_ker_new_category_2_4_0_mean</th>\n",
       "      <th>110_ker_new_category_2_5_0_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>0.987854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.802360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target  110_ker_auth_category_2_1_0_mean  \\\n",
       "0  C_ID_92a2005557 -0.820283                          0.987854   \n",
       "1  C_ID_3d0044924f  0.392913                          1.000000   \n",
       "2  C_ID_d639edf6cd  0.688056                          0.097561   \n",
       "3  C_ID_186d6a6901  0.142495                          0.311688   \n",
       "4  C_ID_cdbd2c0db2 -0.159749                          0.171875   \n",
       "\n",
       "   110_ker_auth_category_2_2_0_mean  110_ker_auth_category_2_3_0_mean  \\\n",
       "0                               0.0                               0.0   \n",
       "1                               0.0                               0.0   \n",
       "2                               0.0                               0.0   \n",
       "3                               0.0                               0.0   \n",
       "4                               0.0                               0.0   \n",
       "\n",
       "   110_ker_auth_category_2_4_0_mean  110_ker_auth_category_2_5_0_mean  \\\n",
       "0                          0.000000                          0.012146   \n",
       "1                          0.000000                          0.000000   \n",
       "2                          0.000000                          0.902439   \n",
       "3                          0.688312                          0.000000   \n",
       "4                          0.820312                          0.007812   \n",
       "\n",
       "   110_ker_auth_category_3_A_mean  110_ker_auth_category_3_B_mean  \\\n",
       "0                        1.000000                        0.000000   \n",
       "1                        0.005900                        0.802360   \n",
       "2                        1.000000                        0.000000   \n",
       "3                        0.025974                        0.883117   \n",
       "4                        0.000000                        0.968750   \n",
       "\n",
       "   110_ker_hist_category_2_1_0_mean               ...                 \\\n",
       "0                               1.0               ...                  \n",
       "1                               1.0               ...                  \n",
       "2                               0.0               ...                  \n",
       "3                               1.0               ...                  \n",
       "4                               0.6               ...                  \n",
       "\n",
       "   110_ker_hist_category_2_4_0_mean  110_ker_hist_category_2_5_0_mean  \\\n",
       "0                               0.0                               0.0   \n",
       "1                               0.0                               0.0   \n",
       "2                               0.0                               1.0   \n",
       "3                               0.0                               0.0   \n",
       "4                               0.4                               0.0   \n",
       "\n",
       "   110_ker_hist_category_3_A_mean  110_ker_hist_category_3_B_mean  \\\n",
       "0                        0.692308                        0.307692   \n",
       "1                        0.000000                        0.363636   \n",
       "2                        1.000000                        0.000000   \n",
       "3                        0.333333                        0.318182   \n",
       "4                        0.000000                        0.400000   \n",
       "\n",
       "   110_ker_hist_category_3_C_mean  110_ker_new_category_2_1_0_mean  \\\n",
       "0                        0.000000                         1.000000   \n",
       "1                        0.636364                         1.000000   \n",
       "2                        0.000000                         0.000000   \n",
       "3                        0.000000                         0.142857   \n",
       "4                        0.600000                         0.111111   \n",
       "\n",
       "   110_ker_new_category_2_2_0_mean  110_ker_new_category_2_3_0_mean  \\\n",
       "0                              0.0                         0.000000   \n",
       "1                              0.0                         0.000000   \n",
       "2                              0.0                         0.000000   \n",
       "3                              0.0                         0.000000   \n",
       "4                              0.0                         0.194444   \n",
       "\n",
       "   110_ker_new_category_2_4_0_mean  110_ker_new_category_2_5_0_mean  \n",
       "0                         0.000000                              0.0  \n",
       "1                         0.000000                              0.0  \n",
       "2                         0.000000                              1.0  \n",
       "3                         0.857143                              0.0  \n",
       "4                         0.694444                              0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Data Load\n",
    "base = utils.read_df_pkl('../input/base*')\n",
    "win_path = f'../features/4_winner/*.gz'\n",
    "win_path_list = glob.glob(win_path)\n",
    "train_path_list = []\n",
    "test_path_list = []\n",
    "for path in win_path_list:\n",
    "    if path.count('train'):\n",
    "        train_path_list.append(path)\n",
    "    elif path.count('test'):\n",
    "        test_path_list.append(path)\n",
    "\n",
    "train_path_list = sorted(train_path_list)[:20]\n",
    "test_path_list  = sorted(test_path_list)[:20]\n",
    "        \n",
    "base_train = base[~base[target].isnull()].reset_index(drop=True)\n",
    "base_test = base[base[target].isnull()].reset_index(drop=True)\n",
    "train_feature_list = utils.parallel_load_data(path_list=train_path_list)\n",
    "test_feature_list = utils.parallel_load_data(path_list=test_path_list)\n",
    "train = pd.concat(train_feature_list, axis=1)\n",
    "train = pd.concat([base_train, train], axis=1)\n",
    "test = pd.concat(test_feature_list, axis=1)\n",
    "test = pd.concat([base_test, test], axis=1)\n",
    "\n",
    "train.fillna(train.median(), inplace=True)\n",
    "test.fillna(test.median(), inplace=True)\n",
    "\n",
    "train.head()\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load & FFM Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161533, 20)\n",
      "(40384, 20)\n",
      "(123623, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_list = [col for col in train.columns if str(train[col].dtype).count('int') or str(train[col].dtype).count('float') ]\n",
    "\n",
    "train = train[num_list]\n",
    "num_list.remove(target)\n",
    "test = test[num_list]\n",
    "\n",
    "train, valid = train_test_split(train, test_size=0.2)\n",
    "tmp_y_train = train[target].map(lambda x: 1 if x<-30 else 0)\n",
    "tmp_y_valid = valid[target].map(lambda x: 1 if x<-30 else 0)\n",
    "train.drop(target, axis=1, inplace=True)\n",
    "valid.drop(target, axis=1, inplace=True)\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161533, 20)\n",
      "(161533, 1)\n",
      "(40384, 20)\n",
      "(40384, 1)\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "len_train = len(train)\n",
    "len_valid = len(valid)\n",
    "len_test = len(test)\n",
    "len_feats = len(train.columns)\n",
    "\n",
    "train_val = train.values\n",
    "y_train_val = tmp_y_train.values\n",
    "valid_val = valid.values\n",
    "y_valid_val = tmp_y_valid.values\n",
    "test_val = test.values\n",
    "\n",
    "x_train = train_val.reshape(len_train, len_feats)\n",
    "y_train = y_train_val.reshape(len_train, 1)\n",
    "x_valid = valid_val.reshape(len_valid, len_feats)\n",
    "y_valid = y_valid_val.reshape(len_valid, 1)\n",
    "x_test = test_val.reshape(len_test, len_feats)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "\n",
    "x_train = [i for i in x_train.T]\n",
    "x_valid = [i for i in x_valid.T]\n",
    "x_test = [i for i in x_test.T]\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_valid))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dd1e2069890b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from keras.layers import Input, Embedding, Dense,Flatten, Activation, dot, add\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2 as l2_reg\n",
    "from keras import initializers\n",
    "import itertools\n",
    "\n",
    "\n",
    "def make_batches(size, batch_size):\n",
    "    nb_batch = int(np.ceil(size/float(batch_size)))\n",
    "    return [(i*batch_size, min(size, (i+1)*batch_size)) for i in range(0, nb_batch)]\n",
    "\n",
    "\n",
    "def batch_generator(X,y,batch_size=128,shuffle=True):\n",
    "    sample_size = X[0].shape[0]\n",
    "    index_array = np.arange(sample_size)\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(index_array)\n",
    "        batches = make_batches(sample_size, batch_size)\n",
    "        for batch_index, (batch_start, batch_end) in enumerate(batches):\n",
    "            batch_ids = index_array[batch_start:batch_end]\n",
    "            X_batch = [X[i][batch_ids] for i in range(len(X))]\n",
    "            y_batch = y[batch_ids]\n",
    "            yield X_batch,y_batch\n",
    "\n",
    "\n",
    "def test_batch_generator(X,y,batch_size=128):\n",
    "    sample_size = X[0].shape[0]\n",
    "    index_array = np.arange(sample_size)\n",
    "    batches = make_batches(sample_size, batch_size)\n",
    "    for batch_index, (batch_start, batch_end) in enumerate(batches):\n",
    "        batch_ids = index_array[batch_start:batch_end]\n",
    "        X_batch = [X[i][batch_ids] for i in range(len(X))]\n",
    "        y_batch = y[batch_ids]\n",
    "        yield X_batch,y_batch\n",
    "\n",
    "\n",
    "def predict_batch(model,X_t,batch_size=128):\n",
    "    outcome = []\n",
    "    for X_batch,y_batch in test_batch_generator(X_t,np.zeros(X_t[0].shape[0]),batch_size=batch_size):\n",
    "        outcome.append(model.predict(X_batch,batch_size=batch_size))\n",
    "    outcome = np.concatenate(outcome).ravel()\n",
    "    return outcome\n",
    "\n",
    "\n",
    "\n",
    "def build_model(input_len, max_features,K=8,solver='adam',l2=0.0,l2_fm = 0.0):\n",
    "\n",
    "    inputs = []\n",
    "    flatten_layers=[]\n",
    "    columns = range(len(max_features))\n",
    "    for c in columns:\n",
    "        inputs_c = Input(shape=(1,), dtype='int32',name = 'input_%s'%c)\n",
    "        num_c = max_features[c]\n",
    "\n",
    "        embed_c = Embedding(\n",
    "                        input_dim=num_c, # 埋め込む特徴の次元\n",
    "                        output_dim=K, # 何次元に埋め込むか\n",
    "                        input_length=1,\n",
    "#                         input_length=1,\n",
    "                        name = 'embed_%s'%c,\n",
    "                        W_regularizer=l2_reg(l2_fm)\n",
    "                        )(inputs_c)\n",
    "\n",
    "              \n",
    "        flatten_c = Flatten()(embed_c)\n",
    "\n",
    "        inputs.append(inputs_c)\n",
    "        flatten_layers.append(flatten_c)\n",
    "\n",
    "    fm_layers = []\n",
    "\n",
    "    for emb1,emb2 in itertools.combinations(flatten_layers, 2):\n",
    "        \n",
    "#         dot_layer = merge([emb1,emb2], mode='dot', dot_axes=1)\n",
    "        dot_layer = dot(inputs=[emb1, emb2], axes=1)\n",
    "        \n",
    "        fm_layers.append(dot_layer)\n",
    "\n",
    "        \n",
    "    for c in columns:\n",
    "        num_c = max_features[c]\n",
    "        \n",
    "        embed_c = Embedding(\n",
    "                        num_c,\n",
    "                        1,\n",
    "                        input_length=1,\n",
    "#                         input_length=input_len,\n",
    "                        name = 'linear_%s'%c,\n",
    "                        W_regularizer=l2_reg(l2)\n",
    "                        )(inputs[c])\n",
    "\n",
    "        flatten_c = Flatten()(embed_c)\n",
    "\n",
    "        fm_layers.append(flatten_c)\n",
    "        \n",
    "#     flatten = merge(fm_layers, mode='sum')\n",
    "    flatten = add(fm_layers) \n",
    "    outputs = Activation('sigmoid',name='outputs')(flatten)\n",
    "    \n",
    "    model = Model(input=inputs, output=outputs)\n",
    "\n",
    "    model.compile(\n",
    "                optimizer=solver,\n",
    "                loss= 'binary_crossentropy'\n",
    "              )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class KerasFM(BaseEstimator):\n",
    "    def __init__(self, input_len, max_features=[], K=8, solver='adam', l2=0.0, l2_fm=0.0):\n",
    "        self.model = build_model(input_len, max_features,K,solver,l2=l2,l2_fm = l2_fm)\n",
    "\n",
    "    def fit(self, X, y, batch_size=128, nb_epoch=10, shuffle=True, verbose=1, validation_data=None):\n",
    "        self.model.fit(X,y,batch_size=batch_size,nb_epoch=nb_epoch,shuffle=shuffle,verbose=verbose,validation_data=None)\n",
    "\n",
    "    def fit_generator(self,X,y,batch_size=128,nb_epoch=10,shuffle=True,verbose=1,validation_data=None,callbacks=None):\n",
    "        tr_gen = batch_generator(X,y,batch_size=batch_size,shuffle=shuffle)\n",
    "        if validation_data:\n",
    "            X_test,y_test = validation_data\n",
    "            te_gen = batch_generator(X_test,y_test,batch_size=batch_size,shuffle=False)\n",
    "            nb_val_samples = X_test[-1].shape[0]\n",
    "        else:\n",
    "            te_gen = None\n",
    "            nb_val_samples = None\n",
    "\n",
    "        self.model.fit_generator(\n",
    "                tr_gen, \n",
    "                samples_per_epoch=X[-1].shape[0], \n",
    "                nb_epoch=nb_epoch, \n",
    "                verbose=verbose, \n",
    "                callbacks=callbacks, \n",
    "                validation_data=te_gen, \n",
    "                nb_val_samples=nb_val_samples, \n",
    "                max_q_size=10\n",
    "                )\n",
    "\n",
    "    def predict(self,X,batch_size=128):\n",
    "        y_preds = predict_batch(self.model,X,batch_size=batch_size)\n",
    "        return y_preds\n",
    "    \n",
    "max_features = [len(train[col]) for col in train.columns]\n",
    "model = KerasFM(input_len=len(train), max_features=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X=x_train, y=y_train, validation_data=(x_valid, y_valid))\n",
    "pred = model.predict(X=x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
