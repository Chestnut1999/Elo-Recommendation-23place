{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "import os\n",
    "import sys\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "sys.path.append(f'{HOME}/kaggle/data_analysis/library')\n",
    "import utils\n",
    "from utils import get_categorical_features, get_numeric_features, reduce_mem_usage\n",
    "from preprocessing import get_dummies\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import sys\n",
    "\n",
    "os.listdir('../input/')\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_avtive_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 105.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 167.48it/s]\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.83s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  4.04 Mb (56.2% reduction)\n",
      "Mem. usage decreased to  2.24 Mb (52.5% reduction)\n",
      "Mem. usage decreased to 2554.26 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 183.47 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train = utils.read_df_pkl('../input/train0*')\n",
    "df_test = utils.read_df_pkl('../input/test0*')\n",
    "df_train.set_index(key, inplace=True)\n",
    "df_test.set_index(key, inplace=True)\n",
    "train_test = pd.concat([df_train, df_test], axis=0)\n",
    "df_hist = utils.read_df_pkl('../input/hist_clean*')\n",
    "df_new = utils.read_df_pkl('../input/new_clean*')\n",
    "\n",
    "df_train = utils.reduce_mem_usage(df_train)\n",
    "df_test  = utils.reduce_mem_usage(df_test )\n",
    "df_hist  = utils.reduce_mem_usage(df_hist )\n",
    "df_new   = utils.reduce_mem_usage(df_new  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_max_date = df_hist.groupby(key)['purchase_date'].max()\n",
    "hist_min_date = df_hist.groupby(key)['purchase_date'].min()\n",
    "hist_max_date.name = 'hist_purchase_date_max'\n",
    "hist_min_date.name = 'hist_purchase_date_min'\n",
    "hist_max_date = hist_max_date.to_frame()\n",
    "hist_min_date = hist_min_date.to_frame()\n",
    "\n",
    "# month_maxは翌月の数字にする\n",
    "hist_max_date['hist_purchase_month_max'] = hist_max_date['hist_purchase_date_max'].map(lambda x: \n",
    "                                                                           str(int(str(x)[:4])+1) + '-' + '01' \n",
    "                                                                              if str(x)[:7][-2:]=='12' \n",
    "                                                                           else str(x)[:4] + '-0' + str(int(str(x)[:7][-1:])+1)\n",
    "                                                                           if str(x)[:7][-2:]!='09' \n",
    "                                                                           else str(x)[:4] + '-10')\n",
    "\n",
    "hist_min_date['hist_purchase_month_min'] = hist_min_date['hist_purchase_date_min'].map(lambda x: str(x)[:7])\n",
    "\n",
    "df_hist.set_index(key, inplace=True)\n",
    "df_hist = df_hist.join(hist_max_date.join(hist_min_date))\n",
    "\n",
    "new_max_date = df_new.groupby(key)['purchase_date'].max()\n",
    "new_min_date = df_new.groupby(key)['purchase_date'].min()\n",
    "new_max_date.name = 'new_purchase_date_max'\n",
    "new_min_date.name = 'new_purchase_date_min'\n",
    "new_max_date = new_max_date.to_frame()\n",
    "new_min_date = new_min_date.to_frame()\n",
    "\n",
    "# month_maxは翌月の数字にする\n",
    "new_max_date['new_purchase_month_max'] = new_max_date['new_purchase_date_max'].map(lambda x: \n",
    "                                                                           str(int(str(x)[:4])+1) + '-' + '01' \n",
    "                                                                              if str(x)[:7][-2:]=='12' \n",
    "                                                                           else str(x)[:4] + '-0' + str(int(str(x)[:7][-1:])+1)\n",
    "                                                                           if str(x)[:7][-2:]!='09' \n",
    "                                                                           else str(x)[:4] + '-10')\n",
    "new_min_date['new_purchase_month_min'] = new_min_date['new_purchase_date_min'].map(lambda x: str(x)[:7])\n",
    "\n",
    "df_new.set_index(key, inplace=True)\n",
    "df_new = df_new.join(new_max_date).join(new_min_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>target</th>\n",
       "      <th>hist_purchase_date_max</th>\n",
       "      <th>hist_purchase_month_max</th>\n",
       "      <th>hist_purchase_date_min</th>\n",
       "      <th>hist_purchase_month_min</th>\n",
       "      <th>new_purchase_date_max</th>\n",
       "      <th>new_purchase_month_max</th>\n",
       "      <th>new_purchase_date_min</th>\n",
       "      <th>new_purchase_month_min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_92a2005557</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>2018-02-25 09:31:15</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>2017-06-27 14:18:08</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>2018-04-29 11:23:05</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>2018-03-05 14:04:36</td>\n",
       "      <td>2018-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_3d0044924f</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>2018-01-31 22:31:09</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>2017-01-06 16:29:42</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2018-03-30 06:48:26</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>2018-02-01 17:07:54</td>\n",
       "      <td>2018-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_d639edf6cd</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>2018-02-27 19:08:25</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>2017-01-11 08:21:22</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2018-04-28 17:43:11</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>2018-04-28 17:43:11</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_186d6a6901</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-09</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>2018-02-28 11:44:40</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>2017-09-26 16:22:21</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2018-04-18 11:00:11</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>2018-03-07 11:55:06</td>\n",
       "      <td>2018-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_cdbd2c0db2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>2018-02-28 20:40:41</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>2017-11-12 00:00:00</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2018-04-28 18:50:25</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>2018-03-02 11:55:43</td>\n",
       "      <td>2018-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature_1  feature_2  feature_3 first_active_month    target  \\\n",
       "card_id                                                                         \n",
       "C_ID_92a2005557          5          2          1            2017-06 -0.820283   \n",
       "C_ID_3d0044924f          4          1          0            2017-01  0.392913   \n",
       "C_ID_d639edf6cd          2          2          0            2016-08  0.688056   \n",
       "C_ID_186d6a6901          4          3          0            2017-09  0.142495   \n",
       "C_ID_cdbd2c0db2          1          3          0            2017-11 -0.159749   \n",
       "\n",
       "                hist_purchase_date_max hist_purchase_month_max  \\\n",
       "card_id                                                          \n",
       "C_ID_92a2005557    2018-02-25 09:31:15              2018-03-01   \n",
       "C_ID_3d0044924f    2018-01-31 22:31:09              2018-02-01   \n",
       "C_ID_d639edf6cd    2018-02-27 19:08:25              2018-03-01   \n",
       "C_ID_186d6a6901    2018-02-28 11:44:40              2018-03-01   \n",
       "C_ID_cdbd2c0db2    2018-02-28 20:40:41              2018-03-01   \n",
       "\n",
       "                hist_purchase_date_min hist_purchase_month_min  \\\n",
       "card_id                                                          \n",
       "C_ID_92a2005557    2017-06-27 14:18:08              2017-06-01   \n",
       "C_ID_3d0044924f    2017-01-06 16:29:42              2017-01-01   \n",
       "C_ID_d639edf6cd    2017-01-11 08:21:22              2017-01-01   \n",
       "C_ID_186d6a6901    2017-09-26 16:22:21              2017-09-01   \n",
       "C_ID_cdbd2c0db2    2017-11-12 00:00:00              2017-11-01   \n",
       "\n",
       "                new_purchase_date_max new_purchase_month_max  \\\n",
       "card_id                                                        \n",
       "C_ID_92a2005557   2018-04-29 11:23:05             2018-05-01   \n",
       "C_ID_3d0044924f   2018-03-30 06:48:26             2018-04-01   \n",
       "C_ID_d639edf6cd   2018-04-28 17:43:11             2018-05-01   \n",
       "C_ID_186d6a6901   2018-04-18 11:00:11             2018-05-01   \n",
       "C_ID_cdbd2c0db2   2018-04-28 18:50:25             2018-05-01   \n",
       "\n",
       "                new_purchase_date_min new_purchase_month_min  \n",
       "card_id                                                       \n",
       "C_ID_92a2005557   2018-03-05 14:04:36             2018-03-01  \n",
       "C_ID_3d0044924f   2018-02-01 17:07:54             2018-02-01  \n",
       "C_ID_d639edf6cd   2018-04-28 17:43:11             2018-04-01  \n",
       "C_ID_186d6a6901   2018-03-07 11:55:06             2018-03-01  \n",
       "C_ID_cdbd2c0db2   2018-03-02 11:55:43             2018-03-01  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_test = train_test.join(hist_max_date).join(hist_min_date).join(new_max_date).join(new_min_date)\n",
    "train_test['hist_purchase_month_max'] = pd.to_datetime(train_test['hist_purchase_month_max'])\n",
    "train_test['hist_purchase_month_min'] = pd.to_datetime(train_test['hist_purchase_month_min'])\n",
    "train_test['new_purchase_month_max'] = pd.to_datetime(train_test['new_purchase_month_max'])\n",
    "train_test['new_purchase_month_min'] = pd.to_datetime(train_test['new_purchase_month_min'])\n",
    "train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 静的なFeature\n",
    "train_test['personal_term_new_min_hist_max'] = (train_test['new_purchase_month_min'] - train_test['hist_purchase_month_max']).dt.days\n",
    "train_test['personal_term_new_min_hist_min'] = (train_test['new_purchase_month_min'] - train_test['hist_purchase_month_min']).dt.days\n",
    "train_test['personal_days_new_max_date_from_hist_max_month'] = (train_test['new_purchase_date_max'] - train_test['hist_purchase_month_max']).dt.days\n",
    "train_test['personal_days_new_min_date_from_hist_max_month'] = (train_test['new_purchase_date_min'] - train_test['hist_purchase_month_max']).dt.days\n",
    "        \n",
    "prefix = '203_pst'\n",
    "ignore_features = ['first_active_month', 'card_id', target]\n",
    "\n",
    "for col in train_test.columns:\n",
    "    if col in ignore_features: continue\n",
    "    if not(col.count('personal')):continue\n",
    "    feature = train_test[col].astype('float32').values\n",
    "    \n",
    "#     utils.to_pkl_gzip(path = f'../features/1_first_valid/{prefix}_{col}@', obj=feature)\n",
    "    utils.to_pkl_gzip(path = f'../features/3_third_valid/{prefix}_{col}@', obj=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist['hist_purchase_month_max'] = pd.to_datetime(df_hist['hist_purchase_month_max'])\n",
    "df_hist['hist_purchase_month_min'] = pd.to_datetime(df_hist['hist_purchase_month_min'])\n",
    "df_hist['new_purchase_month_max'] = pd.to_datetime(df_hist['new_purchase_month_max'])\n",
    "df_hist['new_purchase_month_min'] = pd.to_datetime(df_hist['new_purchase_month_min'])\n",
    "\n",
    "df_new['new_purchase_month_max'] = pd.to_datetime(df_new['new_purchase_month_max'])\n",
    "df_new['new_purchase_month_min'] = pd.to_datetime(df_new['new_purchase_month_min'])\n",
    "df_new['hist_purchase_month_max'] = pd.to_datetime(df_new['hist_purchase_month_max'])\n",
    "df_new['hist_purchase_month_min'] = pd.to_datetime(df_new['hist_purchase_month_min'])\n",
    "\n",
    "# display(df_hist.head())\n",
    "# display(df_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_lag1 = df_new[df_new['month_lag']==1]\n",
    "df_new_lag2 = df_new[df_new['month_lag']==2]\n",
    "\n",
    "df_hist_lag0 = df_hist[df_hist['month_lag']==0]\n",
    "df_hist_lag1 = df_hist[df_hist['month_lag']==-1]\n",
    "df_hist_lag2 = df_hist[df_hist['month_lag']==-2]\n",
    "df_hist_lag02 = df_hist[df_hist['month_lag']>=-2]\n",
    "df_hist_lag05 = df_hist[df_hist['month_lag']>=-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 107.51it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 174.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 100.40it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 126.64it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 110.74it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 181.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 106.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 180.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 107.70it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 183.36it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 105.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 173.89it/s]\n"
     ]
    }
   ],
   "source": [
    "prefix = '203_pst'\n",
    "new_df_list = [df_new, df_new_lag1, df_new_lag2]\n",
    "new_fname_list = ['new', 'new_lag1', 'new_lag2']\n",
    "hist_df_list = [df_hist, df_hist_lag0, df_hist_lag1, df_hist_lag2, df_hist_lag02, df_hist_lag05] \n",
    "hist_fname_list = ['hist', 'hist_lag0', 'hist_lag1', 'hist_lag2', 'hist_lag02', 'hist_lag05']\n",
    "\n",
    "def get_new_columns(name,aggs):\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "#========================================================================\n",
    "# 集計が必要なFeature\n",
    "#========================================================================\n",
    "for df, fname in zip(new_df_list, new_fname_list):\n",
    "    \n",
    "    df_train = utils.read_df_pkl('../input/train0*')\n",
    "    df_test = utils.read_df_pkl('../input/test0*')\n",
    "    df_train.set_index(key, inplace=True)\n",
    "    df_test.set_index(key, inplace=True)\n",
    "    train_test = pd.concat([df_train, df_test], axis=0)\n",
    "    \n",
    "    # new\n",
    "    # new_first_buyと同じだな\n",
    "    # df['personal_new_elapsed_month'] = (df['new_purchase_month_min'] - df['first_active_month']).dt.days\n",
    "    df['diff_date_from_new_min_month'] = (df['new_purchase_month_min'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_new_max_month'] = (df['new_purchase_month_max'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_hist_min_month'] = (df['hist_purchase_month_min'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_hist_max_month'] = (df['hist_purchase_month_max'] - df['purchase_date']).dt.days\n",
    "    \n",
    "    aggs = {}\n",
    "    aggs['diff_date_from_new_min_month'] = ['mean', 'max', 'min', 'std', 'skew']\n",
    "    aggs['diff_date_from_new_max_month'] = ['mean', 'max', 'min', 'std', 'skew']\n",
    "    aggs['diff_date_from_hist_min_month'] = ['mean', 'max', 'min', 'std', 'skew']\n",
    "    aggs['diff_date_from_hist_max_month'] = ['mean', 'max', 'min', 'std', 'skew']\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    new_columns = get_new_columns(fname, aggs)\n",
    "    df_agg = df.groupby(key).agg(aggs)\n",
    "    df_agg.columns = new_columns\n",
    "    \n",
    "    train_test = train_test.join(df_agg)\n",
    "    \n",
    "    #========================================================================\n",
    "    # Save Feature\n",
    "    ignore_features = ['first_active_month', 'card_id', target]\n",
    "    for col in train_test.columns:\n",
    "        if col in ignore_features: continue\n",
    "        if not(col.count('diff')):continue\n",
    "        feature = train_test[col].astype('float32').values\n",
    "        \n",
    "    #     utils.to_pkl_gzip(path = f'../features/1_first_valid/{prefix}_{col}@', obj=feature)\n",
    "        utils.to_pkl_gzip(path = f'../features/3_third_valid/{prefix}_{col}@', obj=feature)\n",
    "    #========================================================================\n",
    "    \n",
    "    \n",
    "for df, fname in zip(hist_df_list, hist_fname_list):\n",
    "    \n",
    "    df_train = utils.read_df_pkl('../input/train0*')\n",
    "    df_test = utils.read_df_pkl('../input/test0*')\n",
    "    df_train.set_index(key, inplace=True)\n",
    "    df_test.set_index(key, inplace=True)\n",
    "    train_test = pd.concat([df_train, df_test], axis=0)\n",
    "    \n",
    "    # new\n",
    "    # new_first_buyと同じだな\n",
    "    # df['personal_new_elapsed_month'] = (df['new_purchase_month_min'] - df['first_active_month']).dt.days\n",
    "    df['diff_date_from_new_min_month'] = (df['new_purchase_month_min'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_new_max_month'] = (df['new_purchase_month_max'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_hist_min_month'] = (df['hist_purchase_month_min'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_hist_max_month'] = (df['hist_purchase_month_max'] - df['purchase_date']).dt.days\n",
    "    \n",
    "    aggs = {}\n",
    "    aggs['diff_date_from_new_min_month'] = ['mean', 'max', 'min', 'std', 'skew']\n",
    "    aggs['diff_date_from_new_max_month'] = ['mean', 'max', 'min', 'std', 'skew']\n",
    "    aggs['diff_date_from_hist_min_month'] = ['mean', 'max', 'min', 'std', 'skew']\n",
    "    aggs['diff_date_from_hist_max_month'] = ['mean', 'max', 'min', 'std', 'skew']\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    new_columns = get_new_columns(fname, aggs)\n",
    "    df_agg = df.groupby(key).agg(aggs)\n",
    "    df_agg.columns = new_columns\n",
    "    \n",
    "    train_test = train_test.join(df_agg)\n",
    "    \n",
    "    #========================================================================\n",
    "    # Save Feature\n",
    "    ignore_features = ['first_active_month', 'card_id', target]\n",
    "    for col in train_test.columns:\n",
    "        if col in ignore_features: continue\n",
    "        if not(col.count('diff')):continue\n",
    "        feature = train_test[col].astype('float32').values\n",
    "        \n",
    "    #     utils.to_pkl_gzip(path = f'../features/1_first_valid/{prefix}_{col}@', obj=feature)\n",
    "        utils.to_pkl_gzip(path = f'../features/3_third_valid/{prefix}_{col}@', obj=feature)\n",
    "    #========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-05-01    167857\n",
       "2018-04-01     55349\n",
       "2018-03-01     16554\n",
       "2018-02-01     11655\n",
       "2018-01-01      8537\n",
       "2017-02-01      6396\n",
       "2017-01-01      5411\n",
       "2017-10-01      4657\n",
       "2017-09-01      4014\n",
       "2017-08-01      3602\n",
       "2017-07-01      3069\n",
       "2017-06-01      2441\n",
       "2017-05-01       434\n",
       "2017-04-01        25\n",
       "Name: new_purchase_month_max, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test['new_purchase_month_max'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
