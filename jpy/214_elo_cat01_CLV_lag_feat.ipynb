{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "import os\n",
    "import sys\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "sys.path.append(f'{HOME}/kaggle/data_analysis/library')\n",
    "import utils\n",
    "from utils import get_categorical_features, get_numeric_features, reduce_mem_usage, elo_save_feature\n",
    "from preprocessing import get_dummies\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import sys\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_avtive_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 51.13it/s]\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.50s/it]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  4.04 Mb (56.2% reduction)\n",
      "Mem. usage decreased to  2.24 Mb (52.5% reduction)\n",
      "Mem. usage decreased to 1971.22 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 129.17 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "train_test = utils.read_df_pkl('../input/base_term**')\n",
    "# df_hist = utils.read_df_pkl('../input/hist_clean*')\n",
    "# df_new = utils.read_df_pkl('../input/new_clean*')\n",
    "df_hist = utils.read_df_pkl('../input/histori*0*')\n",
    "df_new = utils.read_df_pkl('../input/new_mer*0*')\n",
    "\n",
    "df_train = utils.reduce_mem_usage(df_train)\n",
    "df_test  = utils.reduce_mem_usage(df_test )\n",
    "df_hist  = utils.reduce_mem_usage(df_hist )\n",
    "df_new   = utils.reduce_mem_usage(df_new  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = df_hist.set_index(key).join(train_test.set_index(key)).reset_index()\n",
    "df_new = df_new.set_index(key).join(train_test.set_index(key)).reset_index()\n",
    "for df in [df_hist, df_new]:\n",
    "    df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\n",
    "    df['category_1'] = df['category_1'].map({'Y':1, 'N':0}) \n",
    "#     df['yyyymm'] = df['purchase_date'].map(lambda x: str(x)[:7])\n",
    "#     df['yyyymmdd'] = df['purchase_date'].map(lambda x: str(x)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26595452, 29)\n",
      "(2516909, 29)\n"
     ]
    }
   ],
   "source": [
    "df_new_lag1 = df_new[df_new['month_lag']==1]\n",
    "df_new_lag2 = df_new[df_new['month_lag']==2]\n",
    "\n",
    "df = df_hist\n",
    "\n",
    "auth1 = df[df.authorized_flag==1]\n",
    "auth0 = df[df.authorized_flag==0]\n",
    "print(auth1.shape)\n",
    "print(auth0.shape)\n",
    "\n",
    "cat1_0 = False\n",
    "cat1_0 = True\n",
    "if cat1_0:\n",
    "    auth1_cat1 = auth1[auth1.category_1==1]\n",
    "    auth1_cat0 = auth1[auth1.category_1==0]\n",
    "    new_cat1 = df_new[df_new.category_1==1]\n",
    "    new_cat0 = df_new[df_new.category_1==0]\n",
    "#     del auth1, auth0\n",
    "#     gc.collect()\n",
    "    auth1_cat1_lag0  = auth1_cat1[auth1_cat1['month_lag']==0]\n",
    "    auth1_cat0_lag0  = auth1_cat0[auth1_cat0['month_lag']==0]\n",
    "    auth1_cat1_lag1  = auth1_cat1[auth1_cat1['month_lag']==-1]\n",
    "    auth1_cat0_lag1  = auth1_cat0[auth1_cat0['month_lag']==-1]\n",
    "    auth1_cat1_lag2  = auth1_cat1[auth1_cat1['month_lag']==-2]\n",
    "    auth1_cat0_lag2  = auth1_cat0[auth1_cat0['month_lag']==-2]\n",
    "    auth1_cat1_lag02 = auth1_cat1[auth1_cat1['month_lag']>=-2]\n",
    "    auth1_cat0_lag02 = auth1_cat0[auth1_cat0['month_lag']>=-2]\n",
    "    auth1_cat1_lag05 = auth1_cat1[auth1_cat1['month_lag']>=-5]\n",
    "    auth1_cat0_lag05 = auth1_cat0[auth1_cat0['month_lag']>=-5]\n",
    "    \n",
    "    new_cat1_lag1  = new_cat1[new_cat1['month_lag']==1]\n",
    "    new_cat0_lag1  = new_cat0[new_cat0['month_lag']==1]\n",
    "    new_cat1_lag2  = new_cat1[new_cat1['month_lag']==2]\n",
    "    new_cat0_lag2  = new_cat0[new_cat0['month_lag']==2]\n",
    "\n",
    "else:\n",
    "    \n",
    "    auth1_lag0 = auth1[auth1['month_lag']==0]\n",
    "    auth1_lag1 = auth1[auth1['month_lag']==-1]\n",
    "    auth1_lag2 = auth1[auth1['month_lag']==-2]\n",
    "    auth1_lag02 = auth1[auth1['month_lag']>=-2]\n",
    "    auth1_lag05 = auth1[auth1['month_lag']>=-5]\n",
    "    \n",
    "    auth0_lag0 = auth0[auth0['month_lag']==0]\n",
    "    auth0_lag1 = auth0[auth0['month_lag']==-1]\n",
    "    auth0_lag2 = auth0[auth0['month_lag']==-2]\n",
    "    auth0_lag02 = auth0[auth0['month_lag']>=-2]\n",
    "    auth0_lag05 = auth0[auth0['month_lag']>=-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 108.79it/s]\u001b[A\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 171.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:08<00:42,  8.53s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 108.31it/s]\u001b[A\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 175.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:47<01:10, 17.56s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 106.57it/s]\u001b[A\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 161.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:52<00:41, 13.96s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 104.28it/s]\u001b[A\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 175.94it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [01:24<00:38, 19.31s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 108.01it/s]\u001b[A\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 161.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:30<00:15, 15.24s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 106.85it/s]\u001b[A\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 179.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [02:00<00:00, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prefix = '214_pst'\n",
    "prefix = '314_pst'\n",
    "prefix = '414_pst'\n",
    "new_df_list = [new_cat1, new_cat0, new_cat1_lag1, new_cat0_lag1, new_cat1_lag2, new_cat0_lag2]\n",
    "new_fname_list = ['new_cat1', 'new_cat0', 'new_cat1_lag1', 'new_cat0_lag1', 'new_cat1_lag2', 'new_cat0_lag2']\n",
    "\n",
    "debug = False\n",
    "if debug:\n",
    "    train_test = train_test.head(10000)\n",
    "        \n",
    "\n",
    "def get_new_columns(name,aggs):\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "\n",
    "\n",
    "#========================================================================\n",
    "# 集計が必要なFeature\n",
    "#========================================================================\n",
    "for df, fname in zip(tqdm(new_df_list), new_fname_list):\n",
    "    if debug:\n",
    "        df = df.head(3000)\n",
    "    \n",
    "    df_train = utils.read_df_pkl('../input/train0*')\n",
    "    df_test = utils.read_df_pkl('../input/test0*')\n",
    "    df_train.set_index(key, inplace=True)\n",
    "    df_test.set_index(key, inplace=True)\n",
    "    train_test = pd.concat([df_train, df_test], axis=0)\n",
    "    \n",
    "    # new\n",
    "    print('Make Feature.')\n",
    "   \n",
    "    if ('level_0' and 'index' not in df.columns) and key not in df.columns:\n",
    "        df.reset_index(inplace=True)\n",
    "    \n",
    "    aggs = {}\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['month_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)//30\n",
    "    df['month_diff'] += df['month_lag']\n",
    "    df['duration'] = df['purchase_amount']*df['month_diff']\n",
    "    \n",
    "    aggs['duration'] = ['sum', 'mean', 'std', 'max', 'skew']\n",
    "    aggs['purchase_amount'] = ['sum']\n",
    "    aggs['card_id'] = ['count']\n",
    "    \n",
    "    new_columns = get_new_columns(fname, aggs)\n",
    "    df_agg = df.groupby(key).agg(aggs)\n",
    "    df_agg.columns = new_columns\n",
    "    \n",
    "    train_test = train_test.join(df_agg)\n",
    "    print(train_test.shape)\n",
    "    \n",
    "    if not(fname.count('lag')):\n",
    "        train_test[f'{fname}_CLV'] = train_test[f'{fname}_card_id_count'] * train_test[f'{fname}_purchase_amount_sum'] / 2\n",
    "    else:\n",
    "        train_test[f'{fname}_CLV'] = train_test[f'{fname}_card_id_count'] * train_test[f'{fname}_purchase_amount_sum'] / 1\n",
    "\n",
    "    #========================================================================\n",
    "    # Save Feature\n",
    "    elo_save_feature(prefix=prefix, df_feat=train_test)\n",
    "    #========================================================================\n",
    "print('Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 58.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:20<03:43, 20.30s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 53.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [01:21<05:26, 32.63s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 57.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [01:34<03:59, 26.56s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 54.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [02:15<04:07, 30.99s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 55.78it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [02:27<02:57, 25.39s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 54.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [03:09<03:01, 30.29s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 55.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [03:21<02:03, 24.76s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 52.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [04:04<02:01, 30.29s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 54.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [04:21<01:18, 26.16s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 54.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [05:11<01:07, 33.54s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 55.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [05:30<00:29, 29.15s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00, 54.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Feature.\n",
      "(325540, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [06:26<00:00, 37.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "prefix = '214_pst'\n",
    "prefix = '314_pst'\n",
    "prefix = '414_pst'\n",
    "hist_df_list = [\n",
    "auth1_cat1 \n",
    ",auth1_cat0 \n",
    ",auth1_cat1_lag0 \n",
    ",auth1_cat0_lag0 \n",
    ",auth1_cat1_lag1 \n",
    ",auth1_cat0_lag1 \n",
    ",auth1_cat1_lag2 \n",
    ",auth1_cat0_lag2 \n",
    ",auth1_cat1_lag02\n",
    ",auth1_cat0_lag02\n",
    ",auth1_cat1_lag05\n",
    ",auth1_cat0_lag05\n",
    "]\n",
    "\n",
    "\n",
    "hist_fname_list = [\n",
    "'auth1_cat1'\n",
    ",'auth1_cat0'\n",
    ",'auth1_cat1_lag0'\n",
    ",'auth1_cat0_lag0'\n",
    ",'auth1_cat1_lag1'\n",
    ",'auth1_cat0_lag1'\n",
    ",'auth1_cat1_lag2'\n",
    ",'auth1_cat0_lag2'\n",
    ",'auth1_cat1_lag02'\n",
    ",'auth1_cat0_lag02'\n",
    ",'auth1_cat1_lag05'\n",
    ",'auth1_cat0_lag05'\n",
    "]\n",
    "\n",
    "for df, fname in zip(tqdm(hist_df_list), hist_fname_list):\n",
    "    if debug:\n",
    "        df = df.head(3000)\n",
    "    \n",
    "#     df_train = utils.read_df_pkl('../input/train0*')\n",
    "#     df_test = utils.read_df_pkl('../input/test0*')\n",
    "#     df_train.set_index(key, inplace=True)\n",
    "#     df_test.set_index(key, inplace=True)\n",
    "#     train_test = pd.concat([df_train, df_test], axis=0)\n",
    "    train_test = utils.read_df_pkl('../input/base_term*0*').set_index(key)[[target, 'hist_regist_term']]\n",
    "    \n",
    "#     hist\n",
    "    print('Make Feature.')\n",
    "    \n",
    "    if ('level_0' and 'index' not in df.columns) and key not in df.columns:\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "    aggs = {}\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['month_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)//30\n",
    "    df['month_diff'] += df['month_lag']\n",
    "    df['duration'] = df['purchase_amount']*df['month_diff']\n",
    "    aggs['duration'] = ['sum', 'mean', 'std', 'max', 'skew']\n",
    "    \n",
    "    aggs['purchase_amount'] = ['sum']\n",
    "    aggs['card_id'] = ['count']\n",
    "    \n",
    "    new_columns = get_new_columns(fname, aggs)\n",
    "    df_agg = df.groupby(key).agg(aggs)\n",
    "    df_agg.columns = new_columns\n",
    "    \n",
    "    train_test = train_test.join(df_agg)\n",
    "    print(train_test.shape)\n",
    "    \n",
    "    if not(fname.count('lag')):\n",
    "        train_test[f'{fname}_CLV'] = train_test[f'{fname}_card_id_count'] * train_test[f'{fname}_purchase_amount_sum'] / train_test['hist_regist_term']\n",
    "    elif fname[-4:-1]=='lag':\n",
    "        train_test[f'{fname}_CLV'] = train_test[f'{fname}_card_id_count'] * train_test[f'{fname}_purchase_amount_sum'] / 1\n",
    "    elif fname[-2:]=='02':\n",
    "        train_test[f'{fname}_CLV'] = train_test[f'{fname}_card_id_count'] * train_test[f'{fname}_purchase_amount_sum'] / 3\n",
    "    elif fname[-2:]=='05':\n",
    "        train_test[f'{fname}_CLV'] = train_test[f'{fname}_card_id_count'] * train_test[f'{fname}_purchase_amount_sum'] / 6\n",
    "    elif fname[-2:]=='08':\n",
    "        train_test[f'{fname}_CLV'] = train_test[f'{fname}_card_id_count'] * train_test[f'{fname}_purchase_amount_sum'] / 9\n",
    "    elif fname[-2:]=='11':\n",
    "        train_test[f'{fname}_CLV'] = train_test[f'{fname}_card_id_count'] * train_test[f'{fname}_purchase_amount_sum'] / 12\n",
    "    \n",
    "    #========================================================================\n",
    "    # Save Feature\n",
    "    elo_save_feature(prefix=prefix, df_feat=train_test)\n",
    "    #========================================================================    \n",
    "print('Complete!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 47.15it/s]\n",
      "100%|██████████| 39/39 [00:00<00:00, 464.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325540, 63)\n"
     ]
    }
   ],
   "source": [
    "prefix = '214_pst'\n",
    "prefix = '314_pst'\n",
    "prefix = '414_pst'\n",
    "import glob\n",
    "# #========================================================================\n",
    "# # これは作成済のFeatureを読み込んで計算する\n",
    "# #========================================================================\n",
    "combi_list = [ \n",
    "    ['new_cat1', 'new_cat0']\n",
    "    ,['new_cat1_lag1', 'new_cat0_lag1']\n",
    "    ,['new_cat1_lag2', 'new_cat0_lag2']\n",
    "    ,['new_cat1', 'new_cat1_lag1'] \n",
    "    ,['new_cat1', 'auth1_cat1'] \n",
    "    \n",
    "    ,['new_cat1', 'auth1_cat1_lag0'] \n",
    "    ,['new_cat1', 'auth1_cat1_lag02'] \n",
    "    ,['new_cat1', 'auth1_cat1_lag05']  \n",
    "    ,['new_cat1', 'auth1_cat1_lag08']  \n",
    "    ,['new_cat1', 'auth1_cat1_lag011'] \n",
    "    \n",
    "    ,['new_cat0', 'new_cat0_lag1'] \n",
    "    ,['new_cat0', 'auth1_cat0'] \n",
    "    ,['new_cat0', 'auth1_cat0_lag0'] \n",
    "    ,['new_cat0', 'auth1_cat0_lag02'] \n",
    "    ,['new_cat0', 'auth1_cat0_lag05']  \n",
    "    ,['new_cat0', 'auth1_cat0_lag08']  \n",
    "    ,['new_cat0', 'auth1_cat0_lag011'] \n",
    "    \n",
    "    ,['auth1_cat1_lag0', 'auth1_cat0_lag0'] \n",
    "    ,['auth1_cat1_lag02', 'auth1_cat0_lag02'] \n",
    "    ,['auth1_cat1_lag05', 'auth1_cat0_lag05'] \n",
    "    ,['auth1_cat1_lag011', 'auth1_cat0_lag011'] \n",
    "    \n",
    "    ,['auth1_cat1_lag0', 'auth1_cat1_lag02'] \n",
    "    ,['auth1_cat0_lag0', 'auth1_cat0_lag02'] \n",
    "    ,['auth1_cat1_lag0', 'auth1_cat1_lag05'] \n",
    "    ,['auth1_cat0_lag0', 'auth1_cat0_lag05'] \n",
    "    ,['auth1_cat1_lag0', 'auth1_cat1_lag08'] \n",
    "    ,['auth1_cat0_lag0', 'auth1_cat0_lag08'] \n",
    "    ,['auth1_cat1_lag0', 'auth1_cat1_lag011'] \n",
    "    ,['auth1_cat0_lag0', 'auth1_cat0_lag011'] \n",
    "    \n",
    "    ,['auth1_cat1_lag02', 'auth1_cat1_lag05'] \n",
    "    ,['auth1_cat0_lag02', 'auth1_cat0_lag05'] \n",
    "    ,['auth1_cat1_lag02', 'auth1_cat1_lag08'] \n",
    "    ,['auth1_cat0_lag02', 'auth1_cat0_lag08'] \n",
    "    ,['auth1_cat1_lag02', 'auth1_cat1_lag011'] \n",
    "    ,['auth1_cat0_lag02', 'auth1_cat0_lag011'] \n",
    "    \n",
    "    ,['auth1_cat1_lag05', 'auth1_cat1_lag08'] \n",
    "    ,['auth1_cat0_lag05', 'auth1_cat0_lag08'] \n",
    "    ,['auth1_cat1_lag05', 'auth1_cat1_lag011'] \n",
    "    ,['auth1_cat0_lag05', 'auth1_cat0_lag011'] \n",
    "]\n",
    "\n",
    "comp_cols = [\n",
    "     'CLV'\n",
    "#     ,'duration'\n",
    "]\n",
    "\n",
    "tmp_feature_list = glob.glob(f'../features/1_first_valid/{prefix}*.gz')\n",
    "                   \n",
    "feature_list = []\n",
    "for f in tmp_feature_list:\n",
    "    if f.count('pst_ratio_') or f.count('pst_diff_'):continue\n",
    "    for col in comp_cols:\n",
    "        if f.count(col):\n",
    "            feature_list.append(f)\n",
    "            \n",
    "base = utils.read_df_pkl('../input/base_first*0*')\n",
    "p_list = utils.parallel_load_data(path_list=feature_list)\n",
    "df_feat = pd.concat(p_list, axis=1)\n",
    "train_test = pd.concat([base[key], df_feat], axis=1)\n",
    "\n",
    "for (fm1, fm2) in tqdm(combi_list):\n",
    "    for col in comp_cols:\n",
    "#         203_pst_auth0_lag02_monthly_avg_purchase_amount_min\n",
    "        try:\n",
    "            train_test[f\"ratio_{fm1}_{fm2}_{col}\"] = train_test[f\"{prefix}_{fm1}_{col}@\"] / train_test[f\"{prefix}_{fm2}_{col}@\"]\n",
    "            train_test[f\"diff_{fm1}_{fm2}_{col}\"] = train_test[f\"{prefix}_{fm1}_{col}@\"] - train_test[f\"{prefix}_{fm2}_{col}@\"]\n",
    "        except KeyError:\n",
    "#             print(fm1, fm2, col)\n",
    "            continue\n",
    "        \n",
    "print(train_test.shape)\n",
    "ratio_diff_cols = [col for col in train_test.columns if col[:5]=='ratio' or col[:4]=='diff']\n",
    "elo_save_feature(prefix, train_test[ratio_diff_cols], feat_check=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
