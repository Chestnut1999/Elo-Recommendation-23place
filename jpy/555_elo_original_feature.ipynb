{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category_2よってamountの絶対値あたりの価値は違うという仮説で、特徴をリフトにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:40:08.183701Z",
     "start_time": "2018-10-28T07:40:07.309627Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "import os\n",
    "import sys\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "sys.path.append(f'{HOME}/kaggle/data_analysis/library')\n",
    "import utils\n",
    "from utils import get_categorical_features, get_numeric_features\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "os.listdir('../input/')\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_avtive_month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 24.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 45.47it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  6.50it/s]\n",
      "100%|██████████| 3/3 [00:15<00:00,  5.39s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  5.58 Mb (48.2% reduction)\n",
      "Mem. usage decreased to  3.18 Mb (43.8% reduction)\n",
      "Mem. usage decreased to 2554.26 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 183.47 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "# regist_termをもたせる\n",
    "df_train = utils.read_df_pkl('../input/train0*')\n",
    "df_test = utils.read_df_pkl('../input/test0*')\n",
    "train_test = pd.concat([df_train, df_test], axis=0)\n",
    "train_test.set_index(key, inplace=True)\n",
    "base = utils.read_df_pkl('../input/base_term*0*').set_index(key)[['hist_regist_term', 'new_regist_term']]\n",
    "train_test = train_test.join(base)\n",
    "\n",
    "df_hist = utils.read_df_pkl('../input/hist_clean*')\n",
    "df_new = utils.read_df_pkl('../input/new_clean*')\n",
    "\n",
    "df_train = utils.reduce_mem_usage(df_train)\n",
    "df_test  = utils.reduce_mem_usage(df_test )\n",
    "df_hist  = utils.reduce_mem_usage(df_hist )\n",
    "df_new   = utils.reduce_mem_usage(df_new  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 18.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#========================================================================\n",
    "# 登録より前に購買が発生しているユーザーかどうかわかるdiff term \n",
    "prefix = '555_elo'\n",
    "base = utils.read_df_pkl('../input/base_term*0*')\n",
    "base[['hist_regist_term','hist_personal_term']].groupby(['hist_regist_term','hist_personal_term']).size()\n",
    "base[\"diff_regist_term_hist_term\"] = base['hist_regist_term'] - base['hist_personal_term']\n",
    "utils.to_pkl_gzip(obj=base[\"diff_regist_term_hist_term\"], path=f'../features/1_first_valid/{prefix}_diff_regist_term_hist_term')\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Recency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>377.0</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>151.0</td>\n",
       "      <td>342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>283.0</td>\n",
       "      <td>461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>202.0</td>\n",
       "      <td>344.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id   Time  Recency\n",
       "0  C_ID_00007093c1  377.0    343.0\n",
       "1  C_ID_0001238066  151.0    342.0\n",
       "2  C_ID_0001506ef0  398.0    352.0\n",
       "3  C_ID_0001793786  283.0    461.0\n",
       "4  C_ID_000183fdda  202.0    344.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#========================================================================\n",
    "# CLV\n",
    "df_hist = df_hist[['card_id','purchase_date','purchase_amount']]\n",
    "\n",
    "## Time\n",
    "from datetime import datetime\n",
    "\n",
    "z = df_hist.groupby('card_id')['purchase_date'].max().reset_index()\n",
    "q = df_hist.groupby('card_id')['purchase_date'].min().reset_index()\n",
    "\n",
    "z.columns = ['card_id', 'Max']\n",
    "q.columns = ['card_id', 'Min']\n",
    "\n",
    "## Extracting current timestamp\n",
    "now = datetime.now()\n",
    "curr_date = now.strftime(\"%m-%d-%Y, %H:%M:%S\")\n",
    "curr_date = pd.to_datetime(curr_date)\n",
    "\n",
    "rec = pd.merge(z,q, how = 'left',on = 'card_id')\n",
    "rec['Min'] = pd.to_datetime(rec['Min'])\n",
    "rec['Max'] = pd.to_datetime(rec['Max'])\n",
    "\n",
    "## Time value \n",
    "rec['Recency'] = (curr_date - rec['Max']).astype('timedelta64[D]') ## current date - most recent date\n",
    "\n",
    "## Recency value\n",
    "rec['Time'] = (rec['Max'] - rec['Min']).astype('timedelta64[D]') ## Age of customer, MAX - MIN\n",
    "\n",
    "rec = rec[['card_id','Time','Recency']]\n",
    "\n",
    "## Frequency\n",
    "freq = df_hist.groupby('card_id').size().reset_index()\n",
    "freq.columns = ['card_id', 'Frequency']\n",
    "## Monitary\n",
    "mon = df_hist.groupby('card_id')['purchase_amount'].sum().reset_index()\n",
    "mon.columns = ['card_id', 'Monitary']\n",
    "\n",
    "final = pd.merge(freq,mon,how = 'left', on = 'card_id')\n",
    "final = pd.merge(final,rec,how = 'left', on = 'card_id')\n",
    "\n",
    "final['historic_CLV'] = final['Frequency'] * final['Monitary'] \n",
    "final['AOV'] = final['Monitary']/final['Frequency'] ## AOV - Average order value (i.e) total_purchase_amt/total_trans\n",
    "final['Predictive_CLV'] = final['Time']*final['AOV']*final['Monitary']*final['Recency'] \n",
    "\n",
    "for col in ['AOV', 'Predictive_CLV']:\n",
    "    feature = final[col].fillna(-1).values.astype('float32')\n",
    "    print(feature.shape)\n",
    "    utils.to_pkl_gzip(obj=feature, path=f'../features/1_first_valid/{prefix}_{col}')\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.52it/s]\n"
     ]
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Featureをnew_regist_term別にliftにする\n",
    "# train_testの粒度でliftを作る\n",
    "win_path = f'../features/4_winner/*.gz'\n",
    "win_path_list = glob.glob(win_path)\n",
    "base = utils.read_df_pkl('../input/base_term*0*')\n",
    "feature_list = utils.parallel_load_data(path_list=win_path_list)\n",
    "\n",
    "lift_level = 'hist_regist_term'\n",
    "\n",
    "df_feat = pd.concat(feature_list, axis=1)\n",
    "df_feat = pd.concat([base, df_feat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 27/148 [01:09<12:14,  6.07s/it]"
     ]
    }
   ],
   "source": [
    "feat_cols = [col for col in df_feat.columns if col.count('@') and not(col.count('lift')) and not(col.count('114_'))]\n",
    "level_list = np.unique(df_feat[lift_level].values)\n",
    "tmp_list = []\n",
    "df_list = []\n",
    "\n",
    "for col in tqdm(feat_cols):\n",
    "    for level in level_list:\n",
    "        tmp = df_feat[df_feat[lift_level]==level][[key, col]]\n",
    "        base_avg = tmp[col].mean()\n",
    "        tmp[col] = tmp[col] / base_avg\n",
    "        tmp.rename(columns={col:f'lift_{col}'}, inplace=True)\n",
    "        tmp_list.append(tmp)\n",
    "        \n",
    "    df_level = pd.concat(tmp_list, axis=0)\n",
    "#     df_level[lift_level] = level\n",
    "    df_level.set_index(key, inplace=True)\n",
    "    df_list.append(df_level)\n",
    "        \n",
    "df_lift = pd.concat(df_list, axis=1)\n",
    "df_lift = df_lift.reset_index().set_index(key)\n",
    "print(df_lift.shape)\n",
    "\n",
    "df_lift.head()\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
