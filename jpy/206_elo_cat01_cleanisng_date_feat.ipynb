{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "import os\n",
    "import sys\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "sys.path.append(f'{HOME}/kaggle/data_analysis/library')\n",
    "import utils\n",
    "from utils import get_categorical_features, get_numeric_features, reduce_mem_usage, elo_save_feature\n",
    "from preprocessing import get_dummies\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import sys\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_avtive_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23.90it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 64.00it/s]\n",
      "100%|██████████| 3/3 [00:15<00:00,  5.09s/it]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  4.04 Mb (56.2% reduction)\n",
      "Mem. usage decreased to  2.24 Mb (52.5% reduction)\n",
      "Mem. usage decreased to 1971.22 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 129.17 Mb (0.0% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = utils.read_df_pkl('../input/train0*')\n",
    "df_test = utils.read_df_pkl('../input/test0*')\n",
    "df_train.set_index(key, inplace=True)\n",
    "df_test.set_index(key, inplace=True)\n",
    "train_test = pd.concat([df_train, df_test], axis=0)\n",
    "df_hist = utils.read_df_pkl('../input/historical*0*')\n",
    "df_new = utils.read_df_pkl('../input/new_mer*0*')\n",
    "\n",
    "df_train = utils.reduce_mem_usage(df_train)\n",
    "df_test  = utils.reduce_mem_usage(df_test )\n",
    "df_hist  = utils.reduce_mem_usage(df_hist )\n",
    "df_new   = utils.reduce_mem_usage(df_new  )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_hist, df_new]:\n",
    "    df['category_1'] = df['category_1'].map({'Y':1, 'N':0}) \n",
    "    df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\n",
    "#     df['yyyymm'] = df['purchase_date'].map(lambda x: str(x)[:7])\n",
    "#     df['yyyymmdd'] = df['purchase_date'].map(lambda x: str(x)[:10])\n",
    "# df_hist = df_hist.set_index(key).join(train_test['first_active_month']).reset_index()\n",
    "# df_new = df_new.set_index(key).join(train_test['first_active_month']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time_utils import date_add_days\n",
    "\n",
    "hist_max_date = df_hist.groupby(key)['purchase_date'].max()\n",
    "hist_max_date.name = 'hist_purchase_date_max'\n",
    "hist_max_date = hist_max_date.to_frame()\n",
    "# month_maxは翌月の数字にする\n",
    "hist_max_date['hist_purchase_month_max'] = hist_max_date['hist_purchase_date_max'].map(lambda x: date_add_days(x, 32) if int(str(x)[8:10])<=15 else date_add_days(x, 20))\n",
    "hist_max_date['hist_purchase_month_max'] = hist_max_date['hist_purchase_month_max'].map(lambda x: str(x)[:6])\n",
    "\n",
    "hist_min_date = df_hist.groupby(key)['purchase_date'].min()\n",
    "hist_min_date.name = 'hist_purchase_date_min'\n",
    "hist_min_date = hist_min_date.to_frame()\n",
    "hist_min_date['hist_purchase_month_min'] = hist_min_date['hist_purchase_date_min'].map(lambda x: str(x)[:7])\n",
    "\n",
    "\n",
    "new_max_date = df_new.groupby(key)['purchase_date'].max()\n",
    "new_max_date.name = 'new_purchase_date_max'\n",
    "new_max_date = new_max_date.to_frame()\n",
    "new_max_date['new_purchase_month_max'] = new_max_date['new_purchase_date_max'].map(lambda x: date_add_days(x, 32) if int(str(x)[8:10])<=15 else date_add_days(x, 20))\n",
    "new_max_date['new_purchase_month_max'] = new_max_date['new_purchase_month_max'].map(lambda x: str(x)[:6])\n",
    "\n",
    "new_min_date = df_new.groupby(key)['purchase_date'].min()\n",
    "new_min_date.name = 'new_purchase_date_min'\n",
    "new_min_date = new_min_date.to_frame()\n",
    "\n",
    "# month_maxは翌月の数字にする\n",
    "new_min_date['new_purchase_month_min'] = new_min_date['new_purchase_date_min'].map(lambda x: str(x)[:7])\n",
    "\n",
    "df_hist.set_index(key, inplace=True)\n",
    "df_new.set_index(key, inplace=True)\n",
    "df_hist = df_hist.join(hist_max_date).join(hist_min_date).join(new_max_date).join(new_min_date)\n",
    "df_new = df_new.join(hist_max_date).join(hist_min_date).join(new_max_date).join(new_min_date)\n",
    "\n",
    "df_hist['hist_purchase_month_max'] = df_hist['hist_purchase_month_max'].map(lambda x: str(x)[:4] + '-' + str(x)[4:])\n",
    "df_hist['new_purchase_month_max'] = df_hist['new_purchase_month_max'].map(lambda x: str(x)[:4] + '-' + str(x)[4:])\n",
    "df_hist['new_purchase_month_max'] = df_hist['new_purchase_month_max'].replace('nan-', np.nan)\n",
    "\n",
    "df_hist['hist_purchase_month_max'] = pd.to_datetime(df_hist['hist_purchase_month_max'])\n",
    "df_hist['hist_purchase_month_min'] = pd.to_datetime(df_hist['hist_purchase_month_min'])\n",
    "df_hist['new_purchase_month_max'] = pd.to_datetime(df_hist['new_purchase_month_max'])\n",
    "df_hist['new_purchase_month_min'] = pd.to_datetime(df_hist['new_purchase_month_min'])\n",
    "\n",
    "df_new['hist_purchase_month_max'] = df_new['hist_purchase_month_max'].map(lambda x: str(x)[:4] + '-' + str(x)[4:])\n",
    "df_new['new_purchase_month_max'] = df_new['new_purchase_month_max'].map(lambda x: str(x)[:4] + '-' + str(x)[4:])\n",
    "df_new['new_purchase_month_max'] = df_new['new_purchase_month_max'].replace('nan-', np.nan)\n",
    "\n",
    "df_new['new_purchase_month_max'] = pd.to_datetime(df_new['new_purchase_month_max'])\n",
    "df_new['new_purchase_month_min'] = pd.to_datetime(df_new['new_purchase_month_min'])\n",
    "df_new['hist_purchase_month_max'] = pd.to_datetime(df_new['hist_purchase_month_max'])\n",
    "df_new['hist_purchase_month_min'] = pd.to_datetime(df_new['hist_purchase_month_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26595452, 23)\n",
      "(2516909, 23)\n"
     ]
    }
   ],
   "source": [
    "df_new_lag1 = df_new[df_new['month_lag']==1]\n",
    "df_new_lag2 = df_new[df_new['month_lag']==2]\n",
    "\n",
    "df = df_hist\n",
    "\n",
    "auth1 = df[df.authorized_flag==1]\n",
    "auth0 = df[df.authorized_flag==0]\n",
    "print(auth1.shape)\n",
    "print(auth0.shape)\n",
    "\n",
    "cat1_0 = False\n",
    "cat1_0 = True\n",
    "if cat1_0:\n",
    "    auth1_cat1 = auth1[auth1.category_1==1]\n",
    "    auth1_cat0 = auth1[auth1.category_1==0]\n",
    "    new_cat1 = df_new[df_new.category_1==1]\n",
    "    new_cat0 = df_new[df_new.category_1==0]\n",
    "#     del auth1, auth0\n",
    "#     gc.collect()\n",
    "    auth1_cat1_lag0  = auth1_cat1[auth1_cat1['month_lag']==0]\n",
    "    auth1_cat0_lag0  = auth1_cat0[auth1_cat0['month_lag']==0]\n",
    "    auth1_cat1_lag1  = auth1_cat1[auth1_cat1['month_lag']==-1]\n",
    "    auth1_cat0_lag1  = auth1_cat0[auth1_cat0['month_lag']==-1]\n",
    "    auth1_cat1_lag2  = auth1_cat1[auth1_cat1['month_lag']==-2]\n",
    "    auth1_cat0_lag2  = auth1_cat0[auth1_cat0['month_lag']==-2]\n",
    "    auth1_cat1_lag02 = auth1_cat1[auth1_cat1['month_lag']>=-2]\n",
    "    auth1_cat0_lag02 = auth1_cat0[auth1_cat0['month_lag']>=-2]\n",
    "    auth1_cat1_lag05 = auth1_cat1[auth1_cat1['month_lag']>=-5]\n",
    "    auth1_cat0_lag05 = auth1_cat0[auth1_cat0['month_lag']>=-5]\n",
    "    \n",
    "    new_cat1_lag1  = new_cat1[new_cat1['month_lag']==1]\n",
    "    new_cat0_lag1  = new_cat0[new_cat0['month_lag']==1]\n",
    "    new_cat1_lag2  = new_cat1[new_cat1['month_lag']==2]\n",
    "    new_cat0_lag2  = new_cat0[new_cat0['month_lag']==2]\n",
    "\n",
    "else:\n",
    "    \n",
    "    auth1_lag0 = auth1[auth1['month_lag']==0]\n",
    "    auth1_lag1 = auth1[auth1['month_lag']==-1]\n",
    "    auth1_lag2 = auth1[auth1['month_lag']==-2]\n",
    "    auth1_lag02 = auth1[auth1['month_lag']>=-2]\n",
    "    auth1_lag05 = auth1[auth1['month_lag']>=-5]\n",
    "    \n",
    "    auth0_lag0 = auth0[auth0['month_lag']==0]\n",
    "    auth0_lag1 = auth0[auth0['month_lag']==-1]\n",
    "    auth0_lag2 = auth0[auth0['month_lag']==-2]\n",
    "    auth0_lag02 = auth0[auth0['month_lag']>=-2]\n",
    "    auth0_lag05 = auth0[auth0['month_lag']>=-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 116.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 189.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(63096, 31)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 1/6 [00:14<01:12, 14.47s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 105.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 170.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(1899935, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 2/6 [00:37<01:08, 17.13s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 101.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 168.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(30206, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 3/6 [00:51<00:48, 16.16s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 97.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 168.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(997411, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 4/6 [01:12<00:35, 17.61s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 104.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 165.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(32890, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 5/6 [01:26<00:16, 16.42s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 106.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 175.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(902524, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 6/6 [01:46<00:00, 17.66s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!!\n"
     ]
    }
   ],
   "source": [
    "# prefix = '206_pst'\n",
    "prefix = '306_pst'\n",
    "prefix = '406_pst'\n",
    "new_df_list = [new_cat1, new_cat0, new_cat1_lag1, new_cat0_lag1, new_cat1_lag2, new_cat0_lag2]\n",
    "new_fname_list = ['new_cat1', 'new_cat0', 'new_cat1_lag1', 'new_cat0_lag1', 'new_cat1_lag2', 'new_cat0_lag2']\n",
    "\n",
    "debug = False\n",
    "if debug:\n",
    "    train_test = train_test.head(10000)\n",
    "        \n",
    "\n",
    "def get_new_columns(name,aggs):\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]\n",
    "\n",
    "\n",
    "#========================================================================\n",
    "# 集計が必要なFeature\n",
    "#========================================================================\n",
    "for df, fname in zip(tqdm(new_df_list), new_fname_list):\n",
    "    if debug:\n",
    "        df = df.head(3000)\n",
    "#     df.drop(['level_0', 'index'], axis=1, inplace=True)\n",
    "#     sys.exit()\n",
    "    \n",
    "    df_train = utils.read_df_pkl('../input/train0*')\n",
    "    df_test = utils.read_df_pkl('../input/test0*')\n",
    "    df_train.set_index(key, inplace=True)\n",
    "    df_test.set_index(key, inplace=True)\n",
    "    train_test = pd.concat([df_train, df_test], axis=0)\n",
    "    \n",
    "    # new\n",
    "    # new_first_buyと同じだな\n",
    "    # df['personal_new_elapsed_month'] = (df['new_purchase_month_min'] - df['first_active_month']).dt.days\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['diff_date_from_new_min_month'] = (df['new_purchase_month_min'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_new_max_month'] = (df['new_purchase_month_max'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_hist_min_month'] = (df['hist_purchase_month_min'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_hist_max_month'] = (df['hist_purchase_month_max'] - df['purchase_date']).dt.days\n",
    "\n",
    "    df['month_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)//30\n",
    "    df['month_diff'] += df['month_lag']\n",
    "    \n",
    "    aggs = {}\n",
    "    aggs['diff_date_from_new_min_month'] = ['mean', 'max', 'min', 'std']\n",
    "    aggs['diff_date_from_new_max_month'] = ['mean', 'max', 'min', 'std']\n",
    "    aggs['diff_date_from_hist_min_month'] = ['mean', 'max', 'min', 'std']\n",
    "    aggs['diff_date_from_hist_max_month'] = ['mean', 'max', 'min', 'std']\n",
    "\n",
    "#     col_unique =['subsector_id', 'merchant_id', 'merchant_category_id', 'yyyymmdd', 'yyyy_week']\n",
    "    \n",
    "#     df = pd.get_dummies(df, columns=['category_2', 'category_3'])\n",
    "#     aggs = {\n",
    "#     'category_1': ['sum', 'mean'],\n",
    "#     'category_2_1.0': ['mean'],\n",
    "#     'category_2_2.0': ['mean'],\n",
    "#     'category_2_3.0': ['mean'],\n",
    "#     'category_2_4.0': ['mean'],\n",
    "#     'category_2_5.0': ['mean'],\n",
    "#     'category_3_A': ['mean'],\n",
    "#     'category_3_B': ['mean'],\n",
    "#     'category_3_C': ['mean'],\n",
    "#     }\n",
    "    \n",
    "#     for col in col_unique:\n",
    "#         aggs[col] = ['nunique']\n",
    "\n",
    "    aggs['purchase_amount'] = ['sum','max','min','mean','var']\n",
    "#     aggs['installments'] = ['sum', 'max','mean','var']\n",
    "#     aggs['month_lag'] = ['max','min','mean','var']\n",
    "    aggs['month_diff'] = ['mean','var']\n",
    "#     aggs['card_id'] = ['size','count']\n",
    "    \n",
    "    if ('level_0' and 'index' not in df.columns) and key not in df.columns:\n",
    "        df.reset_index(inplace=True)\n",
    "    \n",
    "    new_columns = get_new_columns(fname, aggs)\n",
    "    \n",
    "    print('Aggregation Start!')\n",
    "    print(df.shape)\n",
    "    df_agg = df.groupby(key).agg(aggs)\n",
    "    df_agg.columns = new_columns\n",
    "    \n",
    "#     df_agg[f'{fname}_amount_sum_per_installments_sum'] = df_agg[f'{fname}_purchase_amount_sum'] / (df_agg[f'{fname}_installments_sum'] + 1.0)\n",
    "#     df_agg[f'{fname}_amount_mean_per_installments_mean'] = df_agg[f'{fname}_purchase_amount_mean'] / (df_agg[f'{fname}_installments_mean'] + 1.0)\n",
    "    \n",
    "    \n",
    "    #========================================================================\n",
    "    # monthly agg\n",
    "    #========================================================================\n",
    "    new_columns = get_new_columns(fname + '_monthly_avg', aggs)\n",
    "    month_agg = df.groupby([key, 'yyyymm']).agg(aggs)\n",
    "        \n",
    "    month_agg.columns = new_columns\n",
    "    month_agg = month_agg.reset_index().drop('yyyymm', axis=1).groupby([key]).mean()\n",
    "    \n",
    "#     train_test = train_test.join(df_agg)\n",
    "    train_test = train_test.join(df_agg).join(month_agg)\n",
    "    print(train_test.shape)\n",
    "    \n",
    "    # Save\n",
    "    elo_save_feature(prefix, train_test, feat_check=False)\n",
    "print('Complete!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 103.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 169.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(1560059, 30)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 1/12 [00:18<03:24, 18.62s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 102.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 163.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(25035393, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 2/12 [01:01<04:18, 25.84s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 102.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 170.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(218856, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 3/12 [01:16<03:24, 22.69s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 102.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 164.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(2959498, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 4/12 [01:39<03:01, 22.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 101.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 164.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(218537, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 5/12 [01:54<02:23, 20.46s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 102.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 164.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(3108324, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 6/12 [02:17<02:06, 21.09s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 104.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 173.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(201630, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 7/12 [02:32<01:36, 19.31s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 99.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 167.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(3321484, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 8/12 [02:54<01:21, 20.32s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 100.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 169.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(639023, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 9/12 [03:11<00:57, 19.27s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 103.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 171.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(9389306, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 10/12 [03:40<00:44, 22.20s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 98.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 164.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(1102976, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 11/12 [03:58<00:20, 20.87s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 103.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 168.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Start!\n",
      "(16335920, 29)\n",
      "(325540, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 12/12 [04:33<00:00, 25.14s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!!\n"
     ]
    }
   ],
   "source": [
    "hist_df_list = [\n",
    "auth1_cat1 \n",
    ",auth1_cat0 \n",
    ",auth1_cat1_lag0 \n",
    ",auth1_cat0_lag0 \n",
    ",auth1_cat1_lag1 \n",
    ",auth1_cat0_lag1 \n",
    ",auth1_cat1_lag2 \n",
    ",auth1_cat0_lag2 \n",
    ",auth1_cat1_lag02\n",
    ",auth1_cat0_lag02\n",
    ",auth1_cat1_lag05\n",
    ",auth1_cat0_lag05\n",
    "]\n",
    "\n",
    "\n",
    "hist_fname_list = [\n",
    "'auth1_cat1'\n",
    ",'auth1_cat0'\n",
    ",'auth1_cat1_lag0'\n",
    ",'auth1_cat0_lag0'\n",
    ",'auth1_cat1_lag1'\n",
    ",'auth1_cat0_lag1'\n",
    ",'auth1_cat1_lag2'\n",
    ",'auth1_cat0_lag2'\n",
    ",'auth1_cat1_lag02'\n",
    ",'auth1_cat0_lag02'\n",
    ",'auth1_cat1_lag05'\n",
    ",'auth1_cat0_lag05'\n",
    "]\n",
    "\n",
    "for df, fname in zip(tqdm(hist_df_list), hist_fname_list):\n",
    "    if debug:\n",
    "        df = df.head(3000)\n",
    "    \n",
    "    df_train = utils.read_df_pkl('../input/train0*')\n",
    "    df_test = utils.read_df_pkl('../input/test0*')\n",
    "    df_train.set_index(key, inplace=True)\n",
    "    df_test.set_index(key, inplace=True)\n",
    "    train_test = pd.concat([df_train, df_test], axis=0)\n",
    "    \n",
    "    # new\n",
    "    # new_first_buyと同じだな\n",
    "    # df['personal_new_elapsed_month'] = (df['new_purchase_month_min'] - df['first_active_month']).dt.days\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['diff_date_from_new_min_month'] = (df['new_purchase_month_min'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_new_max_month'] = (df['new_purchase_month_max'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_hist_min_month'] = (df['hist_purchase_month_min'] - df['purchase_date']).dt.days\n",
    "    df['diff_date_from_hist_max_month'] = (df['hist_purchase_month_max'] - df['purchase_date']).dt.days\n",
    "\n",
    "    df['month_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)//30\n",
    "    df['month_diff'] += df['month_lag']\n",
    "    \n",
    "    aggs = {}\n",
    "    aggs['diff_date_from_new_min_month'] = ['mean', 'max', 'min', 'std']\n",
    "    aggs['diff_date_from_new_max_month'] = ['mean', 'max', 'min', 'std']\n",
    "    aggs['diff_date_from_hist_min_month'] = ['mean', 'max', 'min', 'std']\n",
    "    aggs['diff_date_from_hist_max_month'] = ['mean', 'max', 'min', 'std']\n",
    "\n",
    "#     col_unique =['subsector_id', 'merchant_id', 'merchant_category_id', 'yyyymmdd', 'yyyy_week']\n",
    "    \n",
    "#     df = pd.get_dummies(df, columns=['category_2', 'category_3'])\n",
    "#     aggs = {\n",
    "#     'category_1': ['sum', 'mean'],\n",
    "#     'category_2_1.0': ['mean'],\n",
    "#     'category_2_2.0': ['mean'],\n",
    "#     'category_2_3.0': ['mean'],\n",
    "#     'category_2_4.0': ['mean'],\n",
    "#     'category_2_5.0': ['mean'],\n",
    "#     'category_3_A': ['mean'],\n",
    "#     'category_3_B': ['mean'],\n",
    "#     'category_3_C': ['mean'],\n",
    "#     }\n",
    "    \n",
    "#     for col in col_unique:\n",
    "#         aggs[col] = ['nunique']\n",
    "\n",
    "    aggs['purchase_amount'] = ['sum','max','min','mean','var']\n",
    "#     aggs['installments'] = ['sum', 'max','mean','var']\n",
    "#     aggs['month_lag'] = ['max','min','mean','var']\n",
    "    aggs['month_diff'] = ['mean','var']\n",
    "#     aggs['card_id'] = ['size','count']\n",
    "    \n",
    "    if ('level_0' and 'index' not in df.columns) and key not in df.columns:\n",
    "        df.reset_index(inplace=True)\n",
    "    \n",
    "    new_columns = get_new_columns(fname, aggs)\n",
    "    \n",
    "    print('Aggregation Start!')\n",
    "    print(df.shape)\n",
    "    df_agg = df.groupby(key).agg(aggs)\n",
    "    df_agg.columns = new_columns\n",
    "    \n",
    "#     df_agg[f'{fname}_amount_sum_per_installments_sum'] = df_agg[f'{fname}_purchase_amount_sum'] / (df_agg[f'{fname}_installments_sum'] + 1.0)\n",
    "#     df_agg[f'{fname}_amount_mean_per_installments_mean'] = df_agg[f'{fname}_purchase_amount_mean'] / (df_agg[f'{fname}_installments_mean'] + 1.0)\n",
    "    \n",
    "    \n",
    "    #========================================================================\n",
    "    # monthly agg\n",
    "    #========================================================================\n",
    "    new_columns = get_new_columns(fname + '_monthly_avg', aggs)\n",
    "    month_agg = df.groupby([key, 'yyyymm']).agg(aggs)\n",
    "        \n",
    "    month_agg.columns = new_columns\n",
    "    month_agg = month_agg.reset_index().drop('yyyymm', axis=1).groupby([key]).mean()\n",
    "    \n",
    "#     train_test = train_test.join(df_agg)\n",
    "    train_test = train_test.join(df_agg).join(month_agg)\n",
    "    print(train_test.shape)\n",
    "    \n",
    "    # Save\n",
    "    elo_save_feature(prefix, train_test, feat_check=False)\n",
    "print('Complete!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 53.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 4/39 [00:00<00:00, 36.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█▌        | 6/39 [00:00<00:03,  9.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██▊       | 11/39 [00:01<00:03,  8.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███▊      | 15/39 [00:02<00:03,  6.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████▋    | 22/39 [00:03<00:02,  6.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|███████▋  | 30/39 [00:04<00:01,  7.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 39/39 [00:04<00:00,  8.89it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325540, 961)\n"
     ]
    }
   ],
   "source": [
    "prefix = '206_pst'\n",
    "prefix = '306_pst'\n",
    "prefix = '406_pst'\n",
    "import glob\n",
    "# #========================================================================\n",
    "# # これは作成済のFeatureを読み込んで計算する\n",
    "# #========================================================================\n",
    "combi_list = [ \n",
    "    ['new_cat1', 'new_cat0']\n",
    "    ,['new_cat1_lag1', 'new_cat0_lag1']\n",
    "    ,['new_cat1_lag2', 'new_cat0_lag2']\n",
    "    ,['new_cat1', 'new_cat1_lag1'] \n",
    "    ,['new_cat1', 'auth1_cat1'] \n",
    "    \n",
    "    ,['new_cat1', 'auth1_cat1_lag0'] \n",
    "    ,['new_cat1', 'auth1_cat1_lag02'] \n",
    "    ,['new_cat1', 'auth1_cat1_lag05']  \n",
    "    ,['new_cat1', 'auth1_cat1_lag08']  \n",
    "    ,['new_cat1', 'auth1_cat1_lag011'] \n",
    "    \n",
    "    ,['new_cat0', 'new_cat0_lag1'] \n",
    "    ,['new_cat0', 'auth1_cat0'] \n",
    "    ,['new_cat0', 'auth1_cat0_lag0'] \n",
    "    ,['new_cat0', 'auth1_cat0_lag02'] \n",
    "    ,['new_cat0', 'auth1_cat0_lag05']  \n",
    "    ,['new_cat0', 'auth1_cat0_lag08']  \n",
    "    ,['new_cat0', 'auth1_cat0_lag011'] \n",
    "    \n",
    "    ,['auth1_cat1_lag0', 'auth1_cat0_lag0'] \n",
    "    ,['auth1_cat1_lag02', 'auth1_cat0_lag02'] \n",
    "    ,['auth1_cat1_lag05', 'auth1_cat0_lag05'] \n",
    "    ,['auth1_cat1_lag011', 'auth1_cat0_lag011'] \n",
    "    \n",
    "    ,['auth1_cat1_lag0', 'auth1_cat1_lag02'] \n",
    "    ,['auth1_cat0_lag0', 'auth1_cat0_lag02'] \n",
    "    ,['auth1_cat1_lag0', 'auth1_cat1_lag05'] \n",
    "    ,['auth1_cat0_lag0', 'auth1_cat0_lag05'] \n",
    "    ,['auth1_cat1_lag0', 'auth1_cat1_lag08'] \n",
    "    ,['auth1_cat0_lag0', 'auth1_cat0_lag08'] \n",
    "    ,['auth1_cat1_lag0', 'auth1_cat1_lag011'] \n",
    "    ,['auth1_cat0_lag0', 'auth1_cat0_lag011'] \n",
    "    \n",
    "    ,['auth1_cat1_lag02', 'auth1_cat1_lag05'] \n",
    "    ,['auth1_cat0_lag02', 'auth1_cat0_lag05'] \n",
    "    ,['auth1_cat1_lag02', 'auth1_cat1_lag08'] \n",
    "    ,['auth1_cat0_lag02', 'auth1_cat0_lag08'] \n",
    "    ,['auth1_cat1_lag02', 'auth1_cat1_lag011'] \n",
    "    ,['auth1_cat0_lag02', 'auth1_cat0_lag011'] \n",
    "    \n",
    "    ,['auth1_cat1_lag05', 'auth1_cat1_lag08'] \n",
    "    ,['auth1_cat0_lag05', 'auth1_cat0_lag08'] \n",
    "    ,['auth1_cat1_lag05', 'auth1_cat1_lag011'] \n",
    "    ,['auth1_cat0_lag05', 'auth1_cat0_lag011'] \n",
    "]\n",
    "\n",
    "comp_cols = [\n",
    "    'amount_sum_per_installments_sum'\n",
    "    ,'amount_mean_per_installments_mean'\n",
    "    ,'purchase_amount_sum' \n",
    "    ,'purchase_amount_mean' \n",
    "    ,'purchase_amount_max' \n",
    "    ,'purchase_amount_min' \n",
    "    ,'installments_max' \n",
    "    ,'installments_var' \n",
    "    ,'category_1_sum' \n",
    "    ,'category_1_mean' \n",
    "    ,'month_lag_mean' \n",
    "    ,'month_lag_var' \n",
    "    ,'month_lag_skew' \n",
    "    ,'month_diff_mean' \n",
    "    ,'month_diff_var' \n",
    "    ,'month_diff_skew' \n",
    "    ,'card_id_size' \n",
    "    ,'yyyymmdd_nunique'\n",
    "    ,'subsector_id_nunique'\n",
    "    ,'merchant_id_nunique'\n",
    "    ,'merchant_category_id_nunique'\n",
    "    ,'diff_date_from_new_min_month_mean'\n",
    "    ,'diff_date_from_hist_max_month_mean'\n",
    "    ,'diff_date_from_new_min_month_max'\n",
    "    ,'diff_date_from_hist_max_month_max'\n",
    "    ,'diff_date_from_new_min_month_min'\n",
    "    ,'diff_date_from_hist_min_month_min'\n",
    "]\n",
    "\n",
    "tmp_feature_list = glob.glob(f'../features/1_first_valid/{prefix}*.gz')\n",
    "feature_list = []\n",
    "for f in tmp_feature_list:\n",
    "    if f.count('pst_ratio_') or f.count('pst_diff_'):continue\n",
    "    for col in comp_cols:\n",
    "        if f.count(col):\n",
    "            feature_list.append(f)\n",
    "            \n",
    "base = utils.read_df_pkl('../input/base_first*0*')\n",
    "p_list = utils.parallel_load_data(path_list=feature_list)\n",
    "df_feat = pd.concat(p_list, axis=1)\n",
    "train_test = pd.concat([base[key], df_feat], axis=1)\n",
    "\n",
    "for (fm1, fm2) in tqdm(combi_list):\n",
    "    for col in comp_cols:\n",
    "#         203_pst_auth0_lag02_monthly_avg_purchase_amount_min\n",
    "        try:\n",
    "            train_test[f\"ratio_{fm1}_{fm2}_{col}\"] = train_test[f\"{prefix}_{fm1}_{col}@\"] / train_test[f\"{prefix}_{fm2}_{col}@\"]\n",
    "            train_test[f\"diff_{fm1}_{fm2}_{col}\"] = train_test[f\"{prefix}_{fm1}_{col}@\"] - train_test[f\"{prefix}_{fm2}_{col}@\"]\n",
    "        except KeyError:\n",
    "#             print(fm1, fm2, col)\n",
    "            continue\n",
    "        \n",
    "print(train_test.shape)\n",
    "\n",
    "ratio_diff_cols = [col for col in train_test.columns if col[:5]=='ratio' or col[:4]=='diff']\n",
    "elo_save_feature(prefix, train_test[ratio_diff_cols], feat_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save Feature\n",
    "# train_test = train_test.join(hist_max_date).join(hist_min_date).join(new_max_date).join(new_min_date)\n",
    "# train_test['hist_purchase_month_max'] = pd.to_datetime(train_test['hist_purchase_month_max'])\n",
    "# train_test['hist_purchase_month_min'] = pd.to_datetime(train_test['hist_purchase_month_min'])\n",
    "# train_test['new_purchase_month_max'] = pd.to_datetime(train_test['new_purchase_month_max'])\n",
    "# train_test['new_purchase_month_min'] = pd.to_datetime(train_test['new_purchase_month_min'])\n",
    "# train_test.head()\n",
    "\n",
    "# # 静的なFeature\n",
    "# train_test['personal_term_new_min_hist_max'] = (train_test['new_purchase_month_min'] - train_test['hist_purchase_month_max']).dt.days\n",
    "# train_test['personal_term_new_min_hist_min'] = (train_test['new_purchase_month_min'] - train_test['hist_purchase_month_min']).dt.days\n",
    "# train_test['personal_days_new_max_date_from_hist_max_month'] = (train_test['new_purchase_date_max'] - train_test['hist_purchase_month_max']).dt.days\n",
    "# train_test['personal_days_new_min_date_from_hist_max_month'] = (train_test['new_purchase_date_min'] - train_test['hist_purchase_month_max']).dt.days\n",
    "        \n",
    "prefix = '206_cop'\n",
    "ignore_features = ['first_active_month', 'card_id', target]\n",
    "\n",
    "for col in train_test.columns:\n",
    "    if col in ignore_features: continue\n",
    "    if col.count('203_'):continue\n",
    "    if not(col.count('ratio_new')) and not(col.count('diff_new')) and not(col.count('ratio_auth')) and not(col.count('diff_auth')) :continue\n",
    "    feature = train_test[col].astype('float32').values\n",
    "    if np.std(feature)==0:\n",
    "        continue\n",
    "    \n",
    "    utils.to_pkl_gzip(path = f'../features/1_first_valid/{prefix}_{col}@', obj=feature)\n",
    "#     utils.to_pkl_gzip(path = f'../features/1_first_valid/{prefix}_{col}@', obj=feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
