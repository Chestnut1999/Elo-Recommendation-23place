{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import datetime, itertools, zipfile, os, time, psutil, gc, sys\n",
    "from datetime import date, timedelta\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "sys.path.append('../input/my-temp-files/')\n",
    "    \n",
    "import alml2 as alml\n",
    "\n",
    "RS = alml.rs(0)\n",
    "\n",
    "SUBMIT = False\n",
    "SUBMIT = True\n",
    "\n",
    "MODELX = 'A' #A - best LB, B - alternative, C - best CV\n",
    "\n",
    "#3.681205\n",
    "#3.677905 - 3.722\n",
    "#3.666167 - 3.708\n",
    "#3.662555 - 3.707\n",
    "#3.655946 - 3.699\n",
    "#3.655045 - 3.699 (little bit better)\n",
    "#3.653728 - 3.697\n",
    "#3.650593 - 3.692\n",
    "#3.650871 - 3.689\n",
    "#3.646806 - 3.687 (m_h)\n",
    "#3.646362 - 3.687 (-2 feats)\n",
    "#3.644921 - 3.684 (hist m1 feats)\n",
    "#3.644489 - 3.684 better (new m1 feat)\n",
    "#3.643781 - 3.684 better (add aggs month_diff) <<<\n",
    "#3.642602 - 3.685 - C mod\n",
    "#3.642493 - 3.683 - min/max dates to weeks\n",
    "#3.641609 - 3.682 CB - feat 1-2 interaction (RS=1 3.642509)(RS=2 3.643232)\n",
    "\n",
    "ROUNDS = 1000\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "\tscore = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\treturn score\n",
    "\n",
    "NROWS = None\n",
    "NROWS_VAL = None\n",
    "if 0:\n",
    "\tNROWS = 100000 #None \n",
    "\tNROWS_VAL = 20000\n",
    "\n",
    "MODELS = ['lgb']\n",
    "#MODELS = ['lgb','rfr','lnr','lasso','ridge','abr','etr','gbr']\n",
    "#MODELS = ['ridge']\n",
    "\n",
    "MODELS2 = ['lgb']\n",
    "LEVEL = 1 \n",
    "\n",
    "BAGS = 0 if SUBMIT else 0\n",
    "FOLDS = 5\n",
    "EARLY_STOPPING = 100 #100\n",
    "\n",
    "if LEVEL == 2:\n",
    "\tFOLDS = 0\n",
    "\tMODELS = MODELS2\n",
    "\n",
    "# XGB\n",
    "params1 = {}\n",
    "params1['objective'] = 'binary:logistic'\t\t#'binary:logistic'\n",
    "params1['eval_metric'] = 'auc'\t\t\t#'logloss'\n",
    "params1['eta'] = 0.04\n",
    "params1['max_depth'] = 7\n",
    "params1['silent'] = 1\n",
    "params1['subsample'] = 0.8\n",
    "params1['subsample_bytree'] = 0.7\n",
    "#params1['subsample_bylevel'] = 0.7\n",
    "params1['num_rounds'] = 30 #100\n",
    "\n",
    "#LightGBM\n",
    "params2 = {}\n",
    "params2['objective'] = 'regression' #'regression'\n",
    "params2['metric'] = 'rmse'\t\t#'multi_logloss', 'binary_logloss'\n",
    "params2['boosting'] = 'gbdt' #'gbdt'\n",
    "params2['learning_rate'] = 0.03 #0.2\n",
    "params2['verbose'] = -1\n",
    "#params2['num_class'] = 6\n",
    "params2['num_leaves'] = 63 # 1:2 2:4 3:8 4:16 5:32 6:64 7:128 8:256\n",
    "params2['bagging_fraction'] = 0.8\n",
    "params2['bagging_freq'] = 1\n",
    "params2['bagging_seed'] = RS\n",
    "params2['feature_fraction'] = 0.7\n",
    "#params2['colsample_bytree'] = 0.05\n",
    "params2['feature_fraction_seed'] = RS\n",
    "#params2['scale_pos_weight'] = 10\n",
    "#params2['max_bin'] = 300\n",
    "params2['max_depth'] = 7 #6 #s-1\n",
    "params2['min_child_samples'] = 90\n",
    "#params2['min_gain_to_split'] = 0.5\n",
    "#params2['reg_lambda'] = 0.1\n",
    "params2['reg_alpha'] = 0.1\n",
    "params2['num_rounds'] = ROUNDS\n",
    "#params2['tree_learner'] = 'voting'\n",
    "params2['feature_name'] = 'auto'\n",
    "#params2['categorical_feature'] = [\"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\", \"param_1\", \"param_2\", \"param_3\"]\n",
    "#params2['histogram_pool_size'] = 8000\n",
    "\n",
    "params3 = {}\n",
    "params3['n_jobs'] = 2\n",
    "params3['n_estimators'] = 100\n",
    "params3['max_depth'] = 5\n",
    "params3['verbose'] = 0\n",
    "params3['learning_rate'] = 0.1\n",
    "\n",
    "if LEVEL == 2:\n",
    "\t#XGB\n",
    "\tROUNDS = 980\n",
    "\n",
    "CONFIG = []\n",
    "if 'lgb' in MODELS:\n",
    "\tCONFIG.append({'model': 'lgb','params': params2,})\n",
    "if 'etr' in MODELS:\n",
    "\tCONFIG.append({'model': 'etr','params': params3,})\n",
    "if 'abr' in MODELS:\n",
    "\tCONFIG.append({'model': 'abr','params': params3,})\n",
    "if 'gbr' in MODELS:\n",
    "\tCONFIG.append({'model': 'gbr','params': params3,})\n",
    "if 'xgb' in MODELS:\n",
    "\tCONFIG.append({'model': 'xgb','params': params1,})\n",
    "if 'rfr' in MODELS:\n",
    "\tCONFIG.append({'model': 'rfr','params': params3,})\n",
    "if 'lasso' in MODELS:\n",
    "\tCONFIG.append({'model': 'lasso','params': params3,})\n",
    "if 'ridge' in MODELS:\n",
    "\tCONFIG.append({'model': 'ridge','params': params3,})\n",
    "if 'lnr' in MODELS:\n",
    "\tCONFIG.append({'model': 'lnr','params': params3,})\n",
    "\n",
    "print(\"Started {}\".format(\"SUBMIT\" if SUBMIT else \"TEST\"))\n",
    "print(psutil.virtual_memory())\n",
    "target = 'target'\n",
    "scorefn = rmse\n",
    "feats_not_to_use = ['card_id', target, 'first_active_month']\n",
    "cat_vars = [] \n",
    "\n",
    "def procfeats(df):\n",
    "\treturn df\n",
    "\t\n",
    "def add_feat(df, num, name, cols=None):\n",
    "\tft = pd.read_pickle('{}.pkl'.format(name))\n",
    "\tif cols is not None:\n",
    "\t\tft = ft[['card_id'] + cols]\n",
    "\tft.columns = ['f{}_{}'.format(num, x) if x != 'card_id' else x for x in ft.columns]\n",
    "\tdf = df.merge(ft, how='left', on='card_id')\n",
    "\tprint(num,'Added',ft.shape,'features, current:',df.shape)\n",
    "\treturn df\n",
    "\n",
    "def add_submodel(df, name, feat=None):\n",
    "\tusecols = None if feat is None else ['card_id']+feat\n",
    "\tcv = pd.read_csv('runs/cv_{}.csv'.format(name), usecols=usecols)\n",
    "\tte = pd.read_csv('runs/test_{}.csv'.format(name), usecols=usecols)\n",
    "\tif 0:\n",
    "\t\tcv = cv[cv['submodel_2a_size'] > 3]\n",
    "\t\tte = te[te['submodel_2a_size'] > 3]\n",
    "\tcvte = pd.concat([cv, te]).reset_index(drop=True) #[['card_id','submodel_2a_min']]\n",
    "\tdf = df.merge(cvte, how='left', on='card_id')\n",
    "\tprint('Got',name,'with cv:',cv.shape,'test:',te.shape,'total:',cvte.shape,'current:',df.shape)\n",
    "\treturn df\n",
    "\n",
    "df = pd.read_pickle('../input/my-temp-files/feats_0001.pkl')\n",
    "df_train = df[df['target'] != -999][['card_id','target']]\n",
    "df_test = df[df['target'] == -999][['card_id','target']]\n",
    "pos = df_train.shape[0]\n",
    "\t\n",
    "if 0: #most correlated features\n",
    "\tdf['out'] = df['target'].apply(lambda x: 1 if x < -20 else 0)\n",
    "\ttmp = df.corr()\n",
    "\ttmpt = tmp['target'].sort_values()\n",
    "\tprint(tmpt)\n",
    "\ttmpt = tmp['out'].sort_values()\n",
    "\tprint(tmpt)\n",
    "\texit()\n",
    "\t\n",
    "print(df.dtypes)\n",
    "cat_vars = [f for f in df.columns if df[f].dtype == 'object' and f not in feats_not_to_use]\n",
    "print('Categorical:',cat_vars)\n",
    "\n",
    "for col in cat_vars:\n",
    "\tlbl = LabelEncoder()\n",
    "\tdf[col] = lbl.fit_transform(df[col].values.astype('str'))\n",
    "\n",
    "if 0:\n",
    "\tdf, _, ffeats = alml.fe_cat_to_ohe(df, None, cat_vars)\n",
    "\tdf.drop(cat_vars, axis=1, inplace=True)\n",
    "\t\n",
    "print(df.head())\n",
    "\t\n",
    "x_train = df[:pos].reset_index(drop=True)\n",
    "x_test = df[pos:].reset_index(drop=True)\t\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "#x_train, x_test, _ = alml.proc_add_noise(x_train, x_test, on=['binary_preds'], frac=2)\n",
    "\n",
    "#x_train, x_test, _ = alml.fe_num_means_by_cat(x_train, x_test, x_train[target].values, on=['feature_1'], stat_col='diff_dates_in_max', prefix='tgenc', n_folds=5, stratify=False, type='mean')\n",
    "#x_train, x_test, _ = alml.fe_target_encoding(x_train, x_test, x_train[target].values, on=['feature_2'], stat_col=None, prefix='tgenc', n_folds=5, stratify=False, type='mean')\n",
    "#x_train, x_test, _ = alml.fe_target_encoding(x_train, x_test, x_train[target].values, on=['feature_3'], stat_col=None, prefix='tgenc', n_folds=5, stratify=False, type='mean')\n",
    "#feats_not_to_use.append('feature_1')\n",
    "\n",
    "use = [x for x in x_train.columns.values if x not in feats_not_to_use]\n",
    "x_train = x_train[use]\n",
    "x_test = x_test[use]\n",
    "train_y = df_train[target].values\n",
    "#train_y = np.abs(df_train[target].values)\n",
    "#train_y = np.log(np.exp2(df_train[target].values))\n",
    "\n",
    "print('Training on',x_train.shape, train_y.shape ,'testing on',x_test.shape)\t\n",
    "params2['categorical_feature'] = [x for x in cat_vars if x in use]\n",
    "print('Categorical:',params2['categorical_feature'])\t\n",
    "\n",
    "gc.collect()\n",
    "print(psutil.virtual_memory())\n",
    "if 0:\n",
    "\talml.features_eliminator(x_train, train_y, CONFIG[0]['params'], seed=RS, bags=2, score_fn=scorefn, logname='features_eliminator.txt')\n",
    "\tprint('elimination done')\n",
    "\texit()\n",
    "if 0:\n",
    "\talml.features_eliminator2(x_train, train_y, CONFIG[0]['params'], seed=RS, folds=FOLDS, score_fn=scorefn, logname='features_eliminator.txt', early_stopping=EARLY_STOPPING)\n",
    "\tprint('elimination done')\n",
    "\texit()\n",
    "STRATIFYBY = False #True\n",
    "if STRATIFYBY:\n",
    "\tx_train['is_outlier'] = (train_y < -20).astype(int)\n",
    "\tprint(x_train.head())\n",
    "preds, preds_cv, models, preds_cv_cols = alml.ml(x_train, train_y, x_test, CONFIG, None, True, BAGS, FOLDS, score_fn=scorefn, stratify=STRATIFYBY, early_stopping=EARLY_STOPPING)\n",
    "\t\n",
    "del x_train, train_y\n",
    "gc.collect()\n",
    "\n",
    "now = str(datetime.datetime.now().strftime(\"%m%d%H%M\"))\n",
    "tf = 'm1_preds_%s.' % now\n",
    "\t\n",
    "if 1:\n",
    "\tdf_test['target'] = preds\n",
    "\tdf_test = df_test[['card_id','target']]\n",
    "\tprint(df_test.head())\n",
    "\tprint(df_test.tail())\n",
    "\t\n",
    "\tprint('\\nPreparing submission...')\n",
    "\n",
    "\tprint(\"Writing output...\")\n",
    "\tdf_test.to_csv(tf + 'csv', index=False)\n",
    "\n",
    "\tprint(df_test.describe())\n",
    "\tprint(df_test.shape)\n",
    "\n",
    "\tdf_train['preds'] = preds_cv\n",
    "\t\n",
    "\tprint('\\n----- biggest errors')\n",
    "\tdf_train['error'] = (df_train['preds'] - df_train[target]) ** 2\n",
    "\tprint(df_train.sort_values('error', ascending=False).head(10))\n",
    "\t#df_train.sort_values('error', ascending=False).head(300).to_csv('outliers.csv', index=False)\n",
    "\t\n",
    "\tprint('\\n----- lowest preds')\n",
    "\tprint(df_train.sort_values('preds', ascending=True).head(20))\n",
    "\t\n",
    "\tprint('Score full on',df_train.shape[0],'entries',rmse(df_train[target],df_train['preds']))\n",
    "\n",
    "\tdf_train = df_train[['card_id','target','preds']]\n",
    "\tsavename = 'cv_' + tf + 'csv'\n",
    "\tprint('\\nPreparing tosave',df_train.shape)\n",
    "\tprint(df_train.head())\n",
    "\tdf_train.to_csv(savename, index=False)\n",
    "\tprint('CV saved to',savename)\n",
    "\t\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
