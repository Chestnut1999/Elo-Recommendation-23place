{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "import re\n",
    "import gc\n",
    "import glob\n",
    "\n",
    "import os\n",
    "HOME = os.path.expanduser('~')\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "import utils\n",
    "from utils import logger_func\n",
    "logger = logger_func()\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "path_list = glob.glob('../stack/*.gz')\n",
    "import pickle\n",
    "import datetime\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_active_month', 'index', 'personal_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "col_term = 'hist_regist_term'\n",
    "base = utils.read_df_pkl('../input/base_term*')[[key, target, col_term]]\n",
    "# Indexをそろえる\n",
    "base_model_path = '../stack/0207_200_stack_lgb_lr0.01_235feats_10seed_70leaves_iter1870_OUT0_CV1-5500865669760113_LB.gz'\n",
    "best_model = utils.read_pkl_gzip(base_model_path)\n",
    "base_idx = train[[key, col_term]]\n",
    "best_model = base_idx.merge(best_model, how='inner', on=key)\n",
    "\n",
    "best_model[col_term] = best_model[col_term].map(lambda x: \n",
    "                                          6 if 6<=x and x<=8  else \n",
    "                                          9 if 9<=x and x<=12\n",
    "                                          else x\n",
    "                                         )\n",
    "base[col_term] = base[col_term].map(lambda x: \n",
    "                                          6 if 6<=x and x<=8  else \n",
    "                                          9 if 9<=x and x<=12\n",
    "                                          else x\n",
    "                                         )\n",
    "train = base[~base[target].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "ratio_list = []\n",
    "blend_path_list = glob.glob('../stack/*.gz')\n",
    "\n",
    "base = base[base[target]>-30]\n",
    "best_model = best_model[best_model[target]>-30]\n",
    "y_train = base[~base[target].isnull()][target].values\n",
    "best_pred = best_model['pred_mean'].values[:len(y_train)]\n",
    "best_score = np.sqrt(mean_squared_error(y_train, best_pred))\n",
    "print(f\"Best Score: {best_score}\")\n",
    "sys.exit()\n",
    "\n",
    "for i, path in enumerate(blend_path_list):\n",
    "    tmp = utils.read_pkl_gzip(path)\n",
    "    tmp = base_idx.merge(tmp, how='inner', on=key)\n",
    "    \n",
    "    if 'pred_mean' in tmp.columns:\n",
    "        tmp_pred = tmp['pred_mean'].values\n",
    "    else:\n",
    "        tmp_pred = tmp['prediction'].values\n",
    "    del tmp\n",
    "    gc.collect()\n",
    "    \n",
    "    tmp_pred = tmp_pred[:len(train)]\n",
    "    tmp_score_list = []\n",
    "    min_score = 100\n",
    "    for ratio in np.arange(0.1, 1.0, 0.1):\n",
    "        stack_pred = best_pred * ratio + tmp_pred * (1-ratio)\n",
    "        y_pred = stack_pred[:len(y_train)]\n",
    "    \n",
    "        score = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "        if score<min_score:\n",
    "            min_score = score\n",
    "            min_ratio = ratio\n",
    "            \n",
    "    score_list.append(min_score)\n",
    "    ratio_list.append(min_ratio)\n",
    "    \n",
    "    if i%10==0:\n",
    "#         print(f\"BEST: {np.min(score_list)} | BEST RATIO: {ratio_list[np.argmin(score_list)]} | WORST: {np.max(score_list)} | WORST RATIO: {ratio_list[np.argmax(score_list)]}\")\n",
    "        print(f\"BEST: {np.min(score_list)} | BEST RATIO: {ratio_list[np.argmin(score_list)]} | PATH: {blend_path_list[np.argmin(score_list)]}\")\n",
    "    \n",
    "print(\"Complete!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201917"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[col_term].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27823\n",
      "41947\n",
      "77568\n",
      "119280\n",
      "133585\n",
      "149928\n",
      "168280\n"
     ]
    }
   ],
   "source": [
    "outlier_thres = -3\n",
    "term4  = train[train[col_term] == 4]\n",
    "term5  = train[train[col_term] == 5]\n",
    "term6  = train[train[col_term] == 6]\n",
    "term9  = train[train[col_term] == 9]\n",
    "term15  = train[train[col_term] == 15]\n",
    "term18  = train[train[col_term] == 18]\n",
    "term24  = train[train[col_term] == 24]\n",
    "\n",
    "df_list = [\n",
    "term4    \n",
    ",term5 \n",
    ",term6    \n",
    ",term9    \n",
    ",term15   \n",
    ",term18   \n",
    ",term24   \n",
    "]\n",
    "\n",
    "\n",
    "trn_idx_list = []\n",
    "val_idx_list = []\n",
    "train_dict = {}\n",
    "valid_dict = {}\n",
    "for df in df_list:\n",
    "    plus  = df[df[target] >= 0]\n",
    "    tmp_minus = df[df[target] <  0]\n",
    "    minus = tmp_minus[tmp_minus[target] >  -30]\n",
    "    out = tmp_minus[tmp_minus[target] <  -30]\n",
    "\n",
    "    plus['outliers'] = plus[target].map(lambda x: 1 if x>=outlier_thres*-1 else 0)\n",
    "    minus['outliers'] = minus[target].map(lambda x: 1 if x<=outlier_thres else 0)\n",
    "    out['outliers'] = out[target].map(lambda x: 1 if x<=outlier_thres else 0)\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=fold, shuffle=True, random_state=seed)\n",
    "    kfold_plus = folds.split(plus, plus['outliers'].values)\n",
    "    kfold_minus = folds.split(minus, minus['outliers'].values)\n",
    "    kfold_out = folds.split(out, out['outliers'].values)\n",
    "    \n",
    "    for i, ((p_trn_idx, p_val_idx), (m_trn_idx, m_val_idx), (o_trn_idx, o_val_idx)) in enumerate(zip(kfold_plus, kfold_minus, kfold_out)):\n",
    "    \n",
    "        def get_ids(df, idx):\n",
    "            ids = list(df.iloc[idx, :][key].values)\n",
    "            return ids\n",
    "    \n",
    "        trn_ids = get_ids(plus, p_trn_idx) + get_ids(minus, m_trn_idx) + get_ids(out, o_trn_idx)\n",
    "        val_ids = get_ids(plus, p_val_idx) + get_ids(minus, m_val_idx) + get_ids(out, o_val_idx)\n",
    "    \n",
    "        # idをindexの番号にする\n",
    "        trn_ids = list(train[train[key].isin(trn_ids)].index)\n",
    "        val_ids = list(train[train[key].isin(val_ids)].index)\n",
    "    \n",
    "#         trn_idx_list.append(trn_ids)\n",
    "#         val_idx_list.append(val_ids)\n",
    "        if i not in train_dict:\n",
    "            train_dict[i] = trn_ids\n",
    "            valid_dict[i] = val_ids\n",
    "        else:\n",
    "            train_dict[i] += trn_ids\n",
    "            valid_dict[i] += val_ids\n",
    "    print(len(train_dict[i]))\n",
    "# kfold = zip([trn_idx_list], [val_idx_list])\n",
    "kfold = list(zip(train_dict.values(), valid_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325540, 3)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.read_pkl_gzip( '../stack/0208_071_stack_lgb_lr0.01_235feats_multi10_valterm_1seed_71leaves_iter1097_TERM18_CV3-4609004004622372_LB.gz').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../input/sample_submission.csv')\n",
    "submit['target'] = blending\n",
    "\n",
    "clf = utils.read_pkl_gzip('../stack/0112_155_outlier_classify_9seed_lgb_binary_CV0-9047260065151934_200features.gz')\n",
    "clf = clf.iloc[-len(submit):, ].reset_index(drop=True)\n",
    "submit.loc[clf.prediction>0.45, 'target'] = -33.1\n",
    "\n",
    "\n",
    "submit.to_csv(f'../submit/{start_time[4:12]}_elo_{len(blend_list)}blender_outlier_clf0.45_postprocessing.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
