{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 23:38:16,354 utils 340 [INFO]    [logger_func] start \n",
      "2019-02-26 23:38:16,354 utils 340 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "import re\n",
    "import gc\n",
    "import glob\n",
    "\n",
    "import os\n",
    "HOME = os.path.expanduser('~')\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "import utils\n",
    "from utils import logger_func\n",
    "logger = logger_func()\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "path_list = glob.glob('../stack/*.gz')\n",
    "import pickle\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_active_month', 'index', 'personal_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# threshold scoring\n",
    "def get_part_of_score(df, pred_col, thres_col, threshold):\n",
    "    \n",
    "    y_pred  = df.loc[df[thres_col]>=threshold, pred_col].values\n",
    "    y_train = df.loc[df[thres_col]>=threshold, target].values\n",
    "    upper_score = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "    \n",
    "    y_pred  = df.loc[df[thres_col]<threshold, pred_col].values\n",
    "    y_train = df.loc[df[thres_col]<threshold, target].values\n",
    "    lower_score = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "    \n",
    "    return upper_score, lower_score\n",
    "#========================================================================\n",
    "    \n",
    "#========================================================================\n",
    "# Outlier Postprocessing\n",
    "def get_submit(base, is_blend=False, min_thres=0):\n",
    "\n",
    "    # Classifier Thresfold\n",
    "    if not(is_blend):\n",
    "        \n",
    "        pred = 'prediction'\n",
    "        with_outlier = 'base_pred'\n",
    "        col_list = []\n",
    "        score_list = []\n",
    "        #========================================================================\n",
    "        # base pred\n",
    "        base_cols = [col for col in base.columns if col.count('base_')]\n",
    "        base[pred] = base[base_cols]\n",
    "        base[with_outlier] = base[base_cols]\n",
    "        \n",
    "        upper_score, lower_score = get_part_of_score(df=base[~base[target].isnull()], pred_col=pred, thres_col='clf_pred', threshold=min_thres)\n",
    "        print(f\"Base Upper Score: {upper_score} | Base Lower Score: {lower_score}\")\n",
    "        col_list += ['base_upper', 'base_lower']\n",
    "        score_list += [upper_score, lower_score]\n",
    "        #========================================================================\n",
    "        \n",
    "        #========================================================================\n",
    "        # Remove Out\n",
    "        \n",
    "#         flg0_type1 = (base['type']==1) & (base['no_out_flg']==0)\n",
    "#         flg1_type1 = (base['type']==1) & (base['no_out_flg']==1)\n",
    "        # Low Outlier Ratio\n",
    "        type0_flg0_lower = ( (base['type']==0) & (base['no_out_flg']==0) ) & (base['clf_pred']<min_thres)\n",
    "        type0_flg1_lower = ( (base['type']==0) & (base['no_out_flg']==1) ) & (base['clf_pred']<min_thres)\n",
    "        type1_flg0_lower = ( (base['type']==1) & (base['no_out_flg']==0) ) & (base['clf_pred']<min_thres)\n",
    "        type1_flg1_lower = ( (base['type']==1) & (base['no_out_flg']==1) ) & (base['clf_pred']<min_thres)\n",
    "        type2_flg0_lower = ( (base['type']==2) & (base['no_out_flg']==0) ) & (base['clf_pred']<min_thres)\n",
    "        type2_flg1_lower = ( (base['type']==2) & (base['no_out_flg']==1) ) & (base['clf_pred']<min_thres)\n",
    "        \n",
    "#         # High Outlier Ratio\n",
    "        type0_flg0_higher = ( (base['type']==0) & (base['no_out_flg']==0) ) & (base['clf_pred']>=min_thres)\n",
    "        type0_flg1_higher = ( (base['type']==0) & (base['no_out_flg']==1) ) & (base['clf_pred']>=min_thres)\n",
    "        type1_flg0_higher = ( (base['type']==1) & (base['no_out_flg']==0) ) & (base['clf_pred']>=min_thres)\n",
    "        type1_flg1_higher = ( (base['type']==1) & (base['no_out_flg']==1) ) & (base['clf_pred']>=min_thres)\n",
    "        type2_flg0_higher = ( (base['type']==2) & (base['no_out_flg']==0) ) & (base['clf_pred']>=min_thres)\n",
    "        type2_flg1_higher = ( (base['type']==2) & (base['no_out_flg']==1) ) & (base['clf_pred']>=min_thres)\n",
    "        type10 = (base['type']==10)\n",
    "\n",
    "        lower_clf = (base['clf_pred']<min__thres)\n",
    "        flg1 = (base['no_out_flg']==1)\n",
    "        \n",
    "        if len(rm_out_cols):\n",
    "            rm_out_pred = 'rm_out_pred'\n",
    "            base[rm_out_pred] = base[rm_out_cols[0]]\n",
    "            \n",
    "            base.loc[lower_clf, pred] =  base.loc[lower_clf, rm_out_pred]\n",
    "            base.loc[flg1, pred] =  base.loc[flg1, rm_out_pred]\n",
    "            base.loc[type10, pred] =  base.loc[type10, rm_out_pred]\n",
    "#             base.loc[type2_flg1_lower, pred] =  base.loc[type2_flg1_lower, rm_out_pred]*1.0\n",
    "#             base.loc[type10, pred] =  base.loc[type10, rm_out_pred]*1.0\n",
    "#             base.loc[type2_flg1_higher, pred] =  base.loc[type2_flg1_higher, rm_out_pred]*1.0\n",
    "            \n",
    "#             base.loc[type0_flg0_lower, pred] =  base.loc[type0_flg0_lower, with_outlier]*0.3 + base.loc[type0_flg0_lower, rm_out_pred]*0.7\n",
    "#             base.loc[type0_flg1_lower, pred] =  base.loc[type0_flg1_lower, with_outlier]*0.1 + base.loc[type0_flg1_lower, rm_out_pred]*0.9\n",
    "#             base.loc[type1_flg0_lower, pred] =  base.loc[type1_flg0_lower, with_outlier]*0.9 + base.loc[type1_flg0_lower, rm_out_pred]*0.1\n",
    "#             base.loc[type1_flg1_lower, pred] =  base.loc[type1_flg1_lower, with_outlier]*0.95 + base.loc[type1_flg1_lower, rm_out_pred]*0.05\n",
    "#             base.loc[type2_flg0_lower, pred] =  base.loc[type2_flg0_lower, with_outlier]*1.0 + base.loc[type2_flg0_lower, rm_out_pred]*0.0\n",
    "#             base.loc[type2_flg1_lower, pred] =  base.loc[type2_flg1_lower, with_outlier]*0.0 + base.loc[type2_flg1_lower, rm_out_pred]*1.0\n",
    "            \n",
    "#             base.loc[type10, pred] =  base.loc[type10, with_outlier]*0.0 + base.loc[type10, rm_out_pred]*1.0\n",
    "            \n",
    "#             base.loc[type0_flg0_higher, pred] =  base.loc[type0_flg0_higher, with_outlier]*1.0 + base.loc[type0_flg0_higher, rm_out_pred]*0.0\n",
    "#             base.loc[type0_flg1_higher, pred] =  base.loc[type0_flg1_higher, with_outlier]*0.0 + base.loc[type0_flg1_higher, rm_out_pred]*1.0\n",
    "#             base.loc[type1_flg0_higher, pred] =  base.loc[type1_flg0_higher, with_outlier]*1.0 + base.loc[type1_flg0_higher, rm_out_pred]*0.0\n",
    "#             base.loc[type1_flg1_higher, pred] =  base.loc[type1_flg1_higher, with_outlier]*0.0 + base.loc[type1_flg1_higher, rm_out_pred]*1.0\n",
    "#             base.loc[type2_flg0_higher, pred] =  base.loc[type2_flg0_higher, with_outlier]*1.0 + base.loc[type2_flg0_higher, rm_out_pred]*0.0\n",
    "#             base.loc[type2_flg1_higher, pred] =  base.loc[type2_flg1_higher, with_outlier]*0.0 + base.loc[type2_flg1_higher, rm_out_pred]*1.0\n",
    "    \n",
    "            upper_score, lower_score = get_part_of_score(df=base[~base[target].isnull()], pred_col=rm_out_pred, thres_col='clf_pred', threshold=min_thres)\n",
    "            print(f\"Rm Out Upper Score: {upper_score} | Rm Out Lower Score: {lower_score}\")\n",
    "            col_list += ['rm_out_upper', 'rm_out_lower']\n",
    "            score_list += [upper_score, lower_score]\n",
    "        #========================================================================\n",
    "        \n",
    "    # Simple Blender \n",
    "    else:\n",
    "        base[pred] = base[pred_cols].mean(axis=1)\n",
    "        out_cols = []\n",
    "        min_thres = 0\n",
    "    \n",
    "    train = base[~base[target].isnull()]\n",
    "    y_pred = train[pred].values\n",
    "    y_train = train[target].values\n",
    "    score = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "    \n",
    "    #=======================================================================\n",
    "    # Out Score \n",
    "    train.reset_index(inplace=True)\n",
    "    out_score = get_part_of_score(df=train, pred_col=pred, thres_col=target, threshold=-30)\n",
    "    #========================================================================\n",
    "    print(f'''\n",
    "    #========================================================================\n",
    "    # CV SCORE AVG: {score}\n",
    "    # OUT SCORE: {out_score}\n",
    "    #========================================================================''')\n",
    "    col_list += ['cv_score', 'out_score']\n",
    "    score_list += [score, out_score]\n",
    "    result = pd.Series(index=col_list, data=score_list)\n",
    "    \n",
    "    return result\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>clf_pred</th>\n",
       "      <th>no_out_flg</th>\n",
       "      <th>type</th>\n",
       "      <th>base_3-611945069509424</th>\n",
       "      <th>lgb_rm_out_1-5441726427695084_LB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_92a2005557</th>\n",
       "      <td>-0.820283</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.335461</td>\n",
       "      <td>-0.321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_3d0044924f</th>\n",
       "      <td>0.392913</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.648348</td>\n",
       "      <td>0.147586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_d639edf6cd</th>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.723076</td>\n",
       "      <td>0.776194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_186d6a6901</th>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.183964</td>\n",
       "      <td>0.228009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_cdbd2c0db2</th>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.100282</td>\n",
       "      <td>-0.272186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   target  clf_pred  no_out_flg  type  base_3-611945069509424  \\\n",
       "card_id                                                                         \n",
       "C_ID_92a2005557 -0.820283  0.000444         1.0     2               -0.335461   \n",
       "C_ID_3d0044924f  0.392913  0.007831         0.0     0               -0.648348   \n",
       "C_ID_d639edf6cd  0.688056  0.004074         0.0     2                0.723076   \n",
       "C_ID_186d6a6901  0.142495  0.000797         0.0     2                0.183964   \n",
       "C_ID_cdbd2c0db2 -0.159749  0.000251         1.0    10               -0.100282   \n",
       "\n",
       "                 lgb_rm_out_1-5441726427695084_LB  \n",
       "card_id                                            \n",
       "C_ID_92a2005557                         -0.321800  \n",
       "C_ID_3d0044924f                          0.147586  \n",
       "C_ID_d639edf6cd                          0.776194  \n",
       "C_ID_186d6a6901                          0.228009  \n",
       "C_ID_cdbd2c0db2                         -0.272186  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Load\n",
    "is_clf_out = [True, False][1]\n",
    "is_no_out_flg = [True, False][1]\n",
    "is_rm_out = [True, False][0]\n",
    "rm_out_cols = []\n",
    "clf_out_cols = []\n",
    "#========================================================================\n",
    "# Base Model Load\n",
    "base = utils.read_df_pkl('../input/base_no_out_clf.gz')[[key, 'first_active_month', 'hist_purchase_month_max', target, 'clf_pred', 'no_out_flg']].set_index(key)\n",
    "# base = utils.read_pkl_gzip('../input/base_no_out_clf.gz').set_index(key)\n",
    "# Alijs type\n",
    "df_type = pd.read_csv('../input/card_ids_grouping.csv').set_index(key)\n",
    "base = base.join(df_type)\n",
    "\n",
    "# ens_list = glob.glob('../ensemble/lgb_ensemble/*.gz')\n",
    "# ens_list = ['../ensemble/LB3662_stack_set/0220_222_stack_ridge_set-all_valid-term-seed328_lgb41_NN0_ridge0_ext0_rmf0_OUT29.6294_CV3.611435147657334_LB.gz']\n",
    "# ens_list = ['../stack/0222_075_stack_ridge_set-all_valid-ods-seed328_lgb30_NN0_ridge0_ext0_rmf0_OUT29.6705_CV3.6134338981630836_LB.gz']\n",
    "# ens_list = ['../stack/0221_225_stack_ridge_set-all_valid-ods-seed328_lgb53_NN0_ridge0_ext0_rmf0_OUT29.6372_CV3.6127154444046625_LB.gz']\n",
    "# ens_list = ['../stack/0224_075_stack_ridge_set-all_valid-ods-seed328_lgb80_NN0_ridge0_ext0_rmf0_OUT29.6273_CV3.61252078265292_LB.gz']\n",
    "# ens_list = ['../ensemble/LB3662_stack_set/0220_222_stack_ridge_set-all_valid-term-seed328_lgb41_NN0_ridge0_ext0_rmf0_OUT29.6294_CV3.611435147657334_LB.gz' ,'../stack/0226_151_stack_ridge_set-all_valid-ods-seed99_lgb80_NN0_ridge0_ext0_rmf0_OUT29.6076_CV3.6114771349236716_LB.gz']\n",
    "ens_list = ['../stack/0227_003_stack_ridge_set-all_valid-ods-seed29_lgb45_NN0_ridge0_ext0_rmf0_OUT29.6465_CV3.611945069509424_LB.gz']\n",
    "\n",
    "for ens_no, path in enumerate(ens_list):\n",
    "    try:\n",
    "        cv = re.search(r'CV([^/.]*)_LB.gz', path.replace('.', '-')).group(1)\n",
    "    except AttributeError:\n",
    "        print(path)\n",
    "        cv = re.search(r'CV([^/.]*).gz', path.replace('.', '-')).group(1)\n",
    "    \n",
    "#     try:\n",
    "#         blend = utils.read_df_pkl(path).set_index(key)['pred_mean']\n",
    "#     except KeyError:\n",
    "#         blend = utils.read_df_pkl(path).set_index(key)['prediction']\n",
    "    blend = utils.read_df_pkl(path)[[key, 'prediction']].set_index(key)\n",
    "    base[f'base_{cv}'] = blend\n",
    "    \n",
    "base_cols = [col for col in base.columns if col.count('base_')]\n",
    "if len(base_cols)>1:\n",
    "#     blend = utils.read_df_pkl(lb3664_list[0])[[key, 'prediction']].set_index(key)\n",
    "#     base[f'lb3664'] = blend\n",
    "    base['base_pred'] = base[base_cols].mean(axis=1)\n",
    "#     base['base_pred'] = base['base_pred']*0.2 + base['lb3664']*0.8\n",
    "    base.drop(base_cols, axis=1, inplace=True)\n",
    "    base_cols = [col for col in base.columns if col.count('base_')]\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# Clf Out Model\n",
    "if is_clf_out:\n",
    "    out_list = glob.glob('../clf_min_thres_ensemble/*.gz')\n",
    "    out_list = ['../stack/0215_215_clf_out_lgb_out_part-clf_out_valid-ods_foldseed328_ESET0_row199950_lr0.01_235feats_3seed_70leaves_colsample0.325582_iter1222_OUT0_CV7-9325325611862105_LB.gz']\n",
    "    for path in out_list:\n",
    "        cv = re.search(r'CV([^/.]*).gz', path.replace('.', '-')).group(1)\n",
    "        try:\n",
    "            blend = utils.read_pkl_gzip(path).set_index(key)['pred_mean']\n",
    "        except KeyError:\n",
    "            blend = utils.read_pkl_gzip(path).set_index(key)['prediction']\n",
    "        base[f\"clf_out_{cv}\"] = blend\n",
    "    clf_out_cols = [col for col in base.columns if col.count('clf_out_2')]\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# No Out Flg Model\n",
    "if is_no_out_flg:\n",
    "    no_out_flg_list = glob.glob('../no_out_flg_ensemble/*.gz')\n",
    "    no_out_flg_list = ['../stack/']\n",
    "\n",
    "    for path in no_out_flg_list:\n",
    "        cv = re.search(r'CV([^/.]*).gz', path.replace('.', '-')).group(1)\n",
    "        try:\n",
    "            blend = utils.read_pkl_gzip(path).set_index(key)['pred_mean']\n",
    "        except KeyError:\n",
    "            blend = utils.read_pkl_gzip(path).set_index(key)['prediction']\n",
    "        base[f\"no_out_flg_{cv}\"] = blend\n",
    "    no_out_cols = [col for col in base.columns if col.count('no_out_flg_1')]\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# No Out Model\n",
    "if is_rm_out:\n",
    "    rm_out_list = ['../stack/0226_151_stack_ridge_set-rm_out_valid-ods-seed99_lgb11_NN0_ridge0_ext0_rmf0_OUT0_CV1.5441726427695084_LB.gz']\n",
    "#     rm_out_list = ['../stack/0220_224_stack_ridge_set-rm_out_valid-term-seed328_lgb5_NN0_ridge0_ext0_rmf0_OUT0_CV1.5459512546222733_LB.gz'] # LB3.662\n",
    "#     rm_out_list = ['../ensemble/LB3662_stack_set/0220_224_stack_ridge_set-rm_out_valid-term-seed328_lgb5_NN0_ridge0_ext0_rmf0_OUT0_CV1.5459512546222733_LB.gz']\n",
    "    rm_out_list += ['../stack/dir_level2/0215_230_stack_ridge_set-rm_out_lgb20_NN0_ridge1_ext1_rmf1_OUT0_CV8.408986180641215_LB.gz']\n",
    "\n",
    "    for path in rm_out_list:\n",
    "        if path.count('NN') and path.count('all'):continue\n",
    "        try:\n",
    "            cv = re.search(r'CV([^/.]*).gz', path.replace('.', '-')).group(1)\n",
    "        except AttributeError:\n",
    "            print(path)\n",
    "            sys.exit()\n",
    "        try:\n",
    "            blend = utils.read_pkl_gzip(path).set_index(key)['pred_mean']\n",
    "        except KeyError:\n",
    "            blend = utils.read_pkl_gzip(path).set_index(key)['prediction']\n",
    "        if path.count('lgb'):\n",
    "            col = f\"lgb_rm_out_{cv}\"\n",
    "        elif path.count('NN'):\n",
    "            col = f\"nn_rm_out_{cv}\"\n",
    "        base[col] = blend\n",
    "#========================================================================\n",
    "\n",
    "\n",
    "#========================================================================\n",
    "# Classifier\n",
    "clf = utils.read_pkl_gzip('../stack/0207_224_outlier_classify_9seed_lgb_binary_CV0-9099420278047783_235features.gz')[[key, 'pred_mean']].set_index(key)\n",
    "clf_2 = utils.read_pkl_gzip('../stack/0207_212_outlier_classify_9seed_lgb_binary_CV0-9084737642836664_235features.gz')[[key, 'pred_mean']].set_index(key)\n",
    "# clf = utils.read_pkl_gzip('../stack/0215_204_stack_lgr_set-all_lgb20_NN0_ridge1_ext1_rmf1_OUT0_CV0.9541067640604712_LB.gz')[[key, 'prediction']].set_index(key)\n",
    "clf['pred_mean_2'] = clf_2['pred_mean']\n",
    "clf['clf_pred'] =  clf['pred_mean'].values*0.9 + clf['pred_mean_2'].values*0.1\n",
    "# clf['clf_pred'] =  clf['pred_mean']\n",
    "# clf['clf_pred'] =  clf['prediction']\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# Indexをそろえる\n",
    "base['clf_pred'] = clf['clf_pred']\n",
    "pred_cols = [col for col in base.columns if col.count('-') or col.count('base_pred')]\n",
    "ignore_list += [col for col in base.columns if col.count('hist') or col.count('new_') or col.count('month')]\n",
    "pred_cols = sorted(pred_cols)\n",
    "base = base[[target, 'clf_pred', 'no_out_flg', 'type'] + pred_cols]\n",
    "\n",
    "base_col_list = [col for col in base.columns if col.count('base_3-6')]\n",
    "rm1_col_list = [col for col in base.columns if col.count('rm_out_1')]\n",
    "rm8_col_list = [col for col in base.columns if col.count('rm_out_8')]\n",
    "pred_col_list = base_col_list + rm1_col_list + rm8_col_list\n",
    "if len(rm1_col_list):\n",
    "    base.loc[base[rm1_col_list[0]].isnull(), rm1_col_list[0]] = base.loc[base[rm1_col_list[0]].isnull(), rm8_col_list[0]]\n",
    "    base.drop(rm8_col_list[0], axis=1, inplace=True)\n",
    "rm_out_cols = [col for col in base.columns if col.count('rm_out')]\n",
    "\n",
    "base.head()\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Upper Score: 7.367982735385028 | Base Lower Score: 2.170069260004209\n",
      "Rm Out Upper Score: 7.905273671128621 | Rm Out Lower Score: 2.160502483625073\n",
      "\n",
      "    #========================================================================\n",
      "    # CV SCORE AVG: 3.6064515607612058\n",
      "    # OUT SCORE: (1.8500174355070078, 29.66900671264871)\n",
      "    #========================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_upper</th>\n",
       "      <td>7.36798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_lower</th>\n",
       "      <td>2.17007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rm_out_upper</th>\n",
       "      <td>7.90527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rm_out_lower</th>\n",
       "      <td>2.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_score</th>\n",
       "      <td>3.60645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_score</th>\n",
       "      <td>(1.8500174355070078, 29.66900671264871)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "base_upper                                    7.36798\n",
       "base_lower                                    2.17007\n",
       "rm_out_upper                                  7.90527\n",
       "rm_out_lower                                   2.1605\n",
       "cv_score                                      3.60645\n",
       "out_score     (1.8500174355070078, 29.66900671264871)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_0ab67a22ab</th>\n",
       "      <td>-1.361241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_130fd0cbdd</th>\n",
       "      <td>-0.175002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_b709037bc5</th>\n",
       "      <td>-1.335535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_d27d835a9f</th>\n",
       "      <td>-0.140812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_2b5e3df5c2</th>\n",
       "      <td>-1.359720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   target\n",
       "card_id                  \n",
       "C_ID_0ab67a22ab -1.361241\n",
       "C_ID_130fd0cbdd -0.175002\n",
       "C_ID_b709037bc5 -1.335535\n",
       "C_ID_d27d835a9f -0.140812\n",
       "C_ID_2b5e3df5c2 -1.359720"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = 'prediction'\n",
    "min_thres = 0.01\n",
    "# min_thres = 0.019\n",
    "result_list = []\n",
    "clf_out_cols = []\n",
    "df_score = get_submit(base=base, min_thres=min_thres)\n",
    "# df_score.name = i\n",
    "result_list.append(df_score)\n",
    "df_score = pd.concat(result_list, axis=1)\n",
    "display(df_score)\n",
    "\n",
    "cv_score = df_score.loc['cv_score'].values[0]\n",
    "out_score = df_score.loc['out_score'].values[0]\n",
    "\n",
    "submit = pd.read_csv('../input/sample_submission.csv').set_index(key)\n",
    "submit[target] = base[pred]\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
    "submit_path = f'{start_time[4:12]}_submit_outlier_processing_blend_base{len(base_cols)}_clf_out{len(clf_out_cols)}_rm_out{len(rm_out_cols)}_no_out_blend0_minthres{min_thres}_OUT{str(out_score[0])[:6]}-{str(out_score[1])[:6]}_CV{str(cv_score)[:7]}_LB'\n",
    "# submit.to_csv(f'../submit/{submit_path}')\n",
    "utils.to_pkl_gzip(obj=base.reset_index()[[key, target, 'prediction']], path=f\"../stack/{submit_path.replace('submit', 'stack_submit_log')}\")\n",
    "display(submit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For OOF Share\n",
    "\"\"\"\n",
    "# pred_col_list = [target, 'clf_pred', 'no_out_flg', 'base_pred', 'rm_out_pred', 'prediction']\n",
    "# base = base[pred_col_list].rename(columns={'base_pred':'With_Outlier_41LGB_corr~0.985_Stack_OUT29.6294_CV3.611435', 'rm_out_pred':'Without_Outlier_5LGB_corr~0.985_Stack_CV1.54595', 'prediction':'LB3.662_OUT29.656_CV3.60558_WituoutOut1.85059'})\n",
    "# utils.to_pkl_gzip(obj=base, path='../output/0220_234_elo_OOF_LB3662_and_2Stack_OOF')\n",
    "# base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #========================================================================\n",
    "# # Classifier Pred Layer Scoring\n",
    "pd.set_option('max_rows', 300)\n",
    "base_col_list = [col for col in base.columns if col.count('base_3-6')]\n",
    "rm_col_list = [col for col in base.columns if col.count('rm_out_')]\n",
    "pred_col_list = base_col_list + rm_col_list\n",
    "\n",
    "df = base[~base[target].isnull()]\n",
    "df['clf_layer'] = df['clf_pred'].map(lambda x: np.round(x, 3))\n",
    "layer_list = sorted(list(df['clf_layer'].value_counts().index))\n",
    "df_list = []\n",
    "\n",
    "for pred_col in pred_col_list:\n",
    "    part_score_list = []\n",
    "    df.loc[df['no_out_flg']==1, pred_col] = df.loc[df['no_out_flg']==1, rm1_col_list[0]]\n",
    "    for layer in layer_list:\n",
    "        tmp = df[df['clf_layer']==layer]\n",
    "        y_pred = tmp[pred_col]\n",
    "        y_train = tmp[target]\n",
    "        try:\n",
    "            part_score = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "            part_score_list.append(part_score)\n",
    "        except ValueError:\n",
    "            part_score_list.append(0)\n",
    "            continue\n",
    "        \n",
    "    tmp_score = pd.Series(data=part_score_list, index=layer_list, name=pred_col)\n",
    "    df_list.append(tmp_score)\n",
    "    \n",
    "df_layer_score = pd.concat(df_list + [df['clf_layer'].value_counts().to_frame()], axis=1)\n",
    "df_layer_score['diff_score'] = df_layer_score[pred_col_list[0]] - df_layer_score[pred_col_list[1]]\n",
    "display(df_layer_score)\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#========================================================================\n",
    "# Classifier Blend\n",
    "from sklearn.metrics import roc_auc_score\n",
    "train = base[~base[target].isnull()]\n",
    "test = base[base[target].isnull()]\n",
    "y_train = train[target].map(lambda x: 1 if x<-30 else 0).values\n",
    "base_cols = [col for col in train.columns if col.count('base_')]\n",
    "y_pred = (train[base_cols[6]]*0.5 + train[base_cols[8:10]].mean(axis=1)*0.4 + train[base_cols[10]]*0.1).values\n",
    "roc_auc_score(y_train, y_pred)\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# Manual Pred Threshold\n",
    "clf_stack = utils.read_pkl_gzip('../stack/0215_204_stack_lgr_set-all_lgb20_NN0_ridge1_ext1_rmf1_OUT0_CV0.9541067640604712_LB.gz')[[key, 'prediction']].set_index(key)\n",
    "tmp = base.copy()\n",
    "tmp[target] = tmp[target].map(lambda x: 1 if x<-30 else 0)\n",
    "tmp['clf_stack_pred'] = clf_stack['prediction']\n",
    "tmp['clf_pred'] = tmp['base_0-9099420278047783_235features']\n",
    "tmp.sort_values(by='clf_stack_pred', inplace=True, ascending=False)\n",
    "# tmp.sort_values(by='clf_pred', inplace=True, ascending=False)\n",
    "clf_stack_top100_id = list(tmp.iloc[:100, 0].index)\n",
    "#========================================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
