{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-13 08:39:55,913 utils 400 [INFO]    [logger_func] start \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "import re\n",
    "import gc\n",
    "import glob\n",
    "\n",
    "import os\n",
    "HOME = os.path.expanduser('~')\n",
    "sys.path.append(f\"{HOME}/kaggle/data_analysis/library/\")\n",
    "import utils\n",
    "from utils import logger_func\n",
    "logger = logger_func()\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('max_rows', 200)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "path_list = glob.glob('../stack/*.gz')\n",
    "import pickle\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "start_time = \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
    "key = 'card_id'\n",
    "target = 'target'\n",
    "ignore_list = [key, target, 'merchant_id', 'first_active_month', 'index', 'personal_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# CV CHECKER \n",
    "# Data Load\n",
    "def get_cv_score(model_path):\n",
    "    base = utils.read_df_pkl('../input/base_term*')[[key, target]].set_index(key)\n",
    "    train = base[~base[target].isnull()]\n",
    "\n",
    "    tmp = utils.read_pkl_gzip(model_path)\n",
    "    if 'pred_mean' in tmp.columns:\n",
    "        pred_col = 'pred_mean'\n",
    "    elif 'prediction' in tmp.columns:\n",
    "        pred_col = 'prediction'\n",
    "    tmp = tmp.reset_index()[[key, pred_col]].set_index(key)\n",
    "    \n",
    "    train['pred'] = tmp[pred_col]\n",
    "\n",
    "    y_train = train[target].values\n",
    "    y_pred = train['pred'].values\n",
    "    score = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "    print(f\"CV: {score}\")\n",
    "    return score\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================================\n",
    "# 1:N Corr Checker\n",
    "from itertools import combinations\n",
    "base = utils.read_pkl_gzip('../input/base_no_out_clf.gz').set_index(key).query('no_out_flg==1')\n",
    "ens_list = glob.glob('../stack/*.gz')\n",
    "\n",
    "base_path = '../ensemble/0212_105_all_lgb_out_partall_row201917_lr0.01_235feats_10seed_57leaves_iter1428_OUT0_CV3-6206463759490277_LB.gz'\n",
    "base_model = utils.read_pkl_gzip(base_path)[[key, 'pred_mean']].set_index(key)\n",
    "base['base_pred'] = base_model['pred_mean']\n",
    "cv1 = re.search(r'CV([^/.]*)_LB.gz', base_path).group(1)\n",
    "base_len = len(base)\n",
    "\n",
    "#=======================================================================\n",
    "# Classifier\n",
    "# clf = utils.read_pkl_gzip('../stack/0207_224_outlier_classify_9seed_lgb_binary_CV0-9099420278047783_235features.gz')[[key, 'pred_mean']].set_index(key)\n",
    "# clf_2 = utils.read_pkl_gzip('../stack/0207_212_outlier_classify_9seed_lgb_binary_CV0-9084737642836664_235features.gz')[[key, 'pred_mean']].set_index(key)\n",
    "# clf['pred_mean_2'] = clf_2['pred_mean']\n",
    "# clf['clf_pred'] =  clf['pred_mean'].values*0.9 + clf['pred_mean_2'].values*0.1\n",
    "# base['clf_pred'] = clf['clf_pred']\n",
    "# utils.to_pkl_gzip(obj=base.reset_index(), path='../input/base_clf')\n",
    "# sys.exit()\n",
    "#========================================================================\n",
    "\n",
    "#========================================================================\n",
    "# 相関\n",
    "\n",
    "def get_corr_ensemble(path, base):\n",
    "    '''\n",
    "    1. ベースモデルとの相関を個別に取得する\n",
    "    2. ベースモデルにpath_listのモデルの予測をjoinし、相関行列を取得する\n",
    "    '''\n",
    "    \n",
    "    if key in base.columns:\n",
    "        base = base.set_index(key)\n",
    "    \n",
    "    #========================================================================\n",
    "    # 個別に相関を見ていく場合\n",
    "    if str(type(path)).count('str'):\n",
    "    \n",
    "        if path.count('CV1'):\n",
    "            return 0, ''\n",
    "        if path.count('binary'):\n",
    "            return 0, ''\n",
    "        tmp = utils.read_pkl_gzip(path)\n",
    "    \n",
    "        try:\n",
    "            tmp = tmp.reset_index()[[key, 'pred_mean']].set_index(key)\n",
    "            base['tmp_pred'] = tmp.reset_index()['pred_mean']\n",
    "        except KeyError:\n",
    "            tmp = tmp.reset_index()[[key, 'prediction']].set_index(key)\n",
    "            base['tmp_pred'] = tmp['prediction']\n",
    "    \n",
    "        if path.count('LB'):\n",
    "            try:\n",
    "                cv2 = re.search(r'CV([^/.]*)_LB.gz', path.replace('.', '-')).group(1)\n",
    "            except AttributeError:\n",
    "                return 0, ''\n",
    "        else:\n",
    "            cv2 = re.search(r'CV([^/.]*)', path.replace('.', '-')).group(1)\n",
    "    \n",
    "        corr = np.corrcoef(base['base_pred'], base['tmp_pred'].values).min()\n",
    "    \n",
    "        if corr>0 and corr<0.98:\n",
    "            logger.info(f\"CORR: {corr} | CV{cv1[:6]} vs CV{cv2[:6]}\")\n",
    "            \n",
    "            return corr, path\n",
    "        else:\n",
    "            return 0, ''\n",
    "    #========================================================================\n",
    "    \n",
    "    #========================================================================\n",
    "    # まとめて相関行列を見たい場合\n",
    "    elif str(type(path)).count('list'):\n",
    "        path_list = path\n",
    "        for path in path_list:\n",
    "        \n",
    "            if path.count('CV1'):\n",
    "                return 0, ''\n",
    "            if path.count('binary'):\n",
    "                return 0, ''\n",
    "            tmp = utils.read_pkl_gzip(path)\n",
    "\n",
    "            if 'pred_mean' in tmp.columns:\n",
    "                pred_col = 'pred_mean'\n",
    "            elif 'prediction' in tmp.columns:\n",
    "                pred_col = 'prediction'\n",
    "                \n",
    "            tmp = tmp.reset_index()[[key, pred_col]].set_index(key)\n",
    "                \n",
    "            if path.count('LB'):\n",
    "                try:\n",
    "                    cv2 = re.search(r'CV([^/.]*)_LB.gz', path.replace('.', '-')).group(1)\n",
    "                except AttributeError:\n",
    "                    return 0, ''\n",
    "            else:\n",
    "                cv2 = re.search(r'CV([^/.]*)', path.replace('.', '-')).group(1)\n",
    "                \n",
    "            base[f'pr_{cv2[:6]}'] = tmp[pred_col]\n",
    "            \n",
    "        drop_cols = [col for col in base.columns if col.count('term') or col.count('no_out_flg') or col in ignore_list or col.count('clf')]\n",
    "        base.drop(drop_cols, axis=1, inplace=True)\n",
    "        base.sort_index(axis=1, inplace=True)\n",
    "        mx_corr = base.corr(method='pearson')\n",
    "#         mx_cor = mx_corr.drop(drop_cols, axis=1).loc[~mx_corr.index.isin(drop_cols)]\n",
    "        \n",
    "        return mx_corr\n",
    "    #========================================================================\n",
    "    \n",
    "\n",
    "corr_list = []\n",
    "path_list = [] \n",
    "for path in ens_list:\n",
    "    corr, path = get_corr_ensemble(path, base)\n",
    "    if corr>0:\n",
    "        corr_list.append(corr)\n",
    "        path_list.append(path)\n",
    "#========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_ens_list = path_list.copy()\n",
    "df_corr = pd.DataFrame([path_list, corr_list]).T\n",
    "df_corr.columns = ['path', 'corr']\n",
    "df_corr.sort_values(by='corr', ascending=False, inplace=True)\n",
    "df_corr['cv'] = df_corr['path'].map(lambda x: re.search(r'CV([^/.]*)_LB.gz', x.replace('.', '-')).group(1))\n",
    "df_corr.reset_index(inplace=True, drop=True)\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../ensemble/lgb_ensemble/0213_000_all_lgb_obj-regression_out_part-all_valid-term_ESET0_row201917_lr1.0_235feats_1seed_70leaves_iter1_OUT0_CV3-7362871662281507_LB.gz'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "move_path = df_corr[df_corr['cv'].map(lambda x: str(x)[:6])=='3-7362']['path'].values[0]\n",
    "shutil.move(move_path, '../ensemble/lgb_ensemble/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr = get_corr_ensemble(path=top_ens_list, base=base)\n",
    "display(top_corr)\n",
    "top_corr.to_csv('../output/0213_elo_corr_ensemble_heatmap.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr_3-7753</th>\n",
       "      <th>pr_3-7798</th>\n",
       "      <th>pr_3-7806</th>\n",
       "      <th>pr_3-7807</th>\n",
       "      <th>pr_3-7827</th>\n",
       "      <th>pr_3-7852</th>\n",
       "      <th>pr_3-7855</th>\n",
       "      <th>pr_3-7884</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pr_3-7753</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872396</td>\n",
       "      <td>0.851467</td>\n",
       "      <td>0.778420</td>\n",
       "      <td>0.820193</td>\n",
       "      <td>0.844610</td>\n",
       "      <td>0.804543</td>\n",
       "      <td>0.819744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr_3-7798</th>\n",
       "      <td>0.872396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864499</td>\n",
       "      <td>0.799611</td>\n",
       "      <td>0.831859</td>\n",
       "      <td>0.851006</td>\n",
       "      <td>0.822094</td>\n",
       "      <td>0.826828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr_3-7806</th>\n",
       "      <td>0.851467</td>\n",
       "      <td>0.864499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818127</td>\n",
       "      <td>0.843877</td>\n",
       "      <td>0.906750</td>\n",
       "      <td>0.836875</td>\n",
       "      <td>0.846349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr_3-7807</th>\n",
       "      <td>0.778420</td>\n",
       "      <td>0.799611</td>\n",
       "      <td>0.818127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816613</td>\n",
       "      <td>0.803077</td>\n",
       "      <td>0.809814</td>\n",
       "      <td>0.840605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr_3-7827</th>\n",
       "      <td>0.820193</td>\n",
       "      <td>0.831859</td>\n",
       "      <td>0.843877</td>\n",
       "      <td>0.816613</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838519</td>\n",
       "      <td>0.849409</td>\n",
       "      <td>0.850854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr_3-7852</th>\n",
       "      <td>0.844610</td>\n",
       "      <td>0.851006</td>\n",
       "      <td>0.906750</td>\n",
       "      <td>0.803077</td>\n",
       "      <td>0.838519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828511</td>\n",
       "      <td>0.841070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr_3-7855</th>\n",
       "      <td>0.804543</td>\n",
       "      <td>0.822094</td>\n",
       "      <td>0.836875</td>\n",
       "      <td>0.809814</td>\n",
       "      <td>0.849409</td>\n",
       "      <td>0.828511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr_3-7884</th>\n",
       "      <td>0.819744</td>\n",
       "      <td>0.826828</td>\n",
       "      <td>0.846349</td>\n",
       "      <td>0.840605</td>\n",
       "      <td>0.850854</td>\n",
       "      <td>0.841070</td>\n",
       "      <td>0.837329</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pr_3-7753  pr_3-7798  pr_3-7806  pr_3-7807  pr_3-7827  pr_3-7852  \\\n",
       "pr_3-7753   1.000000   0.872396   0.851467   0.778420   0.820193   0.844610   \n",
       "pr_3-7798   0.872396   1.000000   0.864499   0.799611   0.831859   0.851006   \n",
       "pr_3-7806   0.851467   0.864499   1.000000   0.818127   0.843877   0.906750   \n",
       "pr_3-7807   0.778420   0.799611   0.818127   1.000000   0.816613   0.803077   \n",
       "pr_3-7827   0.820193   0.831859   0.843877   0.816613   1.000000   0.838519   \n",
       "pr_3-7852   0.844610   0.851006   0.906750   0.803077   0.838519   1.000000   \n",
       "pr_3-7855   0.804543   0.822094   0.836875   0.809814   0.849409   0.828511   \n",
       "pr_3-7884   0.819744   0.826828   0.846349   0.840605   0.850854   0.841070   \n",
       "\n",
       "           pr_3-7855  pr_3-7884  \n",
       "pr_3-7753   0.804543   0.819744  \n",
       "pr_3-7798   0.822094   0.826828  \n",
       "pr_3-7806   0.836875   0.846349  \n",
       "pr_3-7807   0.809814   0.840605  \n",
       "pr_3-7827   0.849409   0.850854  \n",
       "pr_3-7852   0.828511   0.841070  \n",
       "pr_3-7855   1.000000   0.837329  \n",
       "pr_3-7884   0.837329   1.000000  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '../stack/0209_164_stack_lgb_lr0.01_338feats_1seed_70leaves_iter995_OUT29.9569_CV3-6297296108420443_LB.gz'\n",
    "NN_path = '../ensemble/NN_ensemble/*.gz'\n",
    "nn_path_list = glob.glob(NN_path)\n",
    "# for model_path in nn_path_list:\n",
    "#     get_cv_score(model_path)\n",
    "base = utils.read_pkl_gzip('../input/base_no_out_clf.gz')\n",
    "nn_corr = get_corr_ensemble(path=nn_path_list, base=base)\n",
    "nn_corr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
